{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune SegFormer (B2/B5) on RELLIS-3D or RUGD\n",
    "\n",
    "This notebook trains a larger SegFormer model on Google Colab Pro (A100 GPU).\n",
    "\n",
    "## Setup\n",
    "1. Upload your **preprocessed dataset** to Google Drive root (My Drive):\n",
    "   - `rellis3d_processed.zip` or `rugd_processed.zip`\n",
    "   - These should contain: `train/images/`, `train/labels/`, `val/images/`, `val/labels/`, `id2label.json`, `label2id.json`\n",
    "2. Set the config in Cell 2 below\n",
    "3. **Runtime → Change runtime type → A100 GPU**\n",
    "4. Run all cells\n",
    "\n",
    "## Estimated Training Time (B2 @ 512×512, 50 epochs)\n",
    "- **A100 (Colab Pro):** ~1.5–2 hours\n",
    "- **T4 (Colab Free):** ~3–4 hours\n",
    "\n",
    "With Colab Pro you can close the tab — training continues in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install dependencies\n",
    "!pip install -q transformers datasets torch torchvision Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration — EDIT THESE\n",
    "\n",
    "DATASET = \"rellis3d\"          # \"rellis3d\" or \"rugd\"\n",
    "MODEL_SIZE = \"b2\"             # \"b0\", \"b1\", \"b2\", \"b3\", \"b4\", \"b5\"\n",
    "BASE_MODEL = \"ade\"            # \"ade\" (recommended for off-road) or \"cityscapes\"\n",
    "IMAGE_SIZE = 768              # 768 recommended (near RUGD native res, good for RELLIS-3D too)\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 4                # 4 to avoid system RAM spikes during checkpoint saves\n",
    "LEARNING_RATE = 6e-5\n",
    "FP16 = True                   # Mixed precision (faster on T4/A100)\n",
    "GRADIENT_CHECKPOINTING = False # Set True if you get OOM errors\n",
    "\n",
    "# Paths (relative to Google Drive)\n",
    "DRIVE_ZIP = f\"/content/drive/MyDrive/{DATASET}_processed.zip\"  # uploaded zip\n",
    "DATASET_DIR = f\"/content/{DATASET}_processed\"\n",
    "OUTPUT_DIR = f\"/content/drive/MyDrive/segformer_outputs/{DATASET}_segformer_{MODEL_SIZE}\"\n",
    "\n",
    "# Model ID\n",
    "if BASE_MODEL == \"cityscapes\":\n",
    "    MODEL_NAME = f\"nvidia/segformer-{MODEL_SIZE}-finetuned-cityscapes-1024-1024\"\n",
    "else:\n",
    "    MODEL_NAME = f\"nvidia/segformer-{MODEL_SIZE}-finetuned-ade-512-512\"\n",
    "\n",
    "print(f\"Dataset: {DATASET}\")\n",
    "print(f\"Base model: {MODEL_NAME}\")\n",
    "print(f\"Image size: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}, Batch: {BATCH_SIZE}, LR: {LEARNING_RATE}\")\n",
    "print(f\"FP16: {FP16}, Gradient checkpointing: {GRADIENT_CHECKPOINTING}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Mount Google Drive and copy dataset to local disk\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "import os, shutil\n",
    "\n",
    "# Copy from unzipped folder on Drive to local SSD (faster training)\n",
    "DRIVE_DATASET = f\"/content/drive/MyDrive/{DATASET}_processed\"\n",
    "\n",
    "if not os.path.isdir(DATASET_DIR):\n",
    "    if os.path.isdir(DRIVE_DATASET):\n",
    "        print(f\"Copying {DRIVE_DATASET} to local disk...\")\n",
    "        shutil.copytree(DRIVE_DATASET, DATASET_DIR)\n",
    "        print(\"Done.\")\n",
    "    else:\n",
    "        print(f\"ERROR: {DRIVE_DATASET} not found on Drive!\")\n",
    "        print(\"Available folders:\")\n",
    "        for item in sorted(os.listdir(\"/content/drive/MyDrive/\")):\n",
    "            if \"rellis\" in item.lower() or \"rugd\" in item.lower():\n",
    "                print(f\"  {item}\")\n",
    "else:\n",
    "    print(f\"Dataset already at {DATASET_DIR}\")\n",
    "\n",
    "# Verify structure\n",
    "for sub in [\"train/images\", \"train/labels\", \"val/images\", \"val/labels\", \"id2label.json\"]:\n",
    "    path = os.path.join(DATASET_DIR, sub)\n",
    "    exists = os.path.exists(path)\n",
    "    count = \"\"\n",
    "    if exists and os.path.isdir(path):\n",
    "        count = f\" ({len(os.listdir(path))} files)\"\n",
    "    print(f\"  {'OK' if exists else 'MISSING'}: {sub}{count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Check GPU\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    vram = getattr(props, \"total_memory\", None) or getattr(props, \"total_mem\", 0)\n",
    "    print(f\"VRAM: {vram / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU! Go to Runtime → Change runtime type → A100 GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Load dataset and model\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    SegformerForSemanticSegmentation,\n",
    "    SegformerImageProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "dataset_dir = Path(DATASET_DIR)\n",
    "\n",
    "with open(dataset_dir / \"id2label.json\") as f:\n",
    "    id2label = json.load(f)\n",
    "with open(dataset_dir / \"label2id.json\") as f:\n",
    "    label2id = json.load(f)\n",
    "\n",
    "num_classes = len(id2label)\n",
    "print(f\"Classes ({num_classes}): {list(id2label.values())}\")\n",
    "\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, processor, max_size=512):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.label_dir = Path(label_dir)\n",
    "        self.processor = processor\n",
    "        self.max_size = max_size\n",
    "        image_files = {f.stem: f for f in self.image_dir.iterdir()\n",
    "                       if f.suffix.lower() in (\".jpg\", \".jpeg\", \".png\")}\n",
    "        label_files = {f.stem: f for f in self.label_dir.iterdir()\n",
    "                       if f.suffix.lower() == \".png\"}\n",
    "        common = sorted(set(image_files) & set(label_files))\n",
    "        self.pairs = [(image_files[s], label_files[s]) for s in common]\n",
    "        if not self.pairs:\n",
    "            raise ValueError(f\"No matching pairs in {image_dir} / {label_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, lbl_path = self.pairs[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = Image.open(lbl_path)\n",
    "        image = image.resize((self.max_size, self.max_size), Image.BILINEAR)\n",
    "        label = label.resize((self.max_size, self.max_size), Image.NEAREST)\n",
    "        encoded = self.processor(images=image, return_tensors=\"pt\")\n",
    "        pixel_values = encoded[\"pixel_values\"].squeeze(0)\n",
    "        labels = torch.from_numpy(np.array(label, dtype=np.int64))\n",
    "        return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "\n",
    "# Load processor and model\n",
    "print(f\"Loading {MODEL_NAME} ...\")\n",
    "processor = SegformerImageProcessor.from_pretrained(MODEL_NAME)\n",
    "processor.do_reduce_labels = False\n",
    "\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_classes,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "\n",
    "if GRADIENT_CHECKPOINTING:\n",
    "    model.gradient_checkpointing_enable()\n",
    "    print(\"Gradient checkpointing enabled\")\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SegmentationDataset(\n",
    "    dataset_dir / \"train\" / \"images\",\n",
    "    dataset_dir / \"train\" / \"labels\",\n",
    "    processor, max_size=IMAGE_SIZE,\n",
    ")\n",
    "val_dataset = SegmentationDataset(\n",
    "    dataset_dir / \"val\" / \"images\",\n",
    "    dataset_dir / \"val\" / \"labels\",\n",
    "    processor, max_size=IMAGE_SIZE,\n",
    ")\n",
    "print(f\"Train: {len(train_dataset)} samples\")\n",
    "print(f\"Val: {len(val_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Train\n",
    "import gc\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "\n",
    "LOG_FILE = \"/content/drive/MyDrive/segformer_outputs/training_log.txt\"\n",
    "\n",
    "def log_to_drive(msg):\n",
    "    \"\"\"Append a message to a log file on Drive so we can see what happened.\"\"\"\n",
    "    with open(LOG_FILE, \"a\") as f:\n",
    "        f.write(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}\\n\")\n",
    "    print(msg)\n",
    "\n",
    "def compute_metrics_factory(num_classes, ignore_index=255):\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        logits_tensor = torch.from_numpy(logits)\n",
    "        h, w = labels.shape[1], labels.shape[2]\n",
    "        logits_up = torch.nn.functional.interpolate(\n",
    "            logits_tensor, size=(h, w), mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        preds = logits_up.argmax(dim=1).numpy()\n",
    "        del logits_tensor, logits_up, logits\n",
    "\n",
    "        mask = labels != ignore_index\n",
    "        preds_valid = preds[mask]\n",
    "        labels_valid = labels[mask]\n",
    "        del preds, labels, mask\n",
    "\n",
    "        per_class_iou = []\n",
    "        per_class_acc = []\n",
    "        for cls in range(num_classes):\n",
    "            pred_cls = preds_valid == cls\n",
    "            label_cls = labels_valid == cls\n",
    "            intersection = np.logical_and(pred_cls, label_cls).sum()\n",
    "            union = np.logical_or(pred_cls, label_cls).sum()\n",
    "            if union > 0:\n",
    "                per_class_iou.append(intersection / union)\n",
    "            if label_cls.sum() > 0:\n",
    "                per_class_acc.append(intersection / label_cls.sum())\n",
    "\n",
    "        mean_iou = float(np.mean(per_class_iou)) if per_class_iou else 0.0\n",
    "        mean_acc = float(np.mean(per_class_acc)) if per_class_acc else 0.0\n",
    "        overall_acc = float((preds_valid == labels_valid).sum() / max(len(labels_valid), 1))\n",
    "\n",
    "        del preds_valid, labels_valid\n",
    "        gc.collect()\n",
    "\n",
    "        return {\n",
    "            \"mean_iou\": mean_iou,\n",
    "            \"mean_accuracy\": mean_acc,\n",
    "            \"overall_accuracy\": overall_acc,\n",
    "        }\n",
    "    return compute_metrics\n",
    "\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    lr_scheduler_type=\"polynomial\",\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=os.path.join(OUTPUT_DIR, \"logs\"),\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"mean_iou\",\n",
    "    greater_is_better=True,\n",
    "    fp16=FP16 and torch.cuda.is_available(),\n",
    "    gradient_accumulation_steps=1,\n",
    "    eval_accumulation_steps=2,\n",
    "    dataloader_num_workers=0,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics_factory(num_classes),\n",
    ")\n",
    "\n",
    "# Auto-resume from latest checkpoint if one exists on Drive\n",
    "import glob\n",
    "checkpoints = sorted(glob.glob(os.path.join(OUTPUT_DIR, \"checkpoint-*\")))\n",
    "if checkpoints:\n",
    "    log_to_drive(f\"Resuming from {checkpoints[-1]}\")\n",
    "    resume_from = checkpoints[-1]\n",
    "else:\n",
    "    log_to_drive(\"No checkpoints found, starting fresh\")\n",
    "    resume_from = None\n",
    "\n",
    "log_to_drive(f\"=== Starting training: {DATASET} {MODEL_SIZE} {BASE_MODEL} {IMAGE_SIZE}px batch={BATCH_SIZE} ===\")\n",
    "\n",
    "try:\n",
    "    trainer.train(resume_from_checkpoint=resume_from)\n",
    "    log_to_drive(\"Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    log_to_drive(f\"TRAINING CRASHED: {type(e).__name__}: {e}\")\n",
    "    log_to_drive(traceback.format_exc())\n",
    "    raise  # still show the error in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Save model, evaluate, and log results\n",
    "import shutil\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"Saving model to {OUTPUT_DIR} ...\")\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "processor.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "# Copy class mappings alongside model\n",
    "shutil.copy2(dataset_dir / \"id2label.json\", Path(OUTPUT_DIR) / \"id2label.json\")\n",
    "shutil.copy2(dataset_dir / \"label2id.json\", Path(OUTPUT_DIR) / \"label2id.json\")\n",
    "\n",
    "print(\"\\n=== Final evaluation ===\")\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)\n",
    "\n",
    "# Save results to a JSON file alongside the model\n",
    "results = {\n",
    "    \"dataset\": DATASET,\n",
    "    \"model_size\": MODEL_SIZE,\n",
    "    \"base_model\": BASE_MODEL,\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"image_size\": IMAGE_SIZE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"fp16\": FP16,\n",
    "    \"gradient_checkpointing\": GRADIENT_CHECKPOINTING,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"train_samples\": len(train_dataset),\n",
    "    \"val_samples\": len(val_dataset),\n",
    "    \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\",\n",
    "    \"date\": datetime.now().strftime(\"%Y-%m-%d %H:%M\"),\n",
    "    \"final_metrics\": {\n",
    "        \"eval_loss\": metrics[\"eval_loss\"],\n",
    "        \"mean_iou\": metrics[\"eval_mean_iou\"],\n",
    "        \"mean_accuracy\": metrics[\"eval_mean_accuracy\"],\n",
    "        \"overall_accuracy\": metrics[\"eval_overall_accuracy\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "results_path = os.path.join(OUTPUT_DIR, \"training_results.json\")\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"\\nResults saved to: {results_path}\")\n",
    "\n",
    "# Also append to a central log file on Drive\n",
    "log_path = \"/content/drive/MyDrive/segformer_outputs/all_results.json\"\n",
    "all_results = []\n",
    "if os.path.exists(log_path):\n",
    "    with open(log_path) as f:\n",
    "        all_results = json.load(f)\n",
    "all_results.append(results)\n",
    "with open(log_path, \"w\") as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "print(f\"Appended to central log: {log_path}\")\n",
    "\n",
    "print(f\"\\nDone! Model saved to Google Drive: {OUTPUT_DIR}\")\n",
    "print(\"Download the folder and place it in training/models/<name> to use in CARLA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 (Optional): Zip the model for easy download\n",
    "zip_name = f\"{DATASET}_segformer_{MODEL_SIZE}\"\n",
    "zip_path = f\"/content/drive/MyDrive/{zip_name}.zip\"\n",
    "\n",
    "print(f\"Zipping model to {zip_path} ...\")\n",
    "!cd /content/drive/MyDrive/segformer_outputs && zip -r \"/content/drive/MyDrive/{zip_name}.zip\" \"{zip_name}/\"\n",
    "print(f\"Done! Download {zip_path} from Google Drive.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
