{
  "best_global_step": 32000,
  "best_metric": 0.48413461327493684,
  "best_model_checkpoint": "/scratch/lsa_root/lsa2/howden/segformer-training/outputs/rellis3d_segformer_b0/checkpoint-32000",
  "epoch": 49.63718958207147,
  "eval_steps": 500,
  "global_step": 41000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06056935190793458,
      "grad_norm": 23.106210708618164,
      "learning_rate": 7.118644067796611e-07,
      "loss": 12.548017578125,
      "step": 50
    },
    {
      "epoch": 0.12113870381586916,
      "grad_norm": 20.418983459472656,
      "learning_rate": 1.4382566585956416e-06,
      "loss": 12.414013671875,
      "step": 100
    },
    {
      "epoch": 0.18170805572380375,
      "grad_norm": 19.174707412719727,
      "learning_rate": 2.1646489104116226e-06,
      "loss": 12.121702880859376,
      "step": 150
    },
    {
      "epoch": 0.24227740763173833,
      "grad_norm": 21.54546546936035,
      "learning_rate": 2.891041162227603e-06,
      "loss": 11.657423095703125,
      "step": 200
    },
    {
      "epoch": 0.30284675953967294,
      "grad_norm": 20.309436798095703,
      "learning_rate": 3.6174334140435834e-06,
      "loss": 11.15640625,
      "step": 250
    },
    {
      "epoch": 0.3634161114476075,
      "grad_norm": 21.627883911132812,
      "learning_rate": 4.343825665859564e-06,
      "loss": 10.67240478515625,
      "step": 300
    },
    {
      "epoch": 0.4239854633555421,
      "grad_norm": 18.68130111694336,
      "learning_rate": 5.070217917675545e-06,
      "loss": 10.061095581054687,
      "step": 350
    },
    {
      "epoch": 0.48455481526347666,
      "grad_norm": 19.445716857910156,
      "learning_rate": 5.796610169491526e-06,
      "loss": 9.433338623046875,
      "step": 400
    },
    {
      "epoch": 0.5451241671714112,
      "grad_norm": 20.018882751464844,
      "learning_rate": 6.523002421307506e-06,
      "loss": 8.838526000976563,
      "step": 450
    },
    {
      "epoch": 0.6056935190793459,
      "grad_norm": 19.449378967285156,
      "learning_rate": 7.249394673123487e-06,
      "loss": 8.3313330078125,
      "step": 500
    },
    {
      "epoch": 0.6056935190793459,
      "eval_loss": 1.8493783473968506,
      "eval_mean_accuracy": 0.24495026486744628,
      "eval_mean_iou": 0.16209563484081926,
      "eval_overall_accuracy": 0.828479894907768,
      "eval_runtime": 324.0695,
      "eval_samples_per_second": 3.033,
      "eval_steps_per_second": 3.033,
      "step": 500
    },
    {
      "epoch": 0.6662628709872804,
      "grad_norm": 16.867725372314453,
      "learning_rate": 7.975786924939467e-06,
      "loss": 7.79273193359375,
      "step": 550
    },
    {
      "epoch": 0.726832222895215,
      "grad_norm": 16.25845718383789,
      "learning_rate": 8.70217917675545e-06,
      "loss": 7.451051635742187,
      "step": 600
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 15.176861763000488,
      "learning_rate": 9.428571428571428e-06,
      "loss": 6.872006225585937,
      "step": 650
    },
    {
      "epoch": 0.8479709267110842,
      "grad_norm": 16.789628982543945,
      "learning_rate": 1.015496368038741e-05,
      "loss": 6.654530639648438,
      "step": 700
    },
    {
      "epoch": 0.9085402786190188,
      "grad_norm": 16.608375549316406,
      "learning_rate": 1.088135593220339e-05,
      "loss": 6.107360229492188,
      "step": 750
    },
    {
      "epoch": 0.9691096305269533,
      "grad_norm": 13.651588439941406,
      "learning_rate": 1.160774818401937e-05,
      "loss": 5.771304321289063,
      "step": 800
    },
    {
      "epoch": 1.0290732889158085,
      "grad_norm": 13.185879707336426,
      "learning_rate": 1.2334140435835352e-05,
      "loss": 5.338213500976562,
      "step": 850
    },
    {
      "epoch": 1.0896426408237432,
      "grad_norm": 12.823586463928223,
      "learning_rate": 1.3060532687651332e-05,
      "loss": 5.161336059570313,
      "step": 900
    },
    {
      "epoch": 1.1502119927316778,
      "grad_norm": 14.405535697937012,
      "learning_rate": 1.3786924939467312e-05,
      "loss": 4.7195556640625,
      "step": 950
    },
    {
      "epoch": 1.2107813446396123,
      "grad_norm": 12.166050910949707,
      "learning_rate": 1.4513317191283293e-05,
      "loss": 4.344944152832031,
      "step": 1000
    },
    {
      "epoch": 1.2107813446396123,
      "eval_loss": 0.923039436340332,
      "eval_mean_accuracy": 0.24760720650532814,
      "eval_mean_iou": 0.2127401430446169,
      "eval_overall_accuracy": 0.8350619435431634,
      "eval_runtime": 282.3528,
      "eval_samples_per_second": 3.481,
      "eval_steps_per_second": 3.481,
      "step": 1000
    },
    {
      "epoch": 1.271350696547547,
      "grad_norm": 12.025968551635742,
      "learning_rate": 1.5239709443099274e-05,
      "loss": 3.98187744140625,
      "step": 1050
    },
    {
      "epoch": 1.3319200484554816,
      "grad_norm": 12.722825050354004,
      "learning_rate": 1.5951573849878935e-05,
      "loss": 3.7380999755859374,
      "step": 1100
    },
    {
      "epoch": 1.392489400363416,
      "grad_norm": 9.808631896972656,
      "learning_rate": 1.6677966101694917e-05,
      "loss": 3.4353146362304687,
      "step": 1150
    },
    {
      "epoch": 1.4530587522713507,
      "grad_norm": 12.52505874633789,
      "learning_rate": 1.74043583535109e-05,
      "loss": 3.2121871948242187,
      "step": 1200
    },
    {
      "epoch": 1.5136281041792854,
      "grad_norm": 9.515175819396973,
      "learning_rate": 1.8130750605326877e-05,
      "loss": 2.9809771728515626,
      "step": 1250
    },
    {
      "epoch": 1.5741974560872198,
      "grad_norm": 11.075125694274902,
      "learning_rate": 1.8857142857142856e-05,
      "loss": 2.8554287719726563,
      "step": 1300
    },
    {
      "epoch": 1.6347668079951545,
      "grad_norm": 11.679878234863281,
      "learning_rate": 1.9583535108958838e-05,
      "loss": 2.700908203125,
      "step": 1350
    },
    {
      "epoch": 1.6953361599030892,
      "grad_norm": 6.091855525970459,
      "learning_rate": 2.030992736077482e-05,
      "loss": 2.599202880859375,
      "step": 1400
    },
    {
      "epoch": 1.7559055118110236,
      "grad_norm": 6.780461311340332,
      "learning_rate": 2.1036319612590798e-05,
      "loss": 2.326146240234375,
      "step": 1450
    },
    {
      "epoch": 1.816474863718958,
      "grad_norm": 6.289121627807617,
      "learning_rate": 2.176271186440678e-05,
      "loss": 2.155616455078125,
      "step": 1500
    },
    {
      "epoch": 1.816474863718958,
      "eval_loss": 0.5848500728607178,
      "eval_mean_accuracy": 0.26298122332632534,
      "eval_mean_iou": 0.2267528966590607,
      "eval_overall_accuracy": 0.8291604710498395,
      "eval_runtime": 290.5383,
      "eval_samples_per_second": 3.383,
      "eval_steps_per_second": 3.383,
      "step": 1500
    },
    {
      "epoch": 1.877044215626893,
      "grad_norm": 14.128758430480957,
      "learning_rate": 2.248910411622276e-05,
      "loss": 2.1263360595703125,
      "step": 1550
    },
    {
      "epoch": 1.9376135675348274,
      "grad_norm": 6.084184646606445,
      "learning_rate": 2.321549636803874e-05,
      "loss": 1.9124452209472655,
      "step": 1600
    },
    {
      "epoch": 1.9981829194427618,
      "grad_norm": 5.4948883056640625,
      "learning_rate": 2.3941888619854722e-05,
      "loss": 1.8825067138671876,
      "step": 1650
    },
    {
      "epoch": 2.058146577831617,
      "grad_norm": 7.960609436035156,
      "learning_rate": 2.4668280871670704e-05,
      "loss": 1.7880963134765624,
      "step": 1700
    },
    {
      "epoch": 2.118715929739552,
      "grad_norm": 4.945955276489258,
      "learning_rate": 2.5394673123486686e-05,
      "loss": 1.6786538696289062,
      "step": 1750
    },
    {
      "epoch": 2.1792852816474864,
      "grad_norm": 7.027496814727783,
      "learning_rate": 2.6121065375302664e-05,
      "loss": 1.8030599975585937,
      "step": 1800
    },
    {
      "epoch": 2.239854633555421,
      "grad_norm": 8.371500968933105,
      "learning_rate": 2.6847457627118643e-05,
      "loss": 1.4956517028808594,
      "step": 1850
    },
    {
      "epoch": 2.3004239854633557,
      "grad_norm": 9.609725952148438,
      "learning_rate": 2.7573849878934625e-05,
      "loss": 1.520958251953125,
      "step": 1900
    },
    {
      "epoch": 2.36099333737129,
      "grad_norm": 7.17926549911499,
      "learning_rate": 2.8285714285714287e-05,
      "loss": 1.4409759521484375,
      "step": 1950
    },
    {
      "epoch": 2.4215626892792246,
      "grad_norm": 5.723691463470459,
      "learning_rate": 2.901210653753027e-05,
      "loss": 1.4172171020507813,
      "step": 2000
    },
    {
      "epoch": 2.4215626892792246,
      "eval_loss": 0.5135277509689331,
      "eval_mean_accuracy": 0.3350511223531343,
      "eval_mean_iou": 0.28717073864212567,
      "eval_overall_accuracy": 0.8371527391435656,
      "eval_runtime": 293.6444,
      "eval_samples_per_second": 3.348,
      "eval_steps_per_second": 3.348,
      "step": 2000
    },
    {
      "epoch": 2.4821320411871595,
      "grad_norm": 6.402791500091553,
      "learning_rate": 2.973849878934625e-05,
      "loss": 1.3954147338867187,
      "step": 2050
    },
    {
      "epoch": 2.542701393095094,
      "grad_norm": 4.501773357391357,
      "learning_rate": 3.046489104116223e-05,
      "loss": 1.3487437438964844,
      "step": 2100
    },
    {
      "epoch": 2.6032707450030284,
      "grad_norm": 20.888206481933594,
      "learning_rate": 3.1191283292978214e-05,
      "loss": 1.2828993225097656,
      "step": 2150
    },
    {
      "epoch": 2.6638400969109632,
      "grad_norm": 5.432148456573486,
      "learning_rate": 3.191767554479419e-05,
      "loss": 1.262459487915039,
      "step": 2200
    },
    {
      "epoch": 2.7244094488188977,
      "grad_norm": 3.2016806602478027,
      "learning_rate": 3.264406779661017e-05,
      "loss": 1.219439468383789,
      "step": 2250
    },
    {
      "epoch": 2.784978800726832,
      "grad_norm": 5.659025192260742,
      "learning_rate": 3.337046004842615e-05,
      "loss": 1.1420394897460937,
      "step": 2300
    },
    {
      "epoch": 2.845548152634767,
      "grad_norm": 15.111092567443848,
      "learning_rate": 3.409685230024213e-05,
      "loss": 1.2160749816894532,
      "step": 2350
    },
    {
      "epoch": 2.9061175045427015,
      "grad_norm": 7.729076385498047,
      "learning_rate": 3.482324455205811e-05,
      "loss": 1.1380225372314454,
      "step": 2400
    },
    {
      "epoch": 2.966686856450636,
      "grad_norm": 11.241320610046387,
      "learning_rate": 3.554963680387409e-05,
      "loss": 1.1505612182617186,
      "step": 2450
    },
    {
      "epoch": 3.026650514839491,
      "grad_norm": 2.6916637420654297,
      "learning_rate": 3.6276029055690074e-05,
      "loss": 1.085005645751953,
      "step": 2500
    },
    {
      "epoch": 3.026650514839491,
      "eval_loss": 0.5902406573295593,
      "eval_mean_accuracy": 0.4028902070152608,
      "eval_mean_iou": 0.3412322676863944,
      "eval_overall_accuracy": 0.8301719906128799,
      "eval_runtime": 306.8811,
      "eval_samples_per_second": 3.203,
      "eval_steps_per_second": 3.203,
      "step": 2500
    },
    {
      "epoch": 3.087219866747426,
      "grad_norm": 6.011077880859375,
      "learning_rate": 3.700242130750605e-05,
      "loss": 1.1133905029296876,
      "step": 2550
    },
    {
      "epoch": 3.1477892186553604,
      "grad_norm": 8.637471199035645,
      "learning_rate": 3.772881355932203e-05,
      "loss": 0.9721997833251953,
      "step": 2600
    },
    {
      "epoch": 3.208358570563295,
      "grad_norm": 3.714839458465576,
      "learning_rate": 3.845520581113801e-05,
      "loss": 1.0460725402832032,
      "step": 2650
    },
    {
      "epoch": 3.2689279224712298,
      "grad_norm": 8.987909317016602,
      "learning_rate": 3.9181598062953995e-05,
      "loss": 1.0598860168457032,
      "step": 2700
    },
    {
      "epoch": 3.329497274379164,
      "grad_norm": 5.682387828826904,
      "learning_rate": 3.990799031476998e-05,
      "loss": 0.9476150512695313,
      "step": 2750
    },
    {
      "epoch": 3.3900666262870987,
      "grad_norm": 5.790867328643799,
      "learning_rate": 4.063438256658596e-05,
      "loss": 0.9487598419189454,
      "step": 2800
    },
    {
      "epoch": 3.4506359781950335,
      "grad_norm": 4.847104072570801,
      "learning_rate": 4.136077481840194e-05,
      "loss": 0.9534671783447266,
      "step": 2850
    },
    {
      "epoch": 3.511205330102968,
      "grad_norm": 3.9245355129241943,
      "learning_rate": 4.2087167070217916e-05,
      "loss": 0.880668716430664,
      "step": 2900
    },
    {
      "epoch": 3.5717746820109024,
      "grad_norm": 8.103219032287598,
      "learning_rate": 4.28135593220339e-05,
      "loss": 0.9035134124755859,
      "step": 2950
    },
    {
      "epoch": 3.6323440339188373,
      "grad_norm": 7.93920373916626,
      "learning_rate": 4.353995157384988e-05,
      "loss": 0.8791478729248047,
      "step": 3000
    },
    {
      "epoch": 3.6323440339188373,
      "eval_loss": 0.5508182644844055,
      "eval_mean_accuracy": 0.46890013993083646,
      "eval_mean_iou": 0.39024348827302896,
      "eval_overall_accuracy": 0.8434821096829699,
      "eval_runtime": 284.2398,
      "eval_samples_per_second": 3.458,
      "eval_steps_per_second": 3.458,
      "step": 3000
    },
    {
      "epoch": 3.6929133858267718,
      "grad_norm": 3.727444648742676,
      "learning_rate": 4.426634382566586e-05,
      "loss": 0.8754539489746094,
      "step": 3050
    },
    {
      "epoch": 3.753482737734706,
      "grad_norm": 6.005116939544678,
      "learning_rate": 4.499273607748184e-05,
      "loss": 0.8558686828613281,
      "step": 3100
    },
    {
      "epoch": 3.814052089642641,
      "grad_norm": 11.527677536010742,
      "learning_rate": 4.5719128329297825e-05,
      "loss": 0.9896338653564453,
      "step": 3150
    },
    {
      "epoch": 3.8746214415505755,
      "grad_norm": 19.34640121459961,
      "learning_rate": 4.644552058111381e-05,
      "loss": 0.8966130828857422,
      "step": 3200
    },
    {
      "epoch": 3.93519079345851,
      "grad_norm": 10.924860000610352,
      "learning_rate": 4.717191283292978e-05,
      "loss": 0.865201416015625,
      "step": 3250
    },
    {
      "epoch": 3.9957601453664444,
      "grad_norm": 7.711727142333984,
      "learning_rate": 4.7898305084745764e-05,
      "loss": 0.8579306793212891,
      "step": 3300
    },
    {
      "epoch": 4.0557238037553,
      "grad_norm": 8.42522144317627,
      "learning_rate": 4.8624697336561746e-05,
      "loss": 0.7809613800048828,
      "step": 3350
    },
    {
      "epoch": 4.116293155663234,
      "grad_norm": 3.782888650894165,
      "learning_rate": 4.935108958837773e-05,
      "loss": 0.7782891845703125,
      "step": 3400
    },
    {
      "epoch": 4.176862507571169,
      "grad_norm": 15.896016120910645,
      "learning_rate": 5.007748184019371e-05,
      "loss": 0.7435150909423828,
      "step": 3450
    },
    {
      "epoch": 4.237431859479104,
      "grad_norm": 6.561347007751465,
      "learning_rate": 5.0803874092009684e-05,
      "loss": 0.7503730010986328,
      "step": 3500
    },
    {
      "epoch": 4.237431859479104,
      "eval_loss": 0.5372267365455627,
      "eval_mean_accuracy": 0.5082525601348405,
      "eval_mean_iou": 0.39779546667098725,
      "eval_overall_accuracy": 0.8327624766290612,
      "eval_runtime": 280.2286,
      "eval_samples_per_second": 3.508,
      "eval_steps_per_second": 3.508,
      "step": 3500
    },
    {
      "epoch": 4.298001211387038,
      "grad_norm": 15.365399360656738,
      "learning_rate": 5.1530266343825666e-05,
      "loss": 0.7805766296386719,
      "step": 3550
    },
    {
      "epoch": 4.358570563294973,
      "grad_norm": 5.5040435791015625,
      "learning_rate": 5.225665859564165e-05,
      "loss": 0.7582022857666015,
      "step": 3600
    },
    {
      "epoch": 4.419139915202908,
      "grad_norm": 4.937312126159668,
      "learning_rate": 5.298305084745762e-05,
      "loss": 0.8112242126464844,
      "step": 3650
    },
    {
      "epoch": 4.479709267110842,
      "grad_norm": 7.535648345947266,
      "learning_rate": 5.3709443099273605e-05,
      "loss": 0.7360791778564453,
      "step": 3700
    },
    {
      "epoch": 4.5402786190187765,
      "grad_norm": 3.9249329566955566,
      "learning_rate": 5.443583535108959e-05,
      "loss": 0.8094174194335938,
      "step": 3750
    },
    {
      "epoch": 4.600847970926711,
      "grad_norm": 14.462108612060547,
      "learning_rate": 5.514769975786925e-05,
      "loss": 0.7558576202392578,
      "step": 3800
    },
    {
      "epoch": 4.661417322834645,
      "grad_norm": 10.797205924987793,
      "learning_rate": 5.587409200968523e-05,
      "loss": 0.7302680969238281,
      "step": 3850
    },
    {
      "epoch": 4.72198667474258,
      "grad_norm": 6.7385406494140625,
      "learning_rate": 5.660048426150121e-05,
      "loss": 0.7895218658447266,
      "step": 3900
    },
    {
      "epoch": 4.782556026650515,
      "grad_norm": 3.298769235610962,
      "learning_rate": 5.732687651331719e-05,
      "loss": 0.7604418182373047,
      "step": 3950
    },
    {
      "epoch": 4.843125378558449,
      "grad_norm": 3.2209553718566895,
      "learning_rate": 5.805326876513317e-05,
      "loss": 0.8320087432861328,
      "step": 4000
    },
    {
      "epoch": 4.843125378558449,
      "eval_loss": 0.46138936281204224,
      "eval_mean_accuracy": 0.5322806529184015,
      "eval_mean_iou": 0.4098275874326213,
      "eval_overall_accuracy": 0.8516667813274892,
      "eval_runtime": 287.3106,
      "eval_samples_per_second": 3.421,
      "eval_steps_per_second": 3.421,
      "step": 4000
    },
    {
      "epoch": 4.903694730466384,
      "grad_norm": 10.966452598571777,
      "learning_rate": 5.877966101694915e-05,
      "loss": 0.6696440124511719,
      "step": 4050
    },
    {
      "epoch": 4.964264082374319,
      "grad_norm": 9.49125862121582,
      "learning_rate": 5.9506053268765134e-05,
      "loss": 0.7461383819580079,
      "step": 4100
    },
    {
      "epoch": 5.024227740763174,
      "grad_norm": 4.769062519073486,
      "learning_rate": 5.997421576540221e-05,
      "loss": 0.6964469146728516,
      "step": 4150
    },
    {
      "epoch": 5.084797092671108,
      "grad_norm": 6.505600929260254,
      "learning_rate": 5.98936400322841e-05,
      "loss": 0.716269760131836,
      "step": 4200
    },
    {
      "epoch": 5.145366444579043,
      "grad_norm": 2.9369513988494873,
      "learning_rate": 5.981306429916599e-05,
      "loss": 0.6898282623291015,
      "step": 4250
    },
    {
      "epoch": 5.205935796486978,
      "grad_norm": 9.2747220993042,
      "learning_rate": 5.973248856604789e-05,
      "loss": 0.6426754760742187,
      "step": 4300
    },
    {
      "epoch": 5.266505148394912,
      "grad_norm": 2.463703155517578,
      "learning_rate": 5.9651912832929784e-05,
      "loss": 0.6807150268554687,
      "step": 4350
    },
    {
      "epoch": 5.327074500302847,
      "grad_norm": 5.627993583679199,
      "learning_rate": 5.957133709981168e-05,
      "loss": 0.6512995147705078,
      "step": 4400
    },
    {
      "epoch": 5.387643852210782,
      "grad_norm": 3.737644672393799,
      "learning_rate": 5.949076136669357e-05,
      "loss": 0.7000151824951172,
      "step": 4450
    },
    {
      "epoch": 5.448213204118716,
      "grad_norm": 8.525432586669922,
      "learning_rate": 5.941018563357546e-05,
      "loss": 0.6847740936279297,
      "step": 4500
    },
    {
      "epoch": 5.448213204118716,
      "eval_loss": 0.7392948269844055,
      "eval_mean_accuracy": 0.5178976480187398,
      "eval_mean_iou": 0.41277537432801925,
      "eval_overall_accuracy": 0.8139840608210676,
      "eval_runtime": 285.4788,
      "eval_samples_per_second": 3.443,
      "eval_steps_per_second": 3.443,
      "step": 4500
    },
    {
      "epoch": 5.508782556026651,
      "grad_norm": 4.084555625915527,
      "learning_rate": 5.9329609900457355e-05,
      "loss": 0.696888427734375,
      "step": 4550
    },
    {
      "epoch": 5.5693519079345855,
      "grad_norm": 3.161414861679077,
      "learning_rate": 5.9249034167339254e-05,
      "loss": 0.6326078414916992,
      "step": 4600
    },
    {
      "epoch": 5.6299212598425195,
      "grad_norm": 3.697127342224121,
      "learning_rate": 5.916845843422115e-05,
      "loss": 0.6669266510009766,
      "step": 4650
    },
    {
      "epoch": 5.690490611750454,
      "grad_norm": 3.306525468826294,
      "learning_rate": 5.9087882701103046e-05,
      "loss": 0.6762635803222656,
      "step": 4700
    },
    {
      "epoch": 5.751059963658389,
      "grad_norm": 3.420123815536499,
      "learning_rate": 5.900730696798494e-05,
      "loss": 0.6343314743041992,
      "step": 4750
    },
    {
      "epoch": 5.811629315566323,
      "grad_norm": 6.730242729187012,
      "learning_rate": 5.892673123486683e-05,
      "loss": 0.6831824493408203,
      "step": 4800
    },
    {
      "epoch": 5.872198667474258,
      "grad_norm": 3.0653882026672363,
      "learning_rate": 5.8846155501748724e-05,
      "loss": 0.6150948715209961,
      "step": 4850
    },
    {
      "epoch": 5.932768019382193,
      "grad_norm": 3.1613218784332275,
      "learning_rate": 5.8765579768630617e-05,
      "loss": 0.6787782287597657,
      "step": 4900
    },
    {
      "epoch": 5.993337371290127,
      "grad_norm": 14.305500984191895,
      "learning_rate": 5.868500403551251e-05,
      "loss": 0.6934534454345703,
      "step": 4950
    },
    {
      "epoch": 6.053301029678982,
      "grad_norm": 5.4818644523620605,
      "learning_rate": 5.86044283023944e-05,
      "loss": 0.6384311294555665,
      "step": 5000
    },
    {
      "epoch": 6.053301029678982,
      "eval_loss": 0.5965138673782349,
      "eval_mean_accuracy": 0.552092857170619,
      "eval_mean_iou": 0.4285709019175196,
      "eval_overall_accuracy": 0.8467397602504292,
      "eval_runtime": 293.5057,
      "eval_samples_per_second": 3.349,
      "eval_steps_per_second": 3.349,
      "step": 5000
    },
    {
      "epoch": 6.113870381586917,
      "grad_norm": 7.9179277420043945,
      "learning_rate": 5.85238525692763e-05,
      "loss": 0.6662525177001953,
      "step": 5050
    },
    {
      "epoch": 6.174439733494852,
      "grad_norm": 2.6162707805633545,
      "learning_rate": 5.8443276836158194e-05,
      "loss": 0.6239410400390625,
      "step": 5100
    },
    {
      "epoch": 6.235009085402786,
      "grad_norm": 7.355667591094971,
      "learning_rate": 5.8362701103040086e-05,
      "loss": 0.590357780456543,
      "step": 5150
    },
    {
      "epoch": 6.295578437310721,
      "grad_norm": 4.000810623168945,
      "learning_rate": 5.828212536992198e-05,
      "loss": 0.6123140716552734,
      "step": 5200
    },
    {
      "epoch": 6.356147789218656,
      "grad_norm": 3.2364845275878906,
      "learning_rate": 5.820154963680388e-05,
      "loss": 0.6122110748291015,
      "step": 5250
    },
    {
      "epoch": 6.41671714112659,
      "grad_norm": 3.4032981395721436,
      "learning_rate": 5.812097390368577e-05,
      "loss": 0.630811767578125,
      "step": 5300
    },
    {
      "epoch": 6.477286493034525,
      "grad_norm": 7.538097858428955,
      "learning_rate": 5.8040398170567664e-05,
      "loss": 0.6586930847167969,
      "step": 5350
    },
    {
      "epoch": 6.5378558449424595,
      "grad_norm": 6.6713480949401855,
      "learning_rate": 5.7959822437449556e-05,
      "loss": 0.5774534606933593,
      "step": 5400
    },
    {
      "epoch": 6.5984251968503935,
      "grad_norm": 9.896427154541016,
      "learning_rate": 5.787924670433145e-05,
      "loss": 0.6148529815673828,
      "step": 5450
    },
    {
      "epoch": 6.658994548758328,
      "grad_norm": 2.524714946746826,
      "learning_rate": 5.779867097121335e-05,
      "loss": 0.5767904663085938,
      "step": 5500
    },
    {
      "epoch": 6.658994548758328,
      "eval_loss": 0.5851677060127258,
      "eval_mean_accuracy": 0.5730365995870221,
      "eval_mean_iou": 0.4397378788737614,
      "eval_overall_accuracy": 0.8364256415459292,
      "eval_runtime": 276.7642,
      "eval_samples_per_second": 3.552,
      "eval_steps_per_second": 3.552,
      "step": 5500
    },
    {
      "epoch": 6.719563900666262,
      "grad_norm": 2.6021296977996826,
      "learning_rate": 5.771809523809524e-05,
      "loss": 0.548343276977539,
      "step": 5550
    },
    {
      "epoch": 6.780133252574197,
      "grad_norm": 2.8548178672790527,
      "learning_rate": 5.7637519504977133e-05,
      "loss": 0.6183465576171875,
      "step": 5600
    },
    {
      "epoch": 6.840702604482132,
      "grad_norm": 5.066976070404053,
      "learning_rate": 5.7556943771859026e-05,
      "loss": 0.6369425201416016,
      "step": 5650
    },
    {
      "epoch": 6.901271956390067,
      "grad_norm": 10.999351501464844,
      "learning_rate": 5.747636803874092e-05,
      "loss": 0.5976668167114257,
      "step": 5700
    },
    {
      "epoch": 6.961841308298001,
      "grad_norm": 7.086700439453125,
      "learning_rate": 5.739579230562281e-05,
      "loss": 0.5999417114257812,
      "step": 5750
    },
    {
      "epoch": 7.021804966686856,
      "grad_norm": 5.063155174255371,
      "learning_rate": 5.7315216572504704e-05,
      "loss": 0.651571044921875,
      "step": 5800
    },
    {
      "epoch": 7.082374318594791,
      "grad_norm": 3.76149320602417,
      "learning_rate": 5.723464083938661e-05,
      "loss": 0.6064885711669922,
      "step": 5850
    },
    {
      "epoch": 7.142943670502726,
      "grad_norm": 4.675342559814453,
      "learning_rate": 5.71540651062685e-05,
      "loss": 0.5315633392333985,
      "step": 5900
    },
    {
      "epoch": 7.20351302241066,
      "grad_norm": 4.157742977142334,
      "learning_rate": 5.7073489373150395e-05,
      "loss": 0.6025276184082031,
      "step": 5950
    },
    {
      "epoch": 7.264082374318595,
      "grad_norm": 2.304138660430908,
      "learning_rate": 5.699291364003229e-05,
      "loss": 0.6313897323608398,
      "step": 6000
    },
    {
      "epoch": 7.264082374318595,
      "eval_loss": 0.49948105216026306,
      "eval_mean_accuracy": 0.5887232783750705,
      "eval_mean_iou": 0.46296554606595175,
      "eval_overall_accuracy": 0.8496480264595785,
      "eval_runtime": 298.9615,
      "eval_samples_per_second": 3.288,
      "eval_steps_per_second": 3.288,
      "step": 6000
    },
    {
      "epoch": 7.324651726226529,
      "grad_norm": 4.340079307556152,
      "learning_rate": 5.691233790691418e-05,
      "loss": 0.5668557739257812,
      "step": 6050
    },
    {
      "epoch": 7.385221078134464,
      "grad_norm": 2.7707056999206543,
      "learning_rate": 5.683176217379607e-05,
      "loss": 0.5963176345825195,
      "step": 6100
    },
    {
      "epoch": 7.445790430042399,
      "grad_norm": 7.896157264709473,
      "learning_rate": 5.6751186440677966e-05,
      "loss": 0.5945155715942383,
      "step": 6150
    },
    {
      "epoch": 7.506359781950334,
      "grad_norm": 14.388443946838379,
      "learning_rate": 5.667061070755986e-05,
      "loss": 0.6534979248046875,
      "step": 6200
    },
    {
      "epoch": 7.566929133858268,
      "grad_norm": 4.681816577911377,
      "learning_rate": 5.659003497444176e-05,
      "loss": 0.5520659637451172,
      "step": 6250
    },
    {
      "epoch": 7.6274984857662025,
      "grad_norm": 11.518256187438965,
      "learning_rate": 5.650945924132365e-05,
      "loss": 0.5255310821533203,
      "step": 6300
    },
    {
      "epoch": 7.6880678376741365,
      "grad_norm": 3.5379838943481445,
      "learning_rate": 5.642888350820554e-05,
      "loss": 0.614936637878418,
      "step": 6350
    },
    {
      "epoch": 7.748637189582071,
      "grad_norm": 2.502737283706665,
      "learning_rate": 5.6348307775087435e-05,
      "loss": 0.5515589141845703,
      "step": 6400
    },
    {
      "epoch": 7.809206541490006,
      "grad_norm": 4.955964088439941,
      "learning_rate": 5.626773204196933e-05,
      "loss": 0.5331725311279297,
      "step": 6450
    },
    {
      "epoch": 7.86977589339794,
      "grad_norm": 4.847889423370361,
      "learning_rate": 5.618715630885123e-05,
      "loss": 0.5783296966552735,
      "step": 6500
    },
    {
      "epoch": 7.86977589339794,
      "eval_loss": 0.6350753307342529,
      "eval_mean_accuracy": 0.6055852555708237,
      "eval_mean_iou": 0.45668181453694057,
      "eval_overall_accuracy": 0.8362176221845594,
      "eval_runtime": 288.5672,
      "eval_samples_per_second": 3.406,
      "eval_steps_per_second": 3.406,
      "step": 6500
    },
    {
      "epoch": 7.930345245305875,
      "grad_norm": 1.4828355312347412,
      "learning_rate": 5.610658057573312e-05,
      "loss": 0.5343368530273438,
      "step": 6550
    },
    {
      "epoch": 7.99091459721381,
      "grad_norm": 7.9607253074646,
      "learning_rate": 5.602600484261501e-05,
      "loss": 0.6054129409790039,
      "step": 6600
    },
    {
      "epoch": 8.050878255602665,
      "grad_norm": 4.131068706512451,
      "learning_rate": 5.594542910949691e-05,
      "loss": 0.52667236328125,
      "step": 6650
    },
    {
      "epoch": 8.1114476075106,
      "grad_norm": 1.9665817022323608,
      "learning_rate": 5.5864853376378805e-05,
      "loss": 0.5394251251220703,
      "step": 6700
    },
    {
      "epoch": 8.172016959418535,
      "grad_norm": 9.475178718566895,
      "learning_rate": 5.57842776432607e-05,
      "loss": 0.5177611923217773,
      "step": 6750
    },
    {
      "epoch": 8.232586311326468,
      "grad_norm": 1.7742342948913574,
      "learning_rate": 5.570370191014259e-05,
      "loss": 0.5359785842895508,
      "step": 6800
    },
    {
      "epoch": 8.293155663234403,
      "grad_norm": 5.005674362182617,
      "learning_rate": 5.562312617702448e-05,
      "loss": 0.5712283325195312,
      "step": 6850
    },
    {
      "epoch": 8.353725015142338,
      "grad_norm": 5.387728214263916,
      "learning_rate": 5.5542550443906375e-05,
      "loss": 0.5984277725219727,
      "step": 6900
    },
    {
      "epoch": 8.414294367050273,
      "grad_norm": 2.954721450805664,
      "learning_rate": 5.546197471078827e-05,
      "loss": 0.5718382263183593,
      "step": 6950
    },
    {
      "epoch": 8.474863718958208,
      "grad_norm": 2.235624313354492,
      "learning_rate": 5.538139897767016e-05,
      "loss": 0.5630681991577149,
      "step": 7000
    },
    {
      "epoch": 8.474863718958208,
      "eval_loss": 0.5676028728485107,
      "eval_mean_accuracy": 0.5947473500502138,
      "eval_mean_iou": 0.44700397548953796,
      "eval_overall_accuracy": 0.8441601711517676,
      "eval_runtime": 278.4211,
      "eval_samples_per_second": 3.531,
      "eval_steps_per_second": 3.531,
      "step": 7000
    },
    {
      "epoch": 8.535433070866143,
      "grad_norm": 8.230671882629395,
      "learning_rate": 5.530082324455206e-05,
      "loss": 0.5443822479248047,
      "step": 7050
    },
    {
      "epoch": 8.596002422774076,
      "grad_norm": 4.3511810302734375,
      "learning_rate": 5.522024751143396e-05,
      "loss": 0.5281883239746094,
      "step": 7100
    },
    {
      "epoch": 8.65657177468201,
      "grad_norm": 3.3852639198303223,
      "learning_rate": 5.513967177831585e-05,
      "loss": 0.5955550003051758,
      "step": 7150
    },
    {
      "epoch": 8.717141126589945,
      "grad_norm": 7.944993019104004,
      "learning_rate": 5.5059096045197744e-05,
      "loss": 0.5531766510009766,
      "step": 7200
    },
    {
      "epoch": 8.77771047849788,
      "grad_norm": 4.9589433670043945,
      "learning_rate": 5.497852031207964e-05,
      "loss": 0.5474764633178711,
      "step": 7250
    },
    {
      "epoch": 8.838279830405815,
      "grad_norm": 3.553183078765869,
      "learning_rate": 5.489794457896153e-05,
      "loss": 0.517086296081543,
      "step": 7300
    },
    {
      "epoch": 8.89884918231375,
      "grad_norm": 10.042399406433105,
      "learning_rate": 5.481736884584342e-05,
      "loss": 0.5573058319091797,
      "step": 7350
    },
    {
      "epoch": 8.959418534221683,
      "grad_norm": 4.1440887451171875,
      "learning_rate": 5.473679311272532e-05,
      "loss": 0.5638298416137695,
      "step": 7400
    },
    {
      "epoch": 9.01938219261054,
      "grad_norm": 5.641514301300049,
      "learning_rate": 5.4656217379607214e-05,
      "loss": 0.5434046554565429,
      "step": 7450
    },
    {
      "epoch": 9.079951544518474,
      "grad_norm": 4.393730640411377,
      "learning_rate": 5.457564164648911e-05,
      "loss": 0.5419059371948243,
      "step": 7500
    },
    {
      "epoch": 9.079951544518474,
      "eval_loss": 0.5580925345420837,
      "eval_mean_accuracy": 0.6067227790171476,
      "eval_mean_iou": 0.43927389469928607,
      "eval_overall_accuracy": 0.8485991438189455,
      "eval_runtime": 270.9805,
      "eval_samples_per_second": 3.628,
      "eval_steps_per_second": 3.628,
      "step": 7500
    },
    {
      "epoch": 9.140520896426409,
      "grad_norm": 3.323918581008911,
      "learning_rate": 5.4495065913371e-05,
      "loss": 0.5331359481811524,
      "step": 7550
    },
    {
      "epoch": 9.201090248334342,
      "grad_norm": 2.4552228450775146,
      "learning_rate": 5.441449018025289e-05,
      "loss": 0.5347172546386719,
      "step": 7600
    },
    {
      "epoch": 9.261659600242277,
      "grad_norm": 2.68650221824646,
      "learning_rate": 5.4333914447134785e-05,
      "loss": 0.49418876647949217,
      "step": 7650
    },
    {
      "epoch": 9.322228952150212,
      "grad_norm": 4.17738151550293,
      "learning_rate": 5.425333871401668e-05,
      "loss": 0.540163459777832,
      "step": 7700
    },
    {
      "epoch": 9.382798304058147,
      "grad_norm": 6.784127712249756,
      "learning_rate": 5.4172762980898577e-05,
      "loss": 0.5182270812988281,
      "step": 7750
    },
    {
      "epoch": 9.443367655966082,
      "grad_norm": 6.91928243637085,
      "learning_rate": 5.409218724778047e-05,
      "loss": 0.5124635314941406,
      "step": 7800
    },
    {
      "epoch": 9.503937007874015,
      "grad_norm": 6.788307189941406,
      "learning_rate": 5.401161151466237e-05,
      "loss": 0.559075813293457,
      "step": 7850
    },
    {
      "epoch": 9.56450635978195,
      "grad_norm": 9.030153274536133,
      "learning_rate": 5.393103578154426e-05,
      "loss": 0.5292021560668946,
      "step": 7900
    },
    {
      "epoch": 9.625075711689885,
      "grad_norm": 5.944159984588623,
      "learning_rate": 5.3852071563088516e-05,
      "loss": 0.5589953994750977,
      "step": 7950
    },
    {
      "epoch": 9.68564506359782,
      "grad_norm": 5.959377765655518,
      "learning_rate": 5.377149582997041e-05,
      "loss": 0.5630951309204102,
      "step": 8000
    },
    {
      "epoch": 9.68564506359782,
      "eval_loss": 0.5396194458007812,
      "eval_mean_accuracy": 0.5857320377692193,
      "eval_mean_iou": 0.42656630103793985,
      "eval_overall_accuracy": 0.8356431745682461,
      "eval_runtime": 276.4482,
      "eval_samples_per_second": 3.556,
      "eval_steps_per_second": 3.556,
      "step": 8000
    },
    {
      "epoch": 9.746214415505754,
      "grad_norm": 4.2505106925964355,
      "learning_rate": 5.36909200968523e-05,
      "loss": 0.5540045166015625,
      "step": 8050
    },
    {
      "epoch": 9.80678376741369,
      "grad_norm": 5.827178478240967,
      "learning_rate": 5.3610344363734194e-05,
      "loss": 0.5166554260253906,
      "step": 8100
    },
    {
      "epoch": 9.867353119321624,
      "grad_norm": 12.885956764221191,
      "learning_rate": 5.3529768630616086e-05,
      "loss": 0.5276314544677735,
      "step": 8150
    },
    {
      "epoch": 9.927922471229557,
      "grad_norm": 1.9148170948028564,
      "learning_rate": 5.344919289749798e-05,
      "loss": 0.5014596557617188,
      "step": 8200
    },
    {
      "epoch": 9.988491823137492,
      "grad_norm": 2.6539578437805176,
      "learning_rate": 5.336861716437988e-05,
      "loss": 0.5084236526489258,
      "step": 8250
    },
    {
      "epoch": 10.048455481526348,
      "grad_norm": 2.7071375846862793,
      "learning_rate": 5.328804143126178e-05,
      "loss": 0.5229925155639649,
      "step": 8300
    },
    {
      "epoch": 10.109024833434281,
      "grad_norm": 2.3723199367523193,
      "learning_rate": 5.320746569814367e-05,
      "loss": 0.4954978942871094,
      "step": 8350
    },
    {
      "epoch": 10.169594185342216,
      "grad_norm": 1.4842625856399536,
      "learning_rate": 5.312688996502556e-05,
      "loss": 0.5148262023925781,
      "step": 8400
    },
    {
      "epoch": 10.230163537250151,
      "grad_norm": 6.0664262771606445,
      "learning_rate": 5.3046314231907455e-05,
      "loss": 0.5209538650512695,
      "step": 8450
    },
    {
      "epoch": 10.290732889158086,
      "grad_norm": 10.079168319702148,
      "learning_rate": 5.296573849878935e-05,
      "loss": 0.49094863891601564,
      "step": 8500
    },
    {
      "epoch": 10.290732889158086,
      "eval_loss": 0.4861140251159668,
      "eval_mean_accuracy": 0.6051070781934994,
      "eval_mean_iou": 0.43316482146530927,
      "eval_overall_accuracy": 0.8510598913214092,
      "eval_runtime": 284.1401,
      "eval_samples_per_second": 3.46,
      "eval_steps_per_second": 3.46,
      "step": 8500
    },
    {
      "epoch": 10.351302241066021,
      "grad_norm": 5.829141616821289,
      "learning_rate": 5.288516276567124e-05,
      "loss": 0.4932350921630859,
      "step": 8550
    },
    {
      "epoch": 10.411871592973956,
      "grad_norm": 8.64575481414795,
      "learning_rate": 5.280458703255313e-05,
      "loss": 0.49053272247314456,
      "step": 8600
    },
    {
      "epoch": 10.472440944881889,
      "grad_norm": 2.4708852767944336,
      "learning_rate": 5.2724011299435026e-05,
      "loss": 0.51360107421875,
      "step": 8650
    },
    {
      "epoch": 10.533010296789824,
      "grad_norm": 11.753164291381836,
      "learning_rate": 5.264504708097928e-05,
      "loss": 0.4971652603149414,
      "step": 8700
    },
    {
      "epoch": 10.593579648697759,
      "grad_norm": 2.338120460510254,
      "learning_rate": 5.256447134786118e-05,
      "loss": 0.5212642669677734,
      "step": 8750
    },
    {
      "epoch": 10.654149000605694,
      "grad_norm": 6.728682994842529,
      "learning_rate": 5.248389561474307e-05,
      "loss": 0.5328483581542969,
      "step": 8800
    },
    {
      "epoch": 10.714718352513628,
      "grad_norm": 1.797498345375061,
      "learning_rate": 5.240331988162497e-05,
      "loss": 0.5023420333862305,
      "step": 8850
    },
    {
      "epoch": 10.775287704421563,
      "grad_norm": 1.7412936687469482,
      "learning_rate": 5.2322744148506865e-05,
      "loss": 0.5329242706298828,
      "step": 8900
    },
    {
      "epoch": 10.835857056329496,
      "grad_norm": 2.215390682220459,
      "learning_rate": 5.224216841538876e-05,
      "loss": 0.5150625991821289,
      "step": 8950
    },
    {
      "epoch": 10.896426408237431,
      "grad_norm": 4.725046634674072,
      "learning_rate": 5.216159268227065e-05,
      "loss": 0.5019517517089844,
      "step": 9000
    },
    {
      "epoch": 10.896426408237431,
      "eval_loss": 0.5637712478637695,
      "eval_mean_accuracy": 0.6058028465247454,
      "eval_mean_iou": 0.44464908731499636,
      "eval_overall_accuracy": 0.8476856499455588,
      "eval_runtime": 273.9984,
      "eval_samples_per_second": 3.588,
      "eval_steps_per_second": 3.588,
      "step": 9000
    },
    {
      "epoch": 10.956995760145366,
      "grad_norm": 4.1068596839904785,
      "learning_rate": 5.208101694915254e-05,
      "loss": 0.534122085571289,
      "step": 9050
    },
    {
      "epoch": 11.016959418534222,
      "grad_norm": 5.524643898010254,
      "learning_rate": 5.2000441216034435e-05,
      "loss": 0.5104365539550781,
      "step": 9100
    },
    {
      "epoch": 11.077528770442155,
      "grad_norm": 2.5077481269836426,
      "learning_rate": 5.1919865482916334e-05,
      "loss": 0.4818284225463867,
      "step": 9150
    },
    {
      "epoch": 11.13809812235009,
      "grad_norm": 2.95397686958313,
      "learning_rate": 5.183928974979823e-05,
      "loss": 0.5025648498535156,
      "step": 9200
    },
    {
      "epoch": 11.198667474258025,
      "grad_norm": 13.22088623046875,
      "learning_rate": 5.175871401668012e-05,
      "loss": 0.4793647003173828,
      "step": 9250
    },
    {
      "epoch": 11.25923682616596,
      "grad_norm": 6.620297431945801,
      "learning_rate": 5.167813828356201e-05,
      "loss": 0.5014310836791992,
      "step": 9300
    },
    {
      "epoch": 11.319806178073895,
      "grad_norm": 6.239796161651611,
      "learning_rate": 5.1597562550443905e-05,
      "loss": 0.46316200256347656,
      "step": 9350
    },
    {
      "epoch": 11.38037552998183,
      "grad_norm": 2.547483205795288,
      "learning_rate": 5.1516986817325804e-05,
      "loss": 0.49576004028320314,
      "step": 9400
    },
    {
      "epoch": 11.440944881889763,
      "grad_norm": 6.332777500152588,
      "learning_rate": 5.14364110842077e-05,
      "loss": 0.5381834030151367,
      "step": 9450
    },
    {
      "epoch": 11.501514233797698,
      "grad_norm": 2.991168260574341,
      "learning_rate": 5.135583535108959e-05,
      "loss": 0.4659385681152344,
      "step": 9500
    },
    {
      "epoch": 11.501514233797698,
      "eval_loss": 0.5520944595336914,
      "eval_mean_accuracy": 0.636502539573416,
      "eval_mean_iou": 0.42140252872192857,
      "eval_overall_accuracy": 0.8401391775416455,
      "eval_runtime": 277.2026,
      "eval_samples_per_second": 3.546,
      "eval_steps_per_second": 3.546,
      "step": 9500
    },
    {
      "epoch": 11.562083585705633,
      "grad_norm": 3.7153127193450928,
      "learning_rate": 5.127525961797148e-05,
      "loss": 0.5376374816894531,
      "step": 9550
    },
    {
      "epoch": 11.622652937613568,
      "grad_norm": 5.402000427246094,
      "learning_rate": 5.1194683884853375e-05,
      "loss": 0.4950111770629883,
      "step": 9600
    },
    {
      "epoch": 11.683222289521503,
      "grad_norm": 2.87016224861145,
      "learning_rate": 5.1114108151735274e-05,
      "loss": 0.49278564453125,
      "step": 9650
    },
    {
      "epoch": 11.743791641429437,
      "grad_norm": 6.24379825592041,
      "learning_rate": 5.103353241861717e-05,
      "loss": 0.4807546997070313,
      "step": 9700
    },
    {
      "epoch": 11.80436099333737,
      "grad_norm": 1.7607264518737793,
      "learning_rate": 5.095295668549906e-05,
      "loss": 0.4910344696044922,
      "step": 9750
    },
    {
      "epoch": 11.864930345245305,
      "grad_norm": 4.24537992477417,
      "learning_rate": 5.087238095238095e-05,
      "loss": 0.5259453964233398,
      "step": 9800
    },
    {
      "epoch": 11.92549969715324,
      "grad_norm": 4.718825340270996,
      "learning_rate": 5.0791805219262845e-05,
      "loss": 0.51326904296875,
      "step": 9850
    },
    {
      "epoch": 11.986069049061175,
      "grad_norm": 5.222865581512451,
      "learning_rate": 5.0711229486144744e-05,
      "loss": 0.5055221557617188,
      "step": 9900
    },
    {
      "epoch": 12.04603270745003,
      "grad_norm": 2.4804916381835938,
      "learning_rate": 5.0630653753026637e-05,
      "loss": 0.4946904754638672,
      "step": 9950
    },
    {
      "epoch": 12.106602059357964,
      "grad_norm": 3.913205862045288,
      "learning_rate": 5.0550078019908536e-05,
      "loss": 0.4591609191894531,
      "step": 10000
    },
    {
      "epoch": 12.106602059357964,
      "eval_loss": 0.5844976305961609,
      "eval_mean_accuracy": 0.5959601944541373,
      "eval_mean_iou": 0.4253069197526865,
      "eval_overall_accuracy": 0.8382482208531361,
      "eval_runtime": 279.1593,
      "eval_samples_per_second": 3.521,
      "eval_steps_per_second": 3.521,
      "step": 10000
    },
    {
      "epoch": 12.1671714112659,
      "grad_norm": 1.5082862377166748,
      "learning_rate": 5.046950228679043e-05,
      "loss": 0.47905445098876953,
      "step": 10050
    },
    {
      "epoch": 12.227740763173834,
      "grad_norm": 2.2690184116363525,
      "learning_rate": 5.038892655367232e-05,
      "loss": 0.48459945678710936,
      "step": 10100
    },
    {
      "epoch": 12.288310115081769,
      "grad_norm": 2.150860071182251,
      "learning_rate": 5.0308350820554214e-05,
      "loss": 0.4682461929321289,
      "step": 10150
    },
    {
      "epoch": 12.348879466989704,
      "grad_norm": 3.947148561477661,
      "learning_rate": 5.0227775087436106e-05,
      "loss": 0.499050407409668,
      "step": 10200
    },
    {
      "epoch": 12.409448818897637,
      "grad_norm": 5.4679789543151855,
      "learning_rate": 5.0147199354318e-05,
      "loss": 0.48630802154541014,
      "step": 10250
    },
    {
      "epoch": 12.470018170805572,
      "grad_norm": 2.447204351425171,
      "learning_rate": 5.006662362119989e-05,
      "loss": 0.46041038513183596,
      "step": 10300
    },
    {
      "epoch": 12.530587522713507,
      "grad_norm": 3.219766616821289,
      "learning_rate": 4.9986047888081784e-05,
      "loss": 0.4908242034912109,
      "step": 10350
    },
    {
      "epoch": 12.591156874621442,
      "grad_norm": 2.57745361328125,
      "learning_rate": 4.9905472154963684e-05,
      "loss": 0.41587162017822266,
      "step": 10400
    },
    {
      "epoch": 12.651726226529377,
      "grad_norm": 6.652279376983643,
      "learning_rate": 4.9824896421845576e-05,
      "loss": 0.4896381759643555,
      "step": 10450
    },
    {
      "epoch": 12.712295578437312,
      "grad_norm": 2.1169047355651855,
      "learning_rate": 4.974432068872747e-05,
      "loss": 0.4738647079467773,
      "step": 10500
    },
    {
      "epoch": 12.712295578437312,
      "eval_loss": 0.5268553495407104,
      "eval_mean_accuracy": 0.6009260687979117,
      "eval_mean_iou": 0.4188954899276332,
      "eval_overall_accuracy": 0.8492720517597994,
      "eval_runtime": 281.5878,
      "eval_samples_per_second": 3.491,
      "eval_steps_per_second": 3.491,
      "step": 10500
    },
    {
      "epoch": 12.772864930345245,
      "grad_norm": 17.00443458557129,
      "learning_rate": 4.966374495560936e-05,
      "loss": 0.5481632995605469,
      "step": 10550
    },
    {
      "epoch": 12.83343428225318,
      "grad_norm": 5.497194766998291,
      "learning_rate": 4.9583169222491254e-05,
      "loss": 0.5166721343994141,
      "step": 10600
    },
    {
      "epoch": 12.894003634161114,
      "grad_norm": 2.8256452083587646,
      "learning_rate": 4.950259348937315e-05,
      "loss": 0.46770156860351564,
      "step": 10650
    },
    {
      "epoch": 12.95457298606905,
      "grad_norm": 2.05119252204895,
      "learning_rate": 4.942201775625505e-05,
      "loss": 0.4825484848022461,
      "step": 10700
    },
    {
      "epoch": 13.014536644457904,
      "grad_norm": 1.6235623359680176,
      "learning_rate": 4.9341442023136945e-05,
      "loss": 0.4434383392333984,
      "step": 10750
    },
    {
      "epoch": 13.075105996365838,
      "grad_norm": 2.402332305908203,
      "learning_rate": 4.926086629001884e-05,
      "loss": 0.4499794387817383,
      "step": 10800
    },
    {
      "epoch": 13.135675348273773,
      "grad_norm": 3.3082685470581055,
      "learning_rate": 4.918029055690073e-05,
      "loss": 0.49255153656005857,
      "step": 10850
    },
    {
      "epoch": 13.196244700181708,
      "grad_norm": 2.518529176712036,
      "learning_rate": 4.909971482378262e-05,
      "loss": 0.45280448913574217,
      "step": 10900
    },
    {
      "epoch": 13.256814052089643,
      "grad_norm": 2.5688986778259277,
      "learning_rate": 4.9019139090664516e-05,
      "loss": 0.432537841796875,
      "step": 10950
    },
    {
      "epoch": 13.317383403997578,
      "grad_norm": 11.26322078704834,
      "learning_rate": 4.893856335754641e-05,
      "loss": 0.47871875762939453,
      "step": 11000
    },
    {
      "epoch": 13.317383403997578,
      "eval_loss": 0.5907608270645142,
      "eval_mean_accuracy": 0.5967571058749547,
      "eval_mean_iou": 0.4071087584021472,
      "eval_overall_accuracy": 0.8470938324564471,
      "eval_runtime": 276.9945,
      "eval_samples_per_second": 3.549,
      "eval_steps_per_second": 3.549,
      "step": 11000
    },
    {
      "epoch": 13.377952755905511,
      "grad_norm": 2.2713141441345215,
      "learning_rate": 4.88579876244283e-05,
      "loss": 0.5057208251953125,
      "step": 11050
    },
    {
      "epoch": 13.438522107813446,
      "grad_norm": 5.218894004821777,
      "learning_rate": 4.8777411891310194e-05,
      "loss": 0.4345456314086914,
      "step": 11100
    },
    {
      "epoch": 13.499091459721381,
      "grad_norm": 9.040931701660156,
      "learning_rate": 4.8696836158192086e-05,
      "loss": 0.4665123748779297,
      "step": 11150
    },
    {
      "epoch": 13.559660811629316,
      "grad_norm": 23.159526824951172,
      "learning_rate": 4.8616260425073986e-05,
      "loss": 0.47296096801757814,
      "step": 11200
    },
    {
      "epoch": 13.62023016353725,
      "grad_norm": 2.3538100719451904,
      "learning_rate": 4.853568469195588e-05,
      "loss": 0.42236480712890623,
      "step": 11250
    },
    {
      "epoch": 13.680799515445184,
      "grad_norm": 5.102934837341309,
      "learning_rate": 4.845510895883778e-05,
      "loss": 0.4387694549560547,
      "step": 11300
    },
    {
      "epoch": 13.741368867353119,
      "grad_norm": 2.4761579036712646,
      "learning_rate": 4.837453322571967e-05,
      "loss": 0.45871734619140625,
      "step": 11350
    },
    {
      "epoch": 13.801938219261054,
      "grad_norm": 4.813804626464844,
      "learning_rate": 4.829395749260156e-05,
      "loss": 0.4887384414672852,
      "step": 11400
    },
    {
      "epoch": 13.862507571168988,
      "grad_norm": 5.315291881561279,
      "learning_rate": 4.8213381759483455e-05,
      "loss": 0.46535701751708985,
      "step": 11450
    },
    {
      "epoch": 13.923076923076923,
      "grad_norm": 6.103539943695068,
      "learning_rate": 4.8132806026365355e-05,
      "loss": 0.5137950515747071,
      "step": 11500
    },
    {
      "epoch": 13.923076923076923,
      "eval_loss": 0.5657873153686523,
      "eval_mean_accuracy": 0.6033788473497592,
      "eval_mean_iou": 0.4168490419443162,
      "eval_overall_accuracy": 0.8371915303072148,
      "eval_runtime": 298.8514,
      "eval_samples_per_second": 3.289,
      "eval_steps_per_second": 3.289,
      "step": 11500
    },
    {
      "epoch": 13.983646274984858,
      "grad_norm": 6.6312336921691895,
      "learning_rate": 4.805223029324725e-05,
      "loss": 0.5192544174194336,
      "step": 11550
    },
    {
      "epoch": 14.043609933373713,
      "grad_norm": 7.234951496124268,
      "learning_rate": 4.797165456012914e-05,
      "loss": 0.4230143356323242,
      "step": 11600
    },
    {
      "epoch": 14.104179285281647,
      "grad_norm": 1.7548612356185913,
      "learning_rate": 4.789107882701103e-05,
      "loss": 0.43436786651611325,
      "step": 11650
    },
    {
      "epoch": 14.164748637189582,
      "grad_norm": 3.3365867137908936,
      "learning_rate": 4.7810503093892925e-05,
      "loss": 0.4497589111328125,
      "step": 11700
    },
    {
      "epoch": 14.225317989097517,
      "grad_norm": 4.385034084320068,
      "learning_rate": 4.772992736077482e-05,
      "loss": 0.4403143310546875,
      "step": 11750
    },
    {
      "epoch": 14.285887341005452,
      "grad_norm": 28.09459114074707,
      "learning_rate": 4.764935162765671e-05,
      "loss": 0.4696118927001953,
      "step": 11800
    },
    {
      "epoch": 14.346456692913385,
      "grad_norm": 3.9859459400177,
      "learning_rate": 4.75687758945386e-05,
      "loss": 0.42799911499023435,
      "step": 11850
    },
    {
      "epoch": 14.40702604482132,
      "grad_norm": 3.1546578407287598,
      "learning_rate": 4.74882001614205e-05,
      "loss": 0.45717998504638674,
      "step": 11900
    },
    {
      "epoch": 14.467595396729255,
      "grad_norm": 1.7211754322052002,
      "learning_rate": 4.7407624428302395e-05,
      "loss": 0.46925819396972657,
      "step": 11950
    },
    {
      "epoch": 14.52816474863719,
      "grad_norm": 1.5349177122116089,
      "learning_rate": 4.7327048695184294e-05,
      "loss": 0.44857189178466794,
      "step": 12000
    },
    {
      "epoch": 14.52816474863719,
      "eval_loss": 0.539322555065155,
      "eval_mean_accuracy": 0.6261329230733391,
      "eval_mean_iou": 0.4305660407522652,
      "eval_overall_accuracy": 0.8478565390694541,
      "eval_runtime": 311.0457,
      "eval_samples_per_second": 3.16,
      "eval_steps_per_second": 3.16,
      "step": 12000
    },
    {
      "epoch": 14.588734100545125,
      "grad_norm": 2.693800926208496,
      "learning_rate": 4.724647296206619e-05,
      "loss": 0.480067138671875,
      "step": 12050
    },
    {
      "epoch": 14.649303452453058,
      "grad_norm": 2.203895330429077,
      "learning_rate": 4.716589722894808e-05,
      "loss": 0.43496849060058596,
      "step": 12100
    },
    {
      "epoch": 14.709872804360993,
      "grad_norm": 6.868728160858154,
      "learning_rate": 4.708532149582997e-05,
      "loss": 0.4545126724243164,
      "step": 12150
    },
    {
      "epoch": 14.770442156268928,
      "grad_norm": 3.416977882385254,
      "learning_rate": 4.7004745762711865e-05,
      "loss": 0.4257820129394531,
      "step": 12200
    },
    {
      "epoch": 14.831011508176863,
      "grad_norm": 4.357034683227539,
      "learning_rate": 4.692417002959376e-05,
      "loss": 0.4772001266479492,
      "step": 12250
    },
    {
      "epoch": 14.891580860084797,
      "grad_norm": 14.810358047485352,
      "learning_rate": 4.684359429647566e-05,
      "loss": 0.4161698913574219,
      "step": 12300
    },
    {
      "epoch": 14.952150211992732,
      "grad_norm": 7.116672515869141,
      "learning_rate": 4.676301856335755e-05,
      "loss": 0.486898307800293,
      "step": 12350
    },
    {
      "epoch": 15.012113870381587,
      "grad_norm": 6.885432243347168,
      "learning_rate": 4.668244283023944e-05,
      "loss": 0.42580326080322267,
      "step": 12400
    },
    {
      "epoch": 15.072683222289522,
      "grad_norm": 5.6536970138549805,
      "learning_rate": 4.6601867097121335e-05,
      "loss": 0.43013008117675783,
      "step": 12450
    },
    {
      "epoch": 15.133252574197456,
      "grad_norm": 5.56382417678833,
      "learning_rate": 4.652129136400323e-05,
      "loss": 0.427137565612793,
      "step": 12500
    },
    {
      "epoch": 15.133252574197456,
      "eval_loss": 0.4890347123146057,
      "eval_mean_accuracy": 0.6159118242744018,
      "eval_mean_iou": 0.40086883680321667,
      "eval_overall_accuracy": 0.8564696675763368,
      "eval_runtime": 310.535,
      "eval_samples_per_second": 3.166,
      "eval_steps_per_second": 3.166,
      "step": 12500
    },
    {
      "epoch": 15.193821926105391,
      "grad_norm": 11.532449722290039,
      "learning_rate": 4.644071563088513e-05,
      "loss": 0.4163092803955078,
      "step": 12550
    },
    {
      "epoch": 15.254391278013326,
      "grad_norm": 5.948975086212158,
      "learning_rate": 4.636013989776702e-05,
      "loss": 0.4157262420654297,
      "step": 12600
    },
    {
      "epoch": 15.31496062992126,
      "grad_norm": 4.563790321350098,
      "learning_rate": 4.627956416464891e-05,
      "loss": 0.4042311096191406,
      "step": 12650
    },
    {
      "epoch": 15.375529981829194,
      "grad_norm": 6.812918186187744,
      "learning_rate": 4.6198988431530804e-05,
      "loss": 0.4826938247680664,
      "step": 12700
    },
    {
      "epoch": 15.436099333737129,
      "grad_norm": 1.993779182434082,
      "learning_rate": 4.61184126984127e-05,
      "loss": 0.4240609741210937,
      "step": 12750
    },
    {
      "epoch": 15.496668685645064,
      "grad_norm": 8.359650611877441,
      "learning_rate": 4.6037836965294596e-05,
      "loss": 0.4217351531982422,
      "step": 12800
    },
    {
      "epoch": 15.557238037552999,
      "grad_norm": 3.1452648639678955,
      "learning_rate": 4.595726123217649e-05,
      "loss": 0.4338716506958008,
      "step": 12850
    },
    {
      "epoch": 15.617807389460932,
      "grad_norm": 5.313645839691162,
      "learning_rate": 4.5878297013720744e-05,
      "loss": 0.4355370712280273,
      "step": 12900
    },
    {
      "epoch": 15.678376741368867,
      "grad_norm": 2.392272710800171,
      "learning_rate": 4.5797721280602636e-05,
      "loss": 0.39073734283447265,
      "step": 12950
    },
    {
      "epoch": 15.738946093276802,
      "grad_norm": 1.9478596448898315,
      "learning_rate": 4.571714554748453e-05,
      "loss": 0.461200065612793,
      "step": 13000
    },
    {
      "epoch": 15.738946093276802,
      "eval_loss": 0.645179033279419,
      "eval_mean_accuracy": 0.6012087951244924,
      "eval_mean_iou": 0.41558828916726315,
      "eval_overall_accuracy": 0.8415259577614366,
      "eval_runtime": 288.9729,
      "eval_samples_per_second": 3.402,
      "eval_steps_per_second": 3.402,
      "step": 13000
    },
    {
      "epoch": 15.799515445184737,
      "grad_norm": 5.1147332191467285,
      "learning_rate": 4.563656981436643e-05,
      "loss": 0.40447296142578126,
      "step": 13050
    },
    {
      "epoch": 15.860084797092671,
      "grad_norm": 3.644645929336548,
      "learning_rate": 4.555599408124832e-05,
      "loss": 0.4580016326904297,
      "step": 13100
    },
    {
      "epoch": 15.920654149000606,
      "grad_norm": 4.579935550689697,
      "learning_rate": 4.547541834813022e-05,
      "loss": 0.4938640975952148,
      "step": 13150
    },
    {
      "epoch": 15.98122350090854,
      "grad_norm": 2.389003038406372,
      "learning_rate": 4.539484261501211e-05,
      "loss": 0.474442253112793,
      "step": 13200
    },
    {
      "epoch": 16.041187159297394,
      "grad_norm": 3.2389678955078125,
      "learning_rate": 4.5314266881894006e-05,
      "loss": 0.41019855499267577,
      "step": 13250
    },
    {
      "epoch": 16.10175651120533,
      "grad_norm": 5.0311408042907715,
      "learning_rate": 4.52336911487759e-05,
      "loss": 0.4459503555297852,
      "step": 13300
    },
    {
      "epoch": 16.162325863113264,
      "grad_norm": 2.767902135848999,
      "learning_rate": 4.515311541565779e-05,
      "loss": 0.4383781051635742,
      "step": 13350
    },
    {
      "epoch": 16.2228952150212,
      "grad_norm": 6.590922832489014,
      "learning_rate": 4.5072539682539683e-05,
      "loss": 0.4208038711547852,
      "step": 13400
    },
    {
      "epoch": 16.283464566929133,
      "grad_norm": 4.021482944488525,
      "learning_rate": 4.4991963949421576e-05,
      "loss": 0.42335220336914064,
      "step": 13450
    },
    {
      "epoch": 16.34403391883707,
      "grad_norm": 55.872650146484375,
      "learning_rate": 4.491138821630347e-05,
      "loss": 0.4417982482910156,
      "step": 13500
    },
    {
      "epoch": 16.34403391883707,
      "eval_loss": 0.6052221059799194,
      "eval_mean_accuracy": 0.6021209230753326,
      "eval_mean_iou": 0.4164211241165103,
      "eval_overall_accuracy": 0.8476711207221993,
      "eval_runtime": 287.6087,
      "eval_samples_per_second": 3.418,
      "eval_steps_per_second": 3.418,
      "step": 13500
    },
    {
      "epoch": 16.404603270745003,
      "grad_norm": 5.300965785980225,
      "learning_rate": 4.483081248318536e-05,
      "loss": 0.438841438293457,
      "step": 13550
    },
    {
      "epoch": 16.465172622652936,
      "grad_norm": 11.12307357788086,
      "learning_rate": 4.4750236750067254e-05,
      "loss": 0.4417016220092773,
      "step": 13600
    },
    {
      "epoch": 16.525741974560873,
      "grad_norm": 6.111608505249023,
      "learning_rate": 4.466966101694915e-05,
      "loss": 0.4547676467895508,
      "step": 13650
    },
    {
      "epoch": 16.586311326468806,
      "grad_norm": 1.8486167192459106,
      "learning_rate": 4.458908528383105e-05,
      "loss": 0.41504501342773437,
      "step": 13700
    },
    {
      "epoch": 16.646880678376743,
      "grad_norm": 1.446486234664917,
      "learning_rate": 4.4508509550712945e-05,
      "loss": 0.42012935638427734,
      "step": 13750
    },
    {
      "epoch": 16.707450030284676,
      "grad_norm": 3.5717194080352783,
      "learning_rate": 4.442793381759484e-05,
      "loss": 0.41256610870361327,
      "step": 13800
    },
    {
      "epoch": 16.76801938219261,
      "grad_norm": 2.772542953491211,
      "learning_rate": 4.434735808447673e-05,
      "loss": 0.391695556640625,
      "step": 13850
    },
    {
      "epoch": 16.828588734100546,
      "grad_norm": 6.335010051727295,
      "learning_rate": 4.4268393866020985e-05,
      "loss": 0.41519420623779296,
      "step": 13900
    },
    {
      "epoch": 16.88915808600848,
      "grad_norm": 1.99122953414917,
      "learning_rate": 4.418781813290288e-05,
      "loss": 0.3883670425415039,
      "step": 13950
    },
    {
      "epoch": 16.949727437916415,
      "grad_norm": 1.8787728548049927,
      "learning_rate": 4.410724239978478e-05,
      "loss": 0.4299320602416992,
      "step": 14000
    },
    {
      "epoch": 16.949727437916415,
      "eval_loss": 0.7442893981933594,
      "eval_mean_accuracy": 0.6141360876094246,
      "eval_mean_iou": 0.41809632261586477,
      "eval_overall_accuracy": 0.8428586259378179,
      "eval_runtime": 283.3284,
      "eval_samples_per_second": 3.469,
      "eval_steps_per_second": 3.469,
      "step": 14000
    },
    {
      "epoch": 17.009691096305268,
      "grad_norm": 7.253711700439453,
      "learning_rate": 4.402666666666667e-05,
      "loss": 0.44975929260253905,
      "step": 14050
    },
    {
      "epoch": 17.070260448213205,
      "grad_norm": 2.0228374004364014,
      "learning_rate": 4.394609093354856e-05,
      "loss": 0.41769508361816404,
      "step": 14100
    },
    {
      "epoch": 17.130829800121138,
      "grad_norm": 12.929971694946289,
      "learning_rate": 4.3865515200430455e-05,
      "loss": 0.45973686218261717,
      "step": 14150
    },
    {
      "epoch": 17.191399152029074,
      "grad_norm": 3.1418135166168213,
      "learning_rate": 4.3784939467312354e-05,
      "loss": 0.42566165924072263,
      "step": 14200
    },
    {
      "epoch": 17.251968503937007,
      "grad_norm": 5.333899021148682,
      "learning_rate": 4.370436373419425e-05,
      "loss": 0.38755359649658205,
      "step": 14250
    },
    {
      "epoch": 17.312537855844944,
      "grad_norm": 5.068349361419678,
      "learning_rate": 4.362378800107614e-05,
      "loss": 0.4074580383300781,
      "step": 14300
    },
    {
      "epoch": 17.373107207752877,
      "grad_norm": 2.2984111309051514,
      "learning_rate": 4.354321226795803e-05,
      "loss": 0.4227134704589844,
      "step": 14350
    },
    {
      "epoch": 17.43367655966081,
      "grad_norm": 3.4528772830963135,
      "learning_rate": 4.3462636534839925e-05,
      "loss": 0.4012803649902344,
      "step": 14400
    },
    {
      "epoch": 17.494245911568747,
      "grad_norm": 4.446135997772217,
      "learning_rate": 4.338206080172182e-05,
      "loss": 0.43346633911132815,
      "step": 14450
    },
    {
      "epoch": 17.55481526347668,
      "grad_norm": 5.221648693084717,
      "learning_rate": 4.330148506860371e-05,
      "loss": 0.4277055740356445,
      "step": 14500
    },
    {
      "epoch": 17.55481526347668,
      "eval_loss": 0.6673077940940857,
      "eval_mean_accuracy": 0.6084933462568475,
      "eval_mean_iou": 0.4228516586660048,
      "eval_overall_accuracy": 0.8410085714966938,
      "eval_runtime": 283.3493,
      "eval_samples_per_second": 3.469,
      "eval_steps_per_second": 3.469,
      "step": 14500
    },
    {
      "epoch": 17.615384615384617,
      "grad_norm": 1.739767074584961,
      "learning_rate": 4.32209093354856e-05,
      "loss": 0.4066457748413086,
      "step": 14550
    },
    {
      "epoch": 17.67595396729255,
      "grad_norm": 4.032736301422119,
      "learning_rate": 4.31403336023675e-05,
      "loss": 0.39471778869628904,
      "step": 14600
    },
    {
      "epoch": 17.736523319200483,
      "grad_norm": 2.8934543132781982,
      "learning_rate": 4.3059757869249395e-05,
      "loss": 0.41123485565185547,
      "step": 14650
    },
    {
      "epoch": 17.79709267110842,
      "grad_norm": 2.5725021362304688,
      "learning_rate": 4.297918213613129e-05,
      "loss": 0.42919898986816407,
      "step": 14700
    },
    {
      "epoch": 17.857662023016353,
      "grad_norm": 7.817962169647217,
      "learning_rate": 4.289860640301318e-05,
      "loss": 0.38820419311523435,
      "step": 14750
    },
    {
      "epoch": 17.91823137492429,
      "grad_norm": 3.331134796142578,
      "learning_rate": 4.2818030669895086e-05,
      "loss": 0.4176339340209961,
      "step": 14800
    },
    {
      "epoch": 17.978800726832223,
      "grad_norm": 16.011343002319336,
      "learning_rate": 4.273745493677698e-05,
      "loss": 0.43086498260498046,
      "step": 14850
    },
    {
      "epoch": 18.03876438522108,
      "grad_norm": 4.8953447341918945,
      "learning_rate": 4.265687920365887e-05,
      "loss": 0.40810771942138674,
      "step": 14900
    },
    {
      "epoch": 18.09933373712901,
      "grad_norm": 3.049375534057617,
      "learning_rate": 4.2576303470540764e-05,
      "loss": 0.41845008850097654,
      "step": 14950
    },
    {
      "epoch": 18.15990308903695,
      "grad_norm": 2.9128339290618896,
      "learning_rate": 4.2495727737422656e-05,
      "loss": 0.376291389465332,
      "step": 15000
    },
    {
      "epoch": 18.15990308903695,
      "eval_loss": 0.7105162739753723,
      "eval_mean_accuracy": 0.6010634285914721,
      "eval_mean_iou": 0.4209376247002053,
      "eval_overall_accuracy": 0.8366031743745231,
      "eval_runtime": 280.6483,
      "eval_samples_per_second": 3.503,
      "eval_steps_per_second": 3.503,
      "step": 15000
    },
    {
      "epoch": 18.22047244094488,
      "grad_norm": 2.3593742847442627,
      "learning_rate": 4.241515200430455e-05,
      "loss": 0.37719871520996096,
      "step": 15050
    },
    {
      "epoch": 18.281041792852818,
      "grad_norm": 8.342509269714355,
      "learning_rate": 4.233457627118644e-05,
      "loss": 0.4032138442993164,
      "step": 15100
    },
    {
      "epoch": 18.34161114476075,
      "grad_norm": 4.246118545532227,
      "learning_rate": 4.2254000538068334e-05,
      "loss": 0.3911207962036133,
      "step": 15150
    },
    {
      "epoch": 18.402180496668684,
      "grad_norm": 3.1580276489257812,
      "learning_rate": 4.217342480495023e-05,
      "loss": 0.41167678833007815,
      "step": 15200
    },
    {
      "epoch": 18.46274984857662,
      "grad_norm": 1.5438461303710938,
      "learning_rate": 4.209284907183212e-05,
      "loss": 0.36333744049072264,
      "step": 15250
    },
    {
      "epoch": 18.523319200484554,
      "grad_norm": 2.1575703620910645,
      "learning_rate": 4.201227333871401e-05,
      "loss": 0.4030564117431641,
      "step": 15300
    },
    {
      "epoch": 18.58388855239249,
      "grad_norm": 1.6958742141723633,
      "learning_rate": 4.193169760559591e-05,
      "loss": 0.39092216491699217,
      "step": 15350
    },
    {
      "epoch": 18.644457904300424,
      "grad_norm": 2.3419246673583984,
      "learning_rate": 4.1851121872477804e-05,
      "loss": 0.4175635528564453,
      "step": 15400
    },
    {
      "epoch": 18.705027256208357,
      "grad_norm": 6.0768351554870605,
      "learning_rate": 4.1770546139359703e-05,
      "loss": 0.4287725830078125,
      "step": 15450
    },
    {
      "epoch": 18.765596608116294,
      "grad_norm": 4.9186482429504395,
      "learning_rate": 4.1689970406241596e-05,
      "loss": 0.42941516876220703,
      "step": 15500
    },
    {
      "epoch": 18.765596608116294,
      "eval_loss": 0.579609751701355,
      "eval_mean_accuracy": 0.6044645760434061,
      "eval_mean_iou": 0.39893579535998824,
      "eval_overall_accuracy": 0.8539829506393851,
      "eval_runtime": 281.2563,
      "eval_samples_per_second": 3.495,
      "eval_steps_per_second": 3.495,
      "step": 15500
    },
    {
      "epoch": 18.826165960024227,
      "grad_norm": 2.989607572555542,
      "learning_rate": 4.1609394673123495e-05,
      "loss": 0.44035804748535157,
      "step": 15550
    },
    {
      "epoch": 18.886735311932163,
      "grad_norm": 2.5001730918884277,
      "learning_rate": 4.152881894000539e-05,
      "loss": 0.42020133972167967,
      "step": 15600
    },
    {
      "epoch": 18.947304663840097,
      "grad_norm": 3.074111223220825,
      "learning_rate": 4.144824320688728e-05,
      "loss": 0.42492027282714845,
      "step": 15650
    },
    {
      "epoch": 19.007268322228953,
      "grad_norm": 5.545541286468506,
      "learning_rate": 4.136766747376917e-05,
      "loss": 0.4021272659301758,
      "step": 15700
    },
    {
      "epoch": 19.067837674136886,
      "grad_norm": 2.0913333892822266,
      "learning_rate": 4.1287091740651066e-05,
      "loss": 0.3633819580078125,
      "step": 15750
    },
    {
      "epoch": 19.128407026044822,
      "grad_norm": 1.4524219036102295,
      "learning_rate": 4.120651600753296e-05,
      "loss": 0.3992879867553711,
      "step": 15800
    },
    {
      "epoch": 19.188976377952756,
      "grad_norm": 3.1111106872558594,
      "learning_rate": 4.112594027441485e-05,
      "loss": 0.42997955322265624,
      "step": 15850
    },
    {
      "epoch": 19.249545729860692,
      "grad_norm": 1.8217402696609497,
      "learning_rate": 4.1045364541296744e-05,
      "loss": 0.40551464080810545,
      "step": 15900
    },
    {
      "epoch": 19.310115081768625,
      "grad_norm": 1.5562562942504883,
      "learning_rate": 4.0964788808178636e-05,
      "loss": 0.4019059753417969,
      "step": 15950
    },
    {
      "epoch": 19.37068443367656,
      "grad_norm": 5.0578107833862305,
      "learning_rate": 4.088421307506053e-05,
      "loss": 0.38102046966552733,
      "step": 16000
    },
    {
      "epoch": 19.37068443367656,
      "eval_loss": 0.6386463046073914,
      "eval_mean_accuracy": 0.5965329223307291,
      "eval_mean_iou": 0.39724198849702175,
      "eval_overall_accuracy": 0.8474661438050372,
      "eval_runtime": 283.8688,
      "eval_samples_per_second": 3.463,
      "eval_steps_per_second": 3.463,
      "step": 16000
    },
    {
      "epoch": 19.431253785584495,
      "grad_norm": 1.6012992858886719,
      "learning_rate": 4.080524885660479e-05,
      "loss": 0.4046123504638672,
      "step": 16050
    },
    {
      "epoch": 19.49182313749243,
      "grad_norm": 2.6146976947784424,
      "learning_rate": 4.072467312348668e-05,
      "loss": 0.38259010314941405,
      "step": 16100
    },
    {
      "epoch": 19.552392489400365,
      "grad_norm": 3.1443209648132324,
      "learning_rate": 4.0644097390368576e-05,
      "loss": 0.3901312637329102,
      "step": 16150
    },
    {
      "epoch": 19.612961841308298,
      "grad_norm": 1.663704752922058,
      "learning_rate": 4.056352165725047e-05,
      "loss": 0.3905612564086914,
      "step": 16200
    },
    {
      "epoch": 19.67353119321623,
      "grad_norm": 2.1245336532592773,
      "learning_rate": 4.048294592413237e-05,
      "loss": 0.398807373046875,
      "step": 16250
    },
    {
      "epoch": 19.734100545124168,
      "grad_norm": 1.0681880712509155,
      "learning_rate": 4.040237019101426e-05,
      "loss": 0.4014078903198242,
      "step": 16300
    },
    {
      "epoch": 19.7946698970321,
      "grad_norm": 4.309301376342773,
      "learning_rate": 4.032179445789615e-05,
      "loss": 0.39651199340820314,
      "step": 16350
    },
    {
      "epoch": 19.855239248940038,
      "grad_norm": 4.628543376922607,
      "learning_rate": 4.0241218724778045e-05,
      "loss": 0.382839241027832,
      "step": 16400
    },
    {
      "epoch": 19.91580860084797,
      "grad_norm": 4.2588677406311035,
      "learning_rate": 4.0160642991659945e-05,
      "loss": 0.42120708465576173,
      "step": 16450
    },
    {
      "epoch": 19.976377952755904,
      "grad_norm": 3.292454719543457,
      "learning_rate": 4.008006725854184e-05,
      "loss": 0.38514102935791017,
      "step": 16500
    },
    {
      "epoch": 19.976377952755904,
      "eval_loss": 0.6598678827285767,
      "eval_mean_accuracy": 0.6018577837728409,
      "eval_mean_iou": 0.39474188459369103,
      "eval_overall_accuracy": 0.8423729059291153,
      "eval_runtime": 285.1926,
      "eval_samples_per_second": 3.447,
      "eval_steps_per_second": 3.447,
      "step": 16500
    },
    {
      "epoch": 20.03634161114476,
      "grad_norm": 11.473953247070312,
      "learning_rate": 3.999949152542373e-05,
      "loss": 0.39464908599853515,
      "step": 16550
    },
    {
      "epoch": 20.096910963052697,
      "grad_norm": 1.3502283096313477,
      "learning_rate": 3.991891579230563e-05,
      "loss": 0.40976207733154296,
      "step": 16600
    },
    {
      "epoch": 20.15748031496063,
      "grad_norm": 1.7216973304748535,
      "learning_rate": 3.983834005918752e-05,
      "loss": 0.38120704650878906,
      "step": 16650
    },
    {
      "epoch": 20.218049666868563,
      "grad_norm": 2.7183268070220947,
      "learning_rate": 3.9757764326069415e-05,
      "loss": 0.3900305938720703,
      "step": 16700
    },
    {
      "epoch": 20.2786190187765,
      "grad_norm": 14.12258529663086,
      "learning_rate": 3.967718859295131e-05,
      "loss": 0.41102649688720705,
      "step": 16750
    },
    {
      "epoch": 20.339188370684433,
      "grad_norm": 2.214542865753174,
      "learning_rate": 3.95966128598332e-05,
      "loss": 0.37899471282958985,
      "step": 16800
    },
    {
      "epoch": 20.39975772259237,
      "grad_norm": 1.981465220451355,
      "learning_rate": 3.951603712671509e-05,
      "loss": 0.35976707458496093,
      "step": 16850
    },
    {
      "epoch": 20.460327074500302,
      "grad_norm": 5.62539005279541,
      "learning_rate": 3.9435461393596985e-05,
      "loss": 0.3825069808959961,
      "step": 16900
    },
    {
      "epoch": 20.52089642640824,
      "grad_norm": 5.854732513427734,
      "learning_rate": 3.935488566047888e-05,
      "loss": 0.359818115234375,
      "step": 16950
    },
    {
      "epoch": 20.581465778316172,
      "grad_norm": 4.441317558288574,
      "learning_rate": 3.927430992736077e-05,
      "loss": 0.3823358154296875,
      "step": 17000
    },
    {
      "epoch": 20.581465778316172,
      "eval_loss": 0.5734493136405945,
      "eval_mean_accuracy": 0.5975151990314479,
      "eval_mean_iou": 0.4172015302251768,
      "eval_overall_accuracy": 0.8548973758732435,
      "eval_runtime": 307.7071,
      "eval_samples_per_second": 3.195,
      "eval_steps_per_second": 3.195,
      "step": 17000
    },
    {
      "epoch": 20.642035130224105,
      "grad_norm": 7.981947422027588,
      "learning_rate": 3.919373419424267e-05,
      "loss": 0.4208950424194336,
      "step": 17050
    },
    {
      "epoch": 20.702604482132042,
      "grad_norm": 6.8927717208862305,
      "learning_rate": 3.911315846112456e-05,
      "loss": 0.3993868637084961,
      "step": 17100
    },
    {
      "epoch": 20.763173834039975,
      "grad_norm": 3.2990024089813232,
      "learning_rate": 3.9032582728006455e-05,
      "loss": 0.40430225372314454,
      "step": 17150
    },
    {
      "epoch": 20.82374318594791,
      "grad_norm": 2.902902364730835,
      "learning_rate": 3.8952006994888354e-05,
      "loss": 0.3780899429321289,
      "step": 17200
    },
    {
      "epoch": 20.884312537855845,
      "grad_norm": 1.4550354480743408,
      "learning_rate": 3.8871431261770254e-05,
      "loss": 0.39962791442871093,
      "step": 17250
    },
    {
      "epoch": 20.944881889763778,
      "grad_norm": 5.362315654754639,
      "learning_rate": 3.8790855528652146e-05,
      "loss": 0.40997249603271485,
      "step": 17300
    },
    {
      "epoch": 21.004845548152634,
      "grad_norm": 2.1672325134277344,
      "learning_rate": 3.871027979553404e-05,
      "loss": 0.39405975341796873,
      "step": 17350
    },
    {
      "epoch": 21.06541490006057,
      "grad_norm": 2.5248355865478516,
      "learning_rate": 3.862970406241593e-05,
      "loss": 0.3798117446899414,
      "step": 17400
    },
    {
      "epoch": 21.125984251968504,
      "grad_norm": 4.731898784637451,
      "learning_rate": 3.8549128329297824e-05,
      "loss": 0.37866085052490234,
      "step": 17450
    },
    {
      "epoch": 21.186553603876437,
      "grad_norm": 3.721503257751465,
      "learning_rate": 3.846855259617972e-05,
      "loss": 0.36331092834472656,
      "step": 17500
    },
    {
      "epoch": 21.186553603876437,
      "eval_loss": 0.5954183340072632,
      "eval_mean_accuracy": 0.6240506068379776,
      "eval_mean_iou": 0.43509469013710644,
      "eval_overall_accuracy": 0.8517231131133568,
      "eval_runtime": 287.3226,
      "eval_samples_per_second": 3.421,
      "eval_steps_per_second": 3.421,
      "step": 17500
    },
    {
      "epoch": 21.247122955784373,
      "grad_norm": 2.5386176109313965,
      "learning_rate": 3.838797686306161e-05,
      "loss": 0.3651810455322266,
      "step": 17550
    },
    {
      "epoch": 21.307692307692307,
      "grad_norm": 2.1145660877227783,
      "learning_rate": 3.83074011299435e-05,
      "loss": 0.36630859375,
      "step": 17600
    },
    {
      "epoch": 21.368261659600243,
      "grad_norm": 4.646767616271973,
      "learning_rate": 3.8226825396825395e-05,
      "loss": 0.36617637634277345,
      "step": 17650
    },
    {
      "epoch": 21.428831011508176,
      "grad_norm": 3.2425453662872314,
      "learning_rate": 3.814624966370729e-05,
      "loss": 0.3767844772338867,
      "step": 17700
    },
    {
      "epoch": 21.489400363416113,
      "grad_norm": 2.813601016998291,
      "learning_rate": 3.806567393058918e-05,
      "loss": 0.3863559341430664,
      "step": 17750
    },
    {
      "epoch": 21.549969715324046,
      "grad_norm": 2.8794474601745605,
      "learning_rate": 3.798509819747107e-05,
      "loss": 0.37288249969482423,
      "step": 17800
    },
    {
      "epoch": 21.61053906723198,
      "grad_norm": 3.2102341651916504,
      "learning_rate": 3.790452246435298e-05,
      "loss": 0.3927457809448242,
      "step": 17850
    },
    {
      "epoch": 21.671108419139916,
      "grad_norm": 4.949087142944336,
      "learning_rate": 3.782394673123487e-05,
      "loss": 0.3638539505004883,
      "step": 17900
    },
    {
      "epoch": 21.73167777104785,
      "grad_norm": 2.160534143447876,
      "learning_rate": 3.7743370998116764e-05,
      "loss": 0.3901234817504883,
      "step": 17950
    },
    {
      "epoch": 21.792247122955786,
      "grad_norm": 4.239755153656006,
      "learning_rate": 3.766279526499866e-05,
      "loss": 0.37983509063720705,
      "step": 18000
    },
    {
      "epoch": 21.792247122955786,
      "eval_loss": 0.6973466873168945,
      "eval_mean_accuracy": 0.6161663644965661,
      "eval_mean_iou": 0.4279874605004556,
      "eval_overall_accuracy": 0.8394168143597406,
      "eval_runtime": 292.2371,
      "eval_samples_per_second": 3.364,
      "eval_steps_per_second": 3.364,
      "step": 18000
    },
    {
      "epoch": 21.85281647486372,
      "grad_norm": 2.481170177459717,
      "learning_rate": 3.7582219531880556e-05,
      "loss": 0.3634402465820312,
      "step": 18050
    },
    {
      "epoch": 21.913385826771652,
      "grad_norm": 2.6498970985412598,
      "learning_rate": 3.750164379876245e-05,
      "loss": 0.3802936553955078,
      "step": 18100
    },
    {
      "epoch": 21.97395517867959,
      "grad_norm": 2.6994121074676514,
      "learning_rate": 3.74226795803067e-05,
      "loss": 0.41730953216552735,
      "step": 18150
    },
    {
      "epoch": 22.033918837068445,
      "grad_norm": 2.8404502868652344,
      "learning_rate": 3.7342103847188596e-05,
      "loss": 0.381531867980957,
      "step": 18200
    },
    {
      "epoch": 22.094488188976378,
      "grad_norm": 1.3999656438827515,
      "learning_rate": 3.726152811407049e-05,
      "loss": 0.36839488983154295,
      "step": 18250
    },
    {
      "epoch": 22.15505754088431,
      "grad_norm": 5.472549915313721,
      "learning_rate": 3.718095238095238e-05,
      "loss": 0.37150863647460936,
      "step": 18300
    },
    {
      "epoch": 22.215626892792248,
      "grad_norm": 2.486685276031494,
      "learning_rate": 3.710037664783428e-05,
      "loss": 0.3590965270996094,
      "step": 18350
    },
    {
      "epoch": 22.27619624470018,
      "grad_norm": 1.5680561065673828,
      "learning_rate": 3.701980091471617e-05,
      "loss": 0.392275390625,
      "step": 18400
    },
    {
      "epoch": 22.336765596608117,
      "grad_norm": 2.349472999572754,
      "learning_rate": 3.6939225181598065e-05,
      "loss": 0.3744913864135742,
      "step": 18450
    },
    {
      "epoch": 22.39733494851605,
      "grad_norm": 3.7591493129730225,
      "learning_rate": 3.685864944847996e-05,
      "loss": 0.3775429153442383,
      "step": 18500
    },
    {
      "epoch": 22.39733494851605,
      "eval_loss": 0.64874267578125,
      "eval_mean_accuracy": 0.6163678091662669,
      "eval_mean_iou": 0.42107481767743965,
      "eval_overall_accuracy": 0.8450640409669459,
      "eval_runtime": 285.698,
      "eval_samples_per_second": 3.441,
      "eval_steps_per_second": 3.441,
      "step": 18500
    },
    {
      "epoch": 22.457904300423987,
      "grad_norm": 1.846319556236267,
      "learning_rate": 3.677807371536185e-05,
      "loss": 0.35733360290527344,
      "step": 18550
    },
    {
      "epoch": 22.51847365233192,
      "grad_norm": 5.478713512420654,
      "learning_rate": 3.669749798224374e-05,
      "loss": 0.3962455368041992,
      "step": 18600
    },
    {
      "epoch": 22.579043004239853,
      "grad_norm": 4.905972957611084,
      "learning_rate": 3.6616922249125636e-05,
      "loss": 0.3627265167236328,
      "step": 18650
    },
    {
      "epoch": 22.63961235614779,
      "grad_norm": 2.2309823036193848,
      "learning_rate": 3.6536346516007535e-05,
      "loss": 0.3920730209350586,
      "step": 18700
    },
    {
      "epoch": 22.700181708055723,
      "grad_norm": 8.00723934173584,
      "learning_rate": 3.645577078288943e-05,
      "loss": 0.3663540267944336,
      "step": 18750
    },
    {
      "epoch": 22.76075105996366,
      "grad_norm": 3.516033887863159,
      "learning_rate": 3.637519504977132e-05,
      "loss": 0.38920372009277343,
      "step": 18800
    },
    {
      "epoch": 22.821320411871593,
      "grad_norm": 3.791245698928833,
      "learning_rate": 3.629461931665321e-05,
      "loss": 0.35373085021972656,
      "step": 18850
    },
    {
      "epoch": 22.881889763779526,
      "grad_norm": 5.539220809936523,
      "learning_rate": 3.621404358353511e-05,
      "loss": 0.37609874725341796,
      "step": 18900
    },
    {
      "epoch": 22.942459115687463,
      "grad_norm": 5.371774673461914,
      "learning_rate": 3.6133467850417005e-05,
      "loss": 0.3829318618774414,
      "step": 18950
    },
    {
      "epoch": 23.00242277407632,
      "grad_norm": 1.7402585744857788,
      "learning_rate": 3.6052892117298904e-05,
      "loss": 0.3479228210449219,
      "step": 19000
    },
    {
      "epoch": 23.00242277407632,
      "eval_loss": 0.6718619465827942,
      "eval_mean_accuracy": 0.5882203830467491,
      "eval_mean_iou": 0.42230874901363735,
      "eval_overall_accuracy": 0.8477964352736759,
      "eval_runtime": 289.144,
      "eval_samples_per_second": 3.4,
      "eval_steps_per_second": 3.4,
      "step": 19000
    },
    {
      "epoch": 23.062992125984252,
      "grad_norm": 1.4099360704421997,
      "learning_rate": 3.59723163841808e-05,
      "loss": 0.3625748062133789,
      "step": 19050
    },
    {
      "epoch": 23.123561477892185,
      "grad_norm": 5.2136006355285645,
      "learning_rate": 3.589174065106269e-05,
      "loss": 0.3645480728149414,
      "step": 19100
    },
    {
      "epoch": 23.18413082980012,
      "grad_norm": 3.916476011276245,
      "learning_rate": 3.581116491794458e-05,
      "loss": 0.3572180557250977,
      "step": 19150
    },
    {
      "epoch": 23.244700181708055,
      "grad_norm": 4.132971286773682,
      "learning_rate": 3.5730589184826475e-05,
      "loss": 0.3978551483154297,
      "step": 19200
    },
    {
      "epoch": 23.30526953361599,
      "grad_norm": 2.56463360786438,
      "learning_rate": 3.565001345170837e-05,
      "loss": 0.3530033874511719,
      "step": 19250
    },
    {
      "epoch": 23.365838885523925,
      "grad_norm": 2.333172559738159,
      "learning_rate": 3.556943771859026e-05,
      "loss": 0.3648196029663086,
      "step": 19300
    },
    {
      "epoch": 23.42640823743186,
      "grad_norm": 9.04494571685791,
      "learning_rate": 3.548886198547215e-05,
      "loss": 0.36609691619873047,
      "step": 19350
    },
    {
      "epoch": 23.486977589339794,
      "grad_norm": 1.665069818496704,
      "learning_rate": 3.5408286252354045e-05,
      "loss": 0.3829759979248047,
      "step": 19400
    },
    {
      "epoch": 23.547546941247727,
      "grad_norm": 2.4219372272491455,
      "learning_rate": 3.532771051923594e-05,
      "loss": 0.36355789184570314,
      "step": 19450
    },
    {
      "epoch": 23.608116293155664,
      "grad_norm": 3.4767658710479736,
      "learning_rate": 3.524713478611784e-05,
      "loss": 0.32870265960693357,
      "step": 19500
    },
    {
      "epoch": 23.608116293155664,
      "eval_loss": 0.7129581570625305,
      "eval_mean_accuracy": 0.6068413423648235,
      "eval_mean_iou": 0.4018894486474589,
      "eval_overall_accuracy": 0.8445464218620852,
      "eval_runtime": 284.1792,
      "eval_samples_per_second": 3.459,
      "eval_steps_per_second": 3.459,
      "step": 19500
    },
    {
      "epoch": 23.668685645063597,
      "grad_norm": 8.767248153686523,
      "learning_rate": 3.516655905299973e-05,
      "loss": 0.35654972076416014,
      "step": 19550
    },
    {
      "epoch": 23.729254996971534,
      "grad_norm": 1.8854658603668213,
      "learning_rate": 3.508598331988163e-05,
      "loss": 0.3849988174438477,
      "step": 19600
    },
    {
      "epoch": 23.789824348879467,
      "grad_norm": 7.549427509307861,
      "learning_rate": 3.500540758676352e-05,
      "loss": 0.3564308547973633,
      "step": 19650
    },
    {
      "epoch": 23.8503937007874,
      "grad_norm": 1.338281273841858,
      "learning_rate": 3.492483185364542e-05,
      "loss": 0.36706947326660155,
      "step": 19700
    },
    {
      "epoch": 23.910963052695337,
      "grad_norm": 2.193523406982422,
      "learning_rate": 3.4844256120527314e-05,
      "loss": 0.3384686279296875,
      "step": 19750
    },
    {
      "epoch": 23.97153240460327,
      "grad_norm": 9.936964988708496,
      "learning_rate": 3.4763680387409207e-05,
      "loss": 0.3800687789916992,
      "step": 19800
    },
    {
      "epoch": 24.031496062992126,
      "grad_norm": 2.617741584777832,
      "learning_rate": 3.46831046542911e-05,
      "loss": 0.3456541061401367,
      "step": 19850
    },
    {
      "epoch": 24.09206541490006,
      "grad_norm": 5.653164863586426,
      "learning_rate": 3.460252892117299e-05,
      "loss": 0.3626657485961914,
      "step": 19900
    },
    {
      "epoch": 24.152634766807996,
      "grad_norm": 2.788191556930542,
      "learning_rate": 3.4521953188054884e-05,
      "loss": 0.3638998794555664,
      "step": 19950
    },
    {
      "epoch": 24.21320411871593,
      "grad_norm": 1.8451497554779053,
      "learning_rate": 3.444137745493678e-05,
      "loss": 0.34463001251220704,
      "step": 20000
    },
    {
      "epoch": 24.21320411871593,
      "eval_loss": 0.8639175295829773,
      "eval_mean_accuracy": 0.6135849261738452,
      "eval_mean_iou": 0.3969121160468183,
      "eval_overall_accuracy": 0.8315608974390816,
      "eval_runtime": 287.2698,
      "eval_samples_per_second": 3.422,
      "eval_steps_per_second": 3.422,
      "step": 20000
    },
    {
      "epoch": 24.273773470623865,
      "grad_norm": 3.5833070278167725,
      "learning_rate": 3.436080172181867e-05,
      "loss": 0.4027736663818359,
      "step": 20050
    },
    {
      "epoch": 24.3343428225318,
      "grad_norm": 2.442446231842041,
      "learning_rate": 3.428022598870056e-05,
      "loss": 0.37819202423095705,
      "step": 20100
    },
    {
      "epoch": 24.39491217443973,
      "grad_norm": 3.6887941360473633,
      "learning_rate": 3.4199650255582455e-05,
      "loss": 0.3294095611572266,
      "step": 20150
    },
    {
      "epoch": 24.45548152634767,
      "grad_norm": 4.770366668701172,
      "learning_rate": 3.4119074522464354e-05,
      "loss": 0.3650230407714844,
      "step": 20200
    },
    {
      "epoch": 24.5160508782556,
      "grad_norm": 1.873148798942566,
      "learning_rate": 3.403849878934625e-05,
      "loss": 0.3476858901977539,
      "step": 20250
    },
    {
      "epoch": 24.576620230163538,
      "grad_norm": 5.330074310302734,
      "learning_rate": 3.3957923056228146e-05,
      "loss": 0.34717086791992186,
      "step": 20300
    },
    {
      "epoch": 24.63718958207147,
      "grad_norm": 4.278451919555664,
      "learning_rate": 3.387734732311004e-05,
      "loss": 0.35513957977294924,
      "step": 20350
    },
    {
      "epoch": 24.697758933979408,
      "grad_norm": 3.2287113666534424,
      "learning_rate": 3.379677158999193e-05,
      "loss": 0.35718807220458987,
      "step": 20400
    },
    {
      "epoch": 24.75832828588734,
      "grad_norm": 6.114763259887695,
      "learning_rate": 3.3716195856873824e-05,
      "loss": 0.3762051773071289,
      "step": 20450
    },
    {
      "epoch": 24.818897637795274,
      "grad_norm": 7.0199174880981445,
      "learning_rate": 3.363562012375572e-05,
      "loss": 0.3620168685913086,
      "step": 20500
    },
    {
      "epoch": 24.818897637795274,
      "eval_loss": 0.8288655281066895,
      "eval_mean_accuracy": 0.615847083030191,
      "eval_mean_iou": 0.4021139181316675,
      "eval_overall_accuracy": 0.836035618825701,
      "eval_runtime": 296.1409,
      "eval_samples_per_second": 3.319,
      "eval_steps_per_second": 3.319,
      "step": 20500
    },
    {
      "epoch": 24.87946698970321,
      "grad_norm": 2.8710179328918457,
      "learning_rate": 3.3555044390637616e-05,
      "loss": 0.378134765625,
      "step": 20550
    },
    {
      "epoch": 24.940036341611144,
      "grad_norm": 2.1436619758605957,
      "learning_rate": 3.347446865751951e-05,
      "loss": 0.3563153076171875,
      "step": 20600
    },
    {
      "epoch": 25.0,
      "grad_norm": 1.3253333568572998,
      "learning_rate": 3.33938929244014e-05,
      "loss": 0.36692256927490235,
      "step": 20650
    },
    {
      "epoch": 25.060569351907933,
      "grad_norm": 3.652815341949463,
      "learning_rate": 3.3313317191283294e-05,
      "loss": 0.37071819305419923,
      "step": 20700
    },
    {
      "epoch": 25.12113870381587,
      "grad_norm": 14.720800399780273,
      "learning_rate": 3.3232741458165186e-05,
      "loss": 0.373232421875,
      "step": 20750
    },
    {
      "epoch": 25.181708055723803,
      "grad_norm": 3.883695363998413,
      "learning_rate": 3.315216572504708e-05,
      "loss": 0.3673044967651367,
      "step": 20800
    },
    {
      "epoch": 25.24227740763174,
      "grad_norm": 2.2784006595611572,
      "learning_rate": 3.307158999192898e-05,
      "loss": 0.35423797607421875,
      "step": 20850
    },
    {
      "epoch": 25.302846759539673,
      "grad_norm": 4.939656734466553,
      "learning_rate": 3.299101425881087e-05,
      "loss": 0.3454959106445312,
      "step": 20900
    },
    {
      "epoch": 25.363416111447606,
      "grad_norm": 3.0683233737945557,
      "learning_rate": 3.2910438525692764e-05,
      "loss": 0.377969856262207,
      "step": 20950
    },
    {
      "epoch": 25.423985463355542,
      "grad_norm": 4.771094799041748,
      "learning_rate": 3.2829862792574656e-05,
      "loss": 0.33915233612060547,
      "step": 21000
    },
    {
      "epoch": 25.423985463355542,
      "eval_loss": 0.7401325106620789,
      "eval_mean_accuracy": 0.6193717541737608,
      "eval_mean_iou": 0.37709757983078407,
      "eval_overall_accuracy": 0.8416690457752496,
      "eval_runtime": 287.5316,
      "eval_samples_per_second": 3.419,
      "eval_steps_per_second": 3.419,
      "step": 21000
    },
    {
      "epoch": 25.484554815263476,
      "grad_norm": 1.6546695232391357,
      "learning_rate": 3.2749287059456556e-05,
      "loss": 0.35225284576416016,
      "step": 21050
    },
    {
      "epoch": 25.545124167171412,
      "grad_norm": 4.423564910888672,
      "learning_rate": 3.266871132633845e-05,
      "loss": 0.3697775268554688,
      "step": 21100
    },
    {
      "epoch": 25.605693519079345,
      "grad_norm": 3.1827781200408936,
      "learning_rate": 3.258813559322034e-05,
      "loss": 0.3423880004882813,
      "step": 21150
    },
    {
      "epoch": 25.666262870987282,
      "grad_norm": 3.1165966987609863,
      "learning_rate": 3.2507559860102233e-05,
      "loss": 0.3497219467163086,
      "step": 21200
    },
    {
      "epoch": 25.726832222895215,
      "grad_norm": 3.0411417484283447,
      "learning_rate": 3.242698412698413e-05,
      "loss": 0.3732020950317383,
      "step": 21250
    },
    {
      "epoch": 25.787401574803148,
      "grad_norm": 7.326228141784668,
      "learning_rate": 3.2346408393866025e-05,
      "loss": 0.35768718719482423,
      "step": 21300
    },
    {
      "epoch": 25.847970926711085,
      "grad_norm": 3.119687795639038,
      "learning_rate": 3.226583266074792e-05,
      "loss": 0.3800459671020508,
      "step": 21350
    },
    {
      "epoch": 25.908540278619018,
      "grad_norm": 2.0276641845703125,
      "learning_rate": 3.218525692762981e-05,
      "loss": 0.3547634506225586,
      "step": 21400
    },
    {
      "epoch": 25.969109630526955,
      "grad_norm": 2.8040003776550293,
      "learning_rate": 3.210629270917407e-05,
      "loss": 0.38629974365234376,
      "step": 21450
    },
    {
      "epoch": 26.029073288915807,
      "grad_norm": 1.874464750289917,
      "learning_rate": 3.2025716976055965e-05,
      "loss": 0.32714683532714844,
      "step": 21500
    },
    {
      "epoch": 26.029073288915807,
      "eval_loss": 0.7094176411628723,
      "eval_mean_accuracy": 0.6137346198409703,
      "eval_mean_iou": 0.43129846840948255,
      "eval_overall_accuracy": 0.8490764039700296,
      "eval_runtime": 313.1843,
      "eval_samples_per_second": 3.139,
      "eval_steps_per_second": 3.139,
      "step": 21500
    },
    {
      "epoch": 26.089642640823744,
      "grad_norm": 2.2005414962768555,
      "learning_rate": 3.194514124293786e-05,
      "loss": 0.35215057373046876,
      "step": 21550
    },
    {
      "epoch": 26.150211992731677,
      "grad_norm": 4.992435932159424,
      "learning_rate": 3.186456550981975e-05,
      "loss": 0.3330351257324219,
      "step": 21600
    },
    {
      "epoch": 26.210781344639614,
      "grad_norm": 3.4890987873077393,
      "learning_rate": 3.178398977670164e-05,
      "loss": 0.3514311981201172,
      "step": 21650
    },
    {
      "epoch": 26.271350696547547,
      "grad_norm": 3.02673602104187,
      "learning_rate": 3.1703414043583535e-05,
      "loss": 0.35715259552001954,
      "step": 21700
    },
    {
      "epoch": 26.33192004845548,
      "grad_norm": 2.2663984298706055,
      "learning_rate": 3.162283831046543e-05,
      "loss": 0.3376564407348633,
      "step": 21750
    },
    {
      "epoch": 26.392489400363417,
      "grad_norm": 23.273757934570312,
      "learning_rate": 3.154226257734732e-05,
      "loss": 0.35576061248779295,
      "step": 21800
    },
    {
      "epoch": 26.45305875227135,
      "grad_norm": 2.034761428833008,
      "learning_rate": 3.146168684422921e-05,
      "loss": 0.3628903579711914,
      "step": 21850
    },
    {
      "epoch": 26.513628104179286,
      "grad_norm": 3.487765073776245,
      "learning_rate": 3.1381111111111106e-05,
      "loss": 0.3343524551391602,
      "step": 21900
    },
    {
      "epoch": 26.57419745608722,
      "grad_norm": 24.472389221191406,
      "learning_rate": 3.1300535377993005e-05,
      "loss": 0.35310726165771483,
      "step": 21950
    },
    {
      "epoch": 26.634766807995156,
      "grad_norm": 3.4211971759796143,
      "learning_rate": 3.1219959644874904e-05,
      "loss": 0.3341759490966797,
      "step": 22000
    },
    {
      "epoch": 26.634766807995156,
      "eval_loss": 0.752443253993988,
      "eval_mean_accuracy": 0.6289278278334198,
      "eval_mean_iou": 0.4335523353391155,
      "eval_overall_accuracy": 0.8441113057723487,
      "eval_runtime": 316.9954,
      "eval_samples_per_second": 3.101,
      "eval_steps_per_second": 3.101,
      "step": 22000
    },
    {
      "epoch": 26.69533615990309,
      "grad_norm": 2.7326653003692627,
      "learning_rate": 3.11393839117568e-05,
      "loss": 0.34648128509521486,
      "step": 22050
    },
    {
      "epoch": 26.755905511811022,
      "grad_norm": 4.200559616088867,
      "learning_rate": 3.105880817863869e-05,
      "loss": 0.345718994140625,
      "step": 22100
    },
    {
      "epoch": 26.81647486371896,
      "grad_norm": 1.9715721607208252,
      "learning_rate": 3.097823244552059e-05,
      "loss": 0.33680660247802735,
      "step": 22150
    },
    {
      "epoch": 26.877044215626892,
      "grad_norm": 5.045424938201904,
      "learning_rate": 3.089765671240248e-05,
      "loss": 0.34756362915039063,
      "step": 22200
    },
    {
      "epoch": 26.93761356753483,
      "grad_norm": 2.445322275161743,
      "learning_rate": 3.0817080979284374e-05,
      "loss": 0.3703696823120117,
      "step": 22250
    },
    {
      "epoch": 26.998182919442762,
      "grad_norm": 2.747668981552124,
      "learning_rate": 3.073650524616627e-05,
      "loss": 0.3422139739990234,
      "step": 22300
    },
    {
      "epoch": 27.058146577831618,
      "grad_norm": 1.9692065715789795,
      "learning_rate": 3.065592951304816e-05,
      "loss": 0.3253840637207031,
      "step": 22350
    },
    {
      "epoch": 27.11871592973955,
      "grad_norm": 2.275895833969116,
      "learning_rate": 3.057535377993005e-05,
      "loss": 0.3337688827514648,
      "step": 22400
    },
    {
      "epoch": 27.179285281647488,
      "grad_norm": 1.4794033765792847,
      "learning_rate": 3.0494778046811945e-05,
      "loss": 0.34665512084960937,
      "step": 22450
    },
    {
      "epoch": 27.23985463355542,
      "grad_norm": 8.062013626098633,
      "learning_rate": 3.041420231369384e-05,
      "loss": 0.33699932098388674,
      "step": 22500
    },
    {
      "epoch": 27.23985463355542,
      "eval_loss": 0.6876645684242249,
      "eval_mean_accuracy": 0.5910457060184013,
      "eval_mean_iou": 0.4209812572071636,
      "eval_overall_accuracy": 0.8475473739608501,
      "eval_runtime": 321.9533,
      "eval_samples_per_second": 3.053,
      "eval_steps_per_second": 3.053,
      "step": 22500
    },
    {
      "epoch": 27.300423985463354,
      "grad_norm": 7.7535529136657715,
      "learning_rate": 3.033362658057573e-05,
      "loss": 0.35081844329833983,
      "step": 22550
    },
    {
      "epoch": 27.36099333737129,
      "grad_norm": 2.3684403896331787,
      "learning_rate": 3.0253050847457622e-05,
      "loss": 0.33400276184082034,
      "step": 22600
    },
    {
      "epoch": 27.421562689279224,
      "grad_norm": 2.5027778148651123,
      "learning_rate": 3.017247511433951e-05,
      "loss": 0.34992275238037107,
      "step": 22650
    },
    {
      "epoch": 27.48213204118716,
      "grad_norm": 2.7222440242767334,
      "learning_rate": 3.0091899381221408e-05,
      "loss": 0.3484818649291992,
      "step": 22700
    },
    {
      "epoch": 27.542701393095093,
      "grad_norm": 1.6145477294921875,
      "learning_rate": 3.0011323648103304e-05,
      "loss": 0.3323840713500977,
      "step": 22750
    },
    {
      "epoch": 27.60327074500303,
      "grad_norm": 1.5698955059051514,
      "learning_rate": 2.9930747914985203e-05,
      "loss": 0.32903141021728516,
      "step": 22800
    },
    {
      "epoch": 27.663840096910963,
      "grad_norm": 4.249176025390625,
      "learning_rate": 2.9850172181867096e-05,
      "loss": 0.34513225555419924,
      "step": 22850
    },
    {
      "epoch": 27.724409448818896,
      "grad_norm": 2.280895709991455,
      "learning_rate": 2.9769596448748988e-05,
      "loss": 0.3522006988525391,
      "step": 22900
    },
    {
      "epoch": 27.784978800726833,
      "grad_norm": 4.59811544418335,
      "learning_rate": 2.968902071563088e-05,
      "loss": 0.3587569046020508,
      "step": 22950
    },
    {
      "epoch": 27.845548152634766,
      "grad_norm": 4.186275005340576,
      "learning_rate": 2.9608444982512773e-05,
      "loss": 0.34204097747802736,
      "step": 23000
    },
    {
      "epoch": 27.845548152634766,
      "eval_loss": 0.7763023376464844,
      "eval_mean_accuracy": 0.6034253314193191,
      "eval_mean_iou": 0.42102927418947167,
      "eval_overall_accuracy": 0.8425174220289849,
      "eval_runtime": 320.6569,
      "eval_samples_per_second": 3.066,
      "eval_steps_per_second": 3.066,
      "step": 23000
    },
    {
      "epoch": 27.906117504542703,
      "grad_norm": 3.081084966659546,
      "learning_rate": 2.9527869249394673e-05,
      "loss": 0.33790481567382813,
      "step": 23050
    },
    {
      "epoch": 27.966686856450636,
      "grad_norm": 4.58428430557251,
      "learning_rate": 2.944729351627657e-05,
      "loss": 0.3627011489868164,
      "step": 23100
    },
    {
      "epoch": 28.026650514839492,
      "grad_norm": 1.4968323707580566,
      "learning_rate": 2.936671778315846e-05,
      "loss": 0.3253172302246094,
      "step": 23150
    },
    {
      "epoch": 28.087219866747425,
      "grad_norm": 2.207340717315674,
      "learning_rate": 2.9286142050040354e-05,
      "loss": 0.3381285095214844,
      "step": 23200
    },
    {
      "epoch": 28.14778921865536,
      "grad_norm": 2.499228000640869,
      "learning_rate": 2.9205566316922247e-05,
      "loss": 0.36172096252441405,
      "step": 23250
    },
    {
      "epoch": 28.208358570563295,
      "grad_norm": 1.3094186782836914,
      "learning_rate": 2.912499058380414e-05,
      "loss": 0.3429043579101563,
      "step": 23300
    },
    {
      "epoch": 28.268927922471228,
      "grad_norm": 11.92502212524414,
      "learning_rate": 2.9044414850686032e-05,
      "loss": 0.3552719497680664,
      "step": 23350
    },
    {
      "epoch": 28.329497274379165,
      "grad_norm": 5.257513046264648,
      "learning_rate": 2.8963839117567935e-05,
      "loss": 0.35350887298583983,
      "step": 23400
    },
    {
      "epoch": 28.390066626287098,
      "grad_norm": 18.05130386352539,
      "learning_rate": 2.8883263384449827e-05,
      "loss": 0.338472900390625,
      "step": 23450
    },
    {
      "epoch": 28.450635978195034,
      "grad_norm": 2.7390828132629395,
      "learning_rate": 2.8804299165994082e-05,
      "loss": 0.34085655212402344,
      "step": 23500
    },
    {
      "epoch": 28.450635978195034,
      "eval_loss": 0.7159366011619568,
      "eval_mean_accuracy": 0.5932972601464364,
      "eval_mean_iou": 0.4242149275597781,
      "eval_overall_accuracy": 0.8472644576948754,
      "eval_runtime": 283.1167,
      "eval_samples_per_second": 3.472,
      "eval_steps_per_second": 3.472,
      "step": 23500
    },
    {
      "epoch": 28.511205330102968,
      "grad_norm": 2.279876232147217,
      "learning_rate": 2.8723723432875975e-05,
      "loss": 0.31336088180541993,
      "step": 23550
    },
    {
      "epoch": 28.571774682010904,
      "grad_norm": 1.9339780807495117,
      "learning_rate": 2.864314769975787e-05,
      "loss": 0.34511852264404297,
      "step": 23600
    },
    {
      "epoch": 28.632344033918837,
      "grad_norm": 3.1195662021636963,
      "learning_rate": 2.8562571966639763e-05,
      "loss": 0.3349901580810547,
      "step": 23650
    },
    {
      "epoch": 28.69291338582677,
      "grad_norm": 2.5410280227661133,
      "learning_rate": 2.8481996233521656e-05,
      "loss": 0.346126708984375,
      "step": 23700
    },
    {
      "epoch": 28.753482737734707,
      "grad_norm": 7.296370983123779,
      "learning_rate": 2.840142050040355e-05,
      "loss": 0.31694522857666013,
      "step": 23750
    },
    {
      "epoch": 28.81405208964264,
      "grad_norm": 1.2294292449951172,
      "learning_rate": 2.832084476728544e-05,
      "loss": 0.3504484176635742,
      "step": 23800
    },
    {
      "epoch": 28.874621441550577,
      "grad_norm": 2.9274685382843018,
      "learning_rate": 2.8240269034167334e-05,
      "loss": 0.33011924743652343,
      "step": 23850
    },
    {
      "epoch": 28.93519079345851,
      "grad_norm": 4.752707481384277,
      "learning_rate": 2.8159693301049236e-05,
      "loss": 0.3384727096557617,
      "step": 23900
    },
    {
      "epoch": 28.995760145366443,
      "grad_norm": 3.5815556049346924,
      "learning_rate": 2.807911756793113e-05,
      "loss": 0.3451510238647461,
      "step": 23950
    },
    {
      "epoch": 29.0557238037553,
      "grad_norm": 1.9744586944580078,
      "learning_rate": 2.799854183481302e-05,
      "loss": 0.35567283630371094,
      "step": 24000
    },
    {
      "epoch": 29.0557238037553,
      "eval_loss": 0.7035647034645081,
      "eval_mean_accuracy": 0.6183141268018255,
      "eval_mean_iou": 0.46626337785319927,
      "eval_overall_accuracy": 0.8455642746763337,
      "eval_runtime": 276.5557,
      "eval_samples_per_second": 3.554,
      "eval_steps_per_second": 3.554,
      "step": 24000
    },
    {
      "epoch": 29.116293155663236,
      "grad_norm": 2.149637222290039,
      "learning_rate": 2.7917966101694914e-05,
      "loss": 0.33237571716308595,
      "step": 24050
    },
    {
      "epoch": 29.17686250757117,
      "grad_norm": 6.722894668579102,
      "learning_rate": 2.7837390368576807e-05,
      "loss": 0.33178813934326173,
      "step": 24100
    },
    {
      "epoch": 29.237431859479102,
      "grad_norm": 1.3851453065872192,
      "learning_rate": 2.77568146354587e-05,
      "loss": 0.31329050064086916,
      "step": 24150
    },
    {
      "epoch": 29.29800121138704,
      "grad_norm": 3.1860179901123047,
      "learning_rate": 2.7676238902340592e-05,
      "loss": 0.33342044830322265,
      "step": 24200
    },
    {
      "epoch": 29.358570563294972,
      "grad_norm": 3.726094961166382,
      "learning_rate": 2.7595663169222488e-05,
      "loss": 0.3415557861328125,
      "step": 24250
    },
    {
      "epoch": 29.41913991520291,
      "grad_norm": 3.0136520862579346,
      "learning_rate": 2.7515087436104387e-05,
      "loss": 0.3502685546875,
      "step": 24300
    },
    {
      "epoch": 29.47970926711084,
      "grad_norm": 1.4374414682388306,
      "learning_rate": 2.743451170298628e-05,
      "loss": 0.33958198547363283,
      "step": 24350
    },
    {
      "epoch": 29.54027861901878,
      "grad_norm": 3.01107120513916,
      "learning_rate": 2.7353935969868173e-05,
      "loss": 0.31062026977539064,
      "step": 24400
    },
    {
      "epoch": 29.60084797092671,
      "grad_norm": 3.280339479446411,
      "learning_rate": 2.7273360236750065e-05,
      "loss": 0.3236080169677734,
      "step": 24450
    },
    {
      "epoch": 29.661417322834644,
      "grad_norm": 3.8678338527679443,
      "learning_rate": 2.7192784503631958e-05,
      "loss": 0.3417714309692383,
      "step": 24500
    },
    {
      "epoch": 29.661417322834644,
      "eval_loss": 0.7326874732971191,
      "eval_mean_accuracy": 0.6104552809408608,
      "eval_mean_iou": 0.4217670372994962,
      "eval_overall_accuracy": 0.8442996113370661,
      "eval_runtime": 280.6873,
      "eval_samples_per_second": 3.502,
      "eval_steps_per_second": 3.502,
      "step": 24500
    },
    {
      "epoch": 29.72198667474258,
      "grad_norm": 3.083075523376465,
      "learning_rate": 2.7112208770513854e-05,
      "loss": 0.334671745300293,
      "step": 24550
    },
    {
      "epoch": 29.782556026650514,
      "grad_norm": 2.638090133666992,
      "learning_rate": 2.7031633037395746e-05,
      "loss": 0.3261066818237305,
      "step": 24600
    },
    {
      "epoch": 29.84312537855845,
      "grad_norm": 2.209044933319092,
      "learning_rate": 2.695105730427764e-05,
      "loss": 0.31614486694335936,
      "step": 24650
    },
    {
      "epoch": 29.903694730466384,
      "grad_norm": 2.0722296237945557,
      "learning_rate": 2.687048157115954e-05,
      "loss": 0.34215412139892576,
      "step": 24700
    },
    {
      "epoch": 29.964264082374317,
      "grad_norm": 1.8845245838165283,
      "learning_rate": 2.678990583804143e-05,
      "loss": 0.33976016998291014,
      "step": 24750
    },
    {
      "epoch": 30.024227740763173,
      "grad_norm": 2.403608560562134,
      "learning_rate": 2.6709330104923324e-05,
      "loss": 0.3279345703125,
      "step": 24800
    },
    {
      "epoch": 30.08479709267111,
      "grad_norm": 1.65317964553833,
      "learning_rate": 2.662875437180522e-05,
      "loss": 0.3330901336669922,
      "step": 24850
    },
    {
      "epoch": 30.145366444579043,
      "grad_norm": 4.802414417266846,
      "learning_rate": 2.6548178638687112e-05,
      "loss": 0.3402233123779297,
      "step": 24900
    },
    {
      "epoch": 30.205935796486976,
      "grad_norm": 1.9252793788909912,
      "learning_rate": 2.6469214420231367e-05,
      "loss": 0.34874935150146485,
      "step": 24950
    },
    {
      "epoch": 30.266505148394913,
      "grad_norm": 2.5189476013183594,
      "learning_rate": 2.638863868711326e-05,
      "loss": 0.3357892608642578,
      "step": 25000
    },
    {
      "epoch": 30.266505148394913,
      "eval_loss": 0.703661322593689,
      "eval_mean_accuracy": 0.5973379033508416,
      "eval_mean_iou": 0.42184430521268845,
      "eval_overall_accuracy": 0.849537287699485,
      "eval_runtime": 287.0317,
      "eval_samples_per_second": 3.425,
      "eval_steps_per_second": 3.425,
      "step": 25000
    },
    {
      "epoch": 30.327074500302846,
      "grad_norm": 1.3599857091903687,
      "learning_rate": 2.6308062953995156e-05,
      "loss": 0.33975227355957033,
      "step": 25050
    },
    {
      "epoch": 30.387643852210783,
      "grad_norm": 5.067619800567627,
      "learning_rate": 2.6227487220877048e-05,
      "loss": 0.31869476318359374,
      "step": 25100
    },
    {
      "epoch": 30.448213204118716,
      "grad_norm": 2.8989827632904053,
      "learning_rate": 2.6146911487758948e-05,
      "loss": 0.34248477935791016,
      "step": 25150
    },
    {
      "epoch": 30.508782556026652,
      "grad_norm": 7.546941757202148,
      "learning_rate": 2.606633575464084e-05,
      "loss": 0.31733121871948244,
      "step": 25200
    },
    {
      "epoch": 30.569351907934585,
      "grad_norm": 2.8205184936523438,
      "learning_rate": 2.5985760021522733e-05,
      "loss": 0.3409184265136719,
      "step": 25250
    },
    {
      "epoch": 30.62992125984252,
      "grad_norm": 1.6327929496765137,
      "learning_rate": 2.5905184288404625e-05,
      "loss": 0.3677494430541992,
      "step": 25300
    },
    {
      "epoch": 30.690490611750455,
      "grad_norm": 2.6767733097076416,
      "learning_rate": 2.582460855528652e-05,
      "loss": 0.34155174255371096,
      "step": 25350
    },
    {
      "epoch": 30.75105996365839,
      "grad_norm": 2.9486312866210938,
      "learning_rate": 2.5744032822168414e-05,
      "loss": 0.3328845977783203,
      "step": 25400
    },
    {
      "epoch": 30.811629315566325,
      "grad_norm": 2.719000816345215,
      "learning_rate": 2.5663457089050307e-05,
      "loss": 0.3315354156494141,
      "step": 25450
    },
    {
      "epoch": 30.872198667474258,
      "grad_norm": 4.3083014488220215,
      "learning_rate": 2.55828813559322e-05,
      "loss": 0.3314183044433594,
      "step": 25500
    },
    {
      "epoch": 30.872198667474258,
      "eval_loss": 0.7755062580108643,
      "eval_mean_accuracy": 0.6131570191997494,
      "eval_mean_iou": 0.42409967482492805,
      "eval_overall_accuracy": 0.8405379860956574,
      "eval_runtime": 282.5514,
      "eval_samples_per_second": 3.479,
      "eval_steps_per_second": 3.479,
      "step": 25500
    },
    {
      "epoch": 30.93276801938219,
      "grad_norm": 2.7261931896209717,
      "learning_rate": 2.55023056228141e-05,
      "loss": 0.3523137283325195,
      "step": 25550
    },
    {
      "epoch": 30.993337371290128,
      "grad_norm": 1.10993492603302,
      "learning_rate": 2.542172988969599e-05,
      "loss": 0.324050178527832,
      "step": 25600
    },
    {
      "epoch": 31.053301029678984,
      "grad_norm": 6.649659633636475,
      "learning_rate": 2.5341154156577884e-05,
      "loss": 0.32445247650146486,
      "step": 25650
    },
    {
      "epoch": 31.113870381586917,
      "grad_norm": 3.106048822402954,
      "learning_rate": 2.526057842345978e-05,
      "loss": 0.31202268600463867,
      "step": 25700
    },
    {
      "epoch": 31.17443973349485,
      "grad_norm": 2.8033597469329834,
      "learning_rate": 2.5180002690341672e-05,
      "loss": 0.33468353271484375,
      "step": 25750
    },
    {
      "epoch": 31.235009085402787,
      "grad_norm": 1.5795316696166992,
      "learning_rate": 2.5099426957223565e-05,
      "loss": 0.3156974220275879,
      "step": 25800
    },
    {
      "epoch": 31.29557843731072,
      "grad_norm": 3.085766315460205,
      "learning_rate": 2.5018851224105458e-05,
      "loss": 0.32873245239257814,
      "step": 25850
    },
    {
      "epoch": 31.356147789218657,
      "grad_norm": 16.98001480102539,
      "learning_rate": 2.493827549098735e-05,
      "loss": 0.3508800506591797,
      "step": 25900
    },
    {
      "epoch": 31.41671714112659,
      "grad_norm": 3.013885259628296,
      "learning_rate": 2.485769975786925e-05,
      "loss": 0.34461986541748046,
      "step": 25950
    },
    {
      "epoch": 31.477286493034523,
      "grad_norm": 2.810276508331299,
      "learning_rate": 2.4777124024751146e-05,
      "loss": 0.3311392593383789,
      "step": 26000
    },
    {
      "epoch": 31.477286493034523,
      "eval_loss": 0.7902821898460388,
      "eval_mean_accuracy": 0.5931123011312321,
      "eval_mean_iou": 0.4248245055999893,
      "eval_overall_accuracy": 0.8428298624219147,
      "eval_runtime": 284.051,
      "eval_samples_per_second": 3.461,
      "eval_steps_per_second": 3.461,
      "step": 26000
    },
    {
      "epoch": 31.53785584494246,
      "grad_norm": 3.083684206008911,
      "learning_rate": 2.4696548291633038e-05,
      "loss": 0.32020938873291016,
      "step": 26050
    },
    {
      "epoch": 31.598425196850393,
      "grad_norm": 2.8909308910369873,
      "learning_rate": 2.461597255851493e-05,
      "loss": 0.33134521484375,
      "step": 26100
    },
    {
      "epoch": 31.65899454875833,
      "grad_norm": 3.189523458480835,
      "learning_rate": 2.4535396825396823e-05,
      "loss": 0.3162799072265625,
      "step": 26150
    },
    {
      "epoch": 31.719563900666262,
      "grad_norm": 4.5521769523620605,
      "learning_rate": 2.4454821092278716e-05,
      "loss": 0.3258476638793945,
      "step": 26200
    },
    {
      "epoch": 31.7801332525742,
      "grad_norm": 4.305176258087158,
      "learning_rate": 2.437424535916061e-05,
      "loss": 0.35046146392822264,
      "step": 26250
    },
    {
      "epoch": 31.840702604482132,
      "grad_norm": 3.0748589038848877,
      "learning_rate": 2.4293669626042505e-05,
      "loss": 0.3316982269287109,
      "step": 26300
    },
    {
      "epoch": 31.901271956390065,
      "grad_norm": 3.5437307357788086,
      "learning_rate": 2.4213093892924404e-05,
      "loss": 0.3298664093017578,
      "step": 26350
    },
    {
      "epoch": 31.961841308298002,
      "grad_norm": 3.928349018096924,
      "learning_rate": 2.4132518159806297e-05,
      "loss": 0.3280726623535156,
      "step": 26400
    },
    {
      "epoch": 32.02180496668686,
      "grad_norm": 2.0368497371673584,
      "learning_rate": 2.405194242668819e-05,
      "loss": 0.3196099281311035,
      "step": 26450
    },
    {
      "epoch": 32.08237431859479,
      "grad_norm": 9.804008483886719,
      "learning_rate": 2.3971366693570082e-05,
      "loss": 0.31267404556274414,
      "step": 26500
    },
    {
      "epoch": 32.08237431859479,
      "eval_loss": 0.7527980804443359,
      "eval_mean_accuracy": 0.6017923583811166,
      "eval_mean_iou": 0.4553040445971372,
      "eval_overall_accuracy": 0.8458407490323786,
      "eval_runtime": 280.046,
      "eval_samples_per_second": 3.51,
      "eval_steps_per_second": 3.51,
      "step": 26500
    },
    {
      "epoch": 32.142943670502724,
      "grad_norm": 2.5339081287384033,
      "learning_rate": 2.3890790960451975e-05,
      "loss": 0.32903759002685545,
      "step": 26550
    },
    {
      "epoch": 32.20351302241066,
      "grad_norm": 8.653077125549316,
      "learning_rate": 2.3810215227333867e-05,
      "loss": 0.3746588516235352,
      "step": 26600
    },
    {
      "epoch": 32.2640823743186,
      "grad_norm": 7.717852592468262,
      "learning_rate": 2.3729639494215763e-05,
      "loss": 0.30576435089111326,
      "step": 26650
    },
    {
      "epoch": 32.32465172622653,
      "grad_norm": 3.5861401557922363,
      "learning_rate": 2.3649063761097656e-05,
      "loss": 0.3267295455932617,
      "step": 26700
    },
    {
      "epoch": 32.385221078134464,
      "grad_norm": 3.080321788787842,
      "learning_rate": 2.3568488027979555e-05,
      "loss": 0.33827518463134765,
      "step": 26750
    },
    {
      "epoch": 32.4457904300424,
      "grad_norm": 1.864772081375122,
      "learning_rate": 2.3487912294861448e-05,
      "loss": 0.31601131439208985,
      "step": 26800
    },
    {
      "epoch": 32.50635978195033,
      "grad_norm": 1.6686006784439087,
      "learning_rate": 2.340733656174334e-05,
      "loss": 0.3419483184814453,
      "step": 26850
    },
    {
      "epoch": 32.56692913385827,
      "grad_norm": 3.991025686264038,
      "learning_rate": 2.3326760828625233e-05,
      "loss": 0.33613182067871095,
      "step": 26900
    },
    {
      "epoch": 32.6274984857662,
      "grad_norm": 1.3436306715011597,
      "learning_rate": 2.324618509550713e-05,
      "loss": 0.343934440612793,
      "step": 26950
    },
    {
      "epoch": 32.68806783767414,
      "grad_norm": 3.28800368309021,
      "learning_rate": 2.316560936238902e-05,
      "loss": 0.33128307342529295,
      "step": 27000
    },
    {
      "epoch": 32.68806783767414,
      "eval_loss": 0.8670344352722168,
      "eval_mean_accuracy": 0.5983828251586597,
      "eval_mean_iou": 0.4487291884320008,
      "eval_overall_accuracy": 0.8379727554709356,
      "eval_runtime": 283.0821,
      "eval_samples_per_second": 3.472,
      "eval_steps_per_second": 3.472,
      "step": 27000
    },
    {
      "epoch": 32.74863718958207,
      "grad_norm": 2.209043264389038,
      "learning_rate": 2.3085033629270914e-05,
      "loss": 0.317435302734375,
      "step": 27050
    },
    {
      "epoch": 32.809206541490006,
      "grad_norm": 3.1101863384246826,
      "learning_rate": 2.3004457896152807e-05,
      "loss": 0.34985244750976563,
      "step": 27100
    },
    {
      "epoch": 32.86977589339794,
      "grad_norm": 2.5105395317077637,
      "learning_rate": 2.2923882163034706e-05,
      "loss": 0.3161685180664062,
      "step": 27150
    },
    {
      "epoch": 32.93034524530587,
      "grad_norm": 6.496313095092773,
      "learning_rate": 2.28433064299166e-05,
      "loss": 0.3247226715087891,
      "step": 27200
    },
    {
      "epoch": 32.99091459721381,
      "grad_norm": 1.2133041620254517,
      "learning_rate": 2.2762730696798495e-05,
      "loss": 0.31464176177978515,
      "step": 27250
    },
    {
      "epoch": 33.05087825560266,
      "grad_norm": 3.4491333961486816,
      "learning_rate": 2.2682154963680387e-05,
      "loss": 0.3210258865356445,
      "step": 27300
    },
    {
      "epoch": 33.1114476075106,
      "grad_norm": 1.4911330938339233,
      "learning_rate": 2.260157923056228e-05,
      "loss": 0.2966936492919922,
      "step": 27350
    },
    {
      "epoch": 33.172016959418535,
      "grad_norm": 2.2136147022247314,
      "learning_rate": 2.2521003497444173e-05,
      "loss": 0.3155472564697266,
      "step": 27400
    },
    {
      "epoch": 33.23258631132647,
      "grad_norm": 1.4464526176452637,
      "learning_rate": 2.2440427764326065e-05,
      "loss": 0.30297754287719725,
      "step": 27450
    },
    {
      "epoch": 33.2931556632344,
      "grad_norm": 4.135019779205322,
      "learning_rate": 2.2359852031207958e-05,
      "loss": 0.31404512405395507,
      "step": 27500
    },
    {
      "epoch": 33.2931556632344,
      "eval_loss": 0.6889817118644714,
      "eval_mean_accuracy": 0.602934640952525,
      "eval_mean_iou": 0.4300223679077513,
      "eval_overall_accuracy": 0.849538079355886,
      "eval_runtime": 286.9377,
      "eval_samples_per_second": 3.426,
      "eval_steps_per_second": 3.426,
      "step": 27500
    },
    {
      "epoch": 33.35372501514234,
      "grad_norm": 2.099872350692749,
      "learning_rate": 2.2279276298089857e-05,
      "loss": 0.31211538314819337,
      "step": 27550
    },
    {
      "epoch": 33.414294367050275,
      "grad_norm": 3.473012685775757,
      "learning_rate": 2.2198700564971753e-05,
      "loss": 0.3324332809448242,
      "step": 27600
    },
    {
      "epoch": 33.474863718958204,
      "grad_norm": 5.2467451095581055,
      "learning_rate": 2.2118124831853646e-05,
      "loss": 0.33042999267578127,
      "step": 27650
    },
    {
      "epoch": 33.53543307086614,
      "grad_norm": 2.143674612045288,
      "learning_rate": 2.203754909873554e-05,
      "loss": 0.3223194885253906,
      "step": 27700
    },
    {
      "epoch": 33.59600242277408,
      "grad_norm": 2.108675003051758,
      "learning_rate": 2.195697336561743e-05,
      "loss": 0.3395851516723633,
      "step": 27750
    },
    {
      "epoch": 33.656571774682014,
      "grad_norm": 4.185624599456787,
      "learning_rate": 2.1876397632499324e-05,
      "loss": 0.3208763122558594,
      "step": 27800
    },
    {
      "epoch": 33.717141126589944,
      "grad_norm": 1.8397284746170044,
      "learning_rate": 2.1795821899381216e-05,
      "loss": 0.3376621246337891,
      "step": 27850
    },
    {
      "epoch": 33.77771047849788,
      "grad_norm": 2.200658082962036,
      "learning_rate": 2.1715246166263112e-05,
      "loss": 0.3321292114257812,
      "step": 27900
    },
    {
      "epoch": 33.83827983040582,
      "grad_norm": 1.5379315614700317,
      "learning_rate": 2.163467043314501e-05,
      "loss": 0.3301657485961914,
      "step": 27950
    },
    {
      "epoch": 33.89884918231375,
      "grad_norm": 1.7315089702606201,
      "learning_rate": 2.1554094700026904e-05,
      "loss": 0.33856925964355467,
      "step": 28000
    },
    {
      "epoch": 33.89884918231375,
      "eval_loss": 0.698147714138031,
      "eval_mean_accuracy": 0.5999261692541549,
      "eval_mean_iou": 0.4215371431025766,
      "eval_overall_accuracy": 0.8508102246242768,
      "eval_runtime": 284.8342,
      "eval_samples_per_second": 3.451,
      "eval_steps_per_second": 3.451,
      "step": 28000
    },
    {
      "epoch": 33.95941853422168,
      "grad_norm": 5.283531665802002,
      "learning_rate": 2.1473518966908797e-05,
      "loss": 0.3089784622192383,
      "step": 28050
    },
    {
      "epoch": 34.019382192610536,
      "grad_norm": 1.9482734203338623,
      "learning_rate": 2.139294323379069e-05,
      "loss": 0.3032878112792969,
      "step": 28100
    },
    {
      "epoch": 34.07995154451847,
      "grad_norm": 2.694788932800293,
      "learning_rate": 2.1312367500672582e-05,
      "loss": 0.31933494567871096,
      "step": 28150
    },
    {
      "epoch": 34.14052089642641,
      "grad_norm": 2.4266345500946045,
      "learning_rate": 2.1231791767554478e-05,
      "loss": 0.3144145202636719,
      "step": 28200
    },
    {
      "epoch": 34.201090248334346,
      "grad_norm": 3.176985025405884,
      "learning_rate": 2.115121603443637e-05,
      "loss": 0.3188871765136719,
      "step": 28250
    },
    {
      "epoch": 34.261659600242275,
      "grad_norm": 2.2224373817443848,
      "learning_rate": 2.1070640301318263e-05,
      "loss": 0.327778205871582,
      "step": 28300
    },
    {
      "epoch": 34.32222895215021,
      "grad_norm": 2.7969353199005127,
      "learning_rate": 2.0990064568200163e-05,
      "loss": 0.3242716979980469,
      "step": 28350
    },
    {
      "epoch": 34.38279830405815,
      "grad_norm": 1.55706787109375,
      "learning_rate": 2.0909488835082055e-05,
      "loss": 0.3057989501953125,
      "step": 28400
    },
    {
      "epoch": 34.44336765596608,
      "grad_norm": 4.176516532897949,
      "learning_rate": 2.0828913101963948e-05,
      "loss": 0.31613550186157224,
      "step": 28450
    },
    {
      "epoch": 34.503937007874015,
      "grad_norm": 2.334644079208374,
      "learning_rate": 2.0748337368845844e-05,
      "loss": 0.3119282913208008,
      "step": 28500
    },
    {
      "epoch": 34.503937007874015,
      "eval_loss": 0.6674853563308716,
      "eval_mean_accuracy": 0.6036714947439584,
      "eval_mean_iou": 0.4243532583479155,
      "eval_overall_accuracy": 0.8468818703357468,
      "eval_runtime": 278.5692,
      "eval_samples_per_second": 3.529,
      "eval_steps_per_second": 3.529,
      "step": 28500
    },
    {
      "epoch": 34.56450635978195,
      "grad_norm": 2.8155431747436523,
      "learning_rate": 2.0667761635727736e-05,
      "loss": 0.3177099609375,
      "step": 28550
    },
    {
      "epoch": 34.62507571168989,
      "grad_norm": 1.9685299396514893,
      "learning_rate": 2.058718590260963e-05,
      "loss": 0.32795963287353513,
      "step": 28600
    },
    {
      "epoch": 34.68564506359782,
      "grad_norm": 2.5456173419952393,
      "learning_rate": 2.050661016949152e-05,
      "loss": 0.3124265670776367,
      "step": 28650
    },
    {
      "epoch": 34.746214415505754,
      "grad_norm": 1.7329950332641602,
      "learning_rate": 2.042603443637342e-05,
      "loss": 0.29777093887329104,
      "step": 28700
    },
    {
      "epoch": 34.80678376741369,
      "grad_norm": 2.264885902404785,
      "learning_rate": 2.0345458703255314e-05,
      "loss": 0.3479033660888672,
      "step": 28750
    },
    {
      "epoch": 34.86735311932162,
      "grad_norm": 1.3516907691955566,
      "learning_rate": 2.0264882970137206e-05,
      "loss": 0.33133243560791015,
      "step": 28800
    },
    {
      "epoch": 34.92792247122956,
      "grad_norm": 2.190351724624634,
      "learning_rate": 2.0184307237019102e-05,
      "loss": 0.32935497283935544,
      "step": 28850
    },
    {
      "epoch": 34.988491823137494,
      "grad_norm": 2.4617514610290527,
      "learning_rate": 2.0103731503900995e-05,
      "loss": 0.31058319091796877,
      "step": 28900
    },
    {
      "epoch": 35.04845548152635,
      "grad_norm": 2.146627187728882,
      "learning_rate": 2.0023155770782887e-05,
      "loss": 0.31177827835083005,
      "step": 28950
    },
    {
      "epoch": 35.10902483343428,
      "grad_norm": 1.9236775636672974,
      "learning_rate": 1.994258003766478e-05,
      "loss": 0.30913667678833007,
      "step": 29000
    },
    {
      "epoch": 35.10902483343428,
      "eval_loss": 0.7248905897140503,
      "eval_mean_accuracy": 0.5930850773918711,
      "eval_mean_iou": 0.4262550920650445,
      "eval_overall_accuracy": 0.8456854601963855,
      "eval_runtime": 317.872,
      "eval_samples_per_second": 3.092,
      "eval_steps_per_second": 3.092,
      "step": 29000
    },
    {
      "epoch": 35.16959418534222,
      "grad_norm": 1.8119336366653442,
      "learning_rate": 1.9863615819209038e-05,
      "loss": 0.3216143798828125,
      "step": 29050
    },
    {
      "epoch": 35.23016353725015,
      "grad_norm": 1.8182356357574463,
      "learning_rate": 1.978304008609093e-05,
      "loss": 0.3086978530883789,
      "step": 29100
    },
    {
      "epoch": 35.290732889158086,
      "grad_norm": 1.98940908908844,
      "learning_rate": 1.9702464352972823e-05,
      "loss": 0.29488080978393555,
      "step": 29150
    },
    {
      "epoch": 35.35130224106602,
      "grad_norm": 19.70596694946289,
      "learning_rate": 1.9621888619854723e-05,
      "loss": 0.31811344146728515,
      "step": 29200
    },
    {
      "epoch": 35.41187159297395,
      "grad_norm": 5.514362812042236,
      "learning_rate": 1.9541312886736615e-05,
      "loss": 0.3091869735717773,
      "step": 29250
    },
    {
      "epoch": 35.47244094488189,
      "grad_norm": 3.445833444595337,
      "learning_rate": 1.9460737153618508e-05,
      "loss": 0.31369489669799805,
      "step": 29300
    },
    {
      "epoch": 35.533010296789826,
      "grad_norm": 3.585052013397217,
      "learning_rate": 1.9380161420500404e-05,
      "loss": 0.3379830551147461,
      "step": 29350
    },
    {
      "epoch": 35.59357964869776,
      "grad_norm": 8.828086853027344,
      "learning_rate": 1.9299585687382297e-05,
      "loss": 0.3185665893554688,
      "step": 29400
    },
    {
      "epoch": 35.65414900060569,
      "grad_norm": 2.848309278488159,
      "learning_rate": 1.921900995426419e-05,
      "loss": 0.31893077850341794,
      "step": 29450
    },
    {
      "epoch": 35.71471835251363,
      "grad_norm": 2.2059237957000732,
      "learning_rate": 1.9138434221146082e-05,
      "loss": 0.32473949432373045,
      "step": 29500
    },
    {
      "epoch": 35.71471835251363,
      "eval_loss": 0.7637423872947693,
      "eval_mean_accuracy": 0.6181405280309386,
      "eval_mean_iou": 0.45532458256561303,
      "eval_overall_accuracy": 0.8452757236795047,
      "eval_runtime": 273.8049,
      "eval_samples_per_second": 3.59,
      "eval_steps_per_second": 3.59,
      "step": 29500
    },
    {
      "epoch": 35.775287704421565,
      "grad_norm": 5.469277381896973,
      "learning_rate": 1.9057858488027974e-05,
      "loss": 0.31042062759399414,
      "step": 29550
    },
    {
      "epoch": 35.835857056329495,
      "grad_norm": 4.103715896606445,
      "learning_rate": 1.8977282754909874e-05,
      "loss": 0.34404598236083983,
      "step": 29600
    },
    {
      "epoch": 35.89642640823743,
      "grad_norm": 0.9339900016784668,
      "learning_rate": 1.889670702179177e-05,
      "loss": 0.3083435821533203,
      "step": 29650
    },
    {
      "epoch": 35.95699576014537,
      "grad_norm": 5.711855888366699,
      "learning_rate": 1.8816131288673662e-05,
      "loss": 0.32591461181640624,
      "step": 29700
    },
    {
      "epoch": 36.01695941853422,
      "grad_norm": 2.2374472618103027,
      "learning_rate": 1.8735555555555555e-05,
      "loss": 0.31995559692382813,
      "step": 29750
    },
    {
      "epoch": 36.07752877044216,
      "grad_norm": 3.9220175743103027,
      "learning_rate": 1.8654979822437448e-05,
      "loss": 0.3270090484619141,
      "step": 29800
    },
    {
      "epoch": 36.138098122350094,
      "grad_norm": 1.523747444152832,
      "learning_rate": 1.857440408931934e-05,
      "loss": 0.29567554473876956,
      "step": 29850
    },
    {
      "epoch": 36.19866747425802,
      "grad_norm": 1.4561861753463745,
      "learning_rate": 1.8493828356201233e-05,
      "loss": 0.32486480712890625,
      "step": 29900
    },
    {
      "epoch": 36.25923682616596,
      "grad_norm": 3.238023042678833,
      "learning_rate": 1.841325262308313e-05,
      "loss": 0.3196131896972656,
      "step": 29950
    },
    {
      "epoch": 36.3198061780739,
      "grad_norm": 3.2117257118225098,
      "learning_rate": 1.8332676889965028e-05,
      "loss": 0.3102729415893555,
      "step": 30000
    },
    {
      "epoch": 36.3198061780739,
      "eval_loss": 0.7157424092292786,
      "eval_mean_accuracy": 0.6028865740141122,
      "eval_mean_iou": 0.4275057687053778,
      "eval_overall_accuracy": 0.8494299173597645,
      "eval_runtime": 275.5225,
      "eval_samples_per_second": 3.568,
      "eval_steps_per_second": 3.568,
      "step": 30000
    },
    {
      "epoch": 36.380375529981826,
      "grad_norm": 2.4334793090820312,
      "learning_rate": 1.825210115684692e-05,
      "loss": 0.31841642379760743,
      "step": 30050
    },
    {
      "epoch": 36.44094488188976,
      "grad_norm": 1.2317160367965698,
      "learning_rate": 1.8171525423728813e-05,
      "loss": 0.2950638008117676,
      "step": 30100
    },
    {
      "epoch": 36.5015142337977,
      "grad_norm": 1.7761750221252441,
      "learning_rate": 1.8090949690610706e-05,
      "loss": 0.3018603134155273,
      "step": 30150
    },
    {
      "epoch": 36.562083585705636,
      "grad_norm": 1.4838730096817017,
      "learning_rate": 1.80103739574926e-05,
      "loss": 0.3360552597045898,
      "step": 30200
    },
    {
      "epoch": 36.622652937613566,
      "grad_norm": 3.3588788509368896,
      "learning_rate": 1.792979822437449e-05,
      "loss": 0.2976111030578613,
      "step": 30250
    },
    {
      "epoch": 36.6832222895215,
      "grad_norm": 15.15401840209961,
      "learning_rate": 1.7849222491256387e-05,
      "loss": 0.31630964279174806,
      "step": 30300
    },
    {
      "epoch": 36.74379164142944,
      "grad_norm": 1.6464455127716064,
      "learning_rate": 1.776864675813828e-05,
      "loss": 0.32368003845214843,
      "step": 30350
    },
    {
      "epoch": 36.80436099333737,
      "grad_norm": 2.88106632232666,
      "learning_rate": 1.768807102502018e-05,
      "loss": 0.3058509826660156,
      "step": 30400
    },
    {
      "epoch": 36.864930345245305,
      "grad_norm": 2.06898832321167,
      "learning_rate": 1.7607495291902072e-05,
      "loss": 0.32424808502197267,
      "step": 30450
    },
    {
      "epoch": 36.92549969715324,
      "grad_norm": 2.346395492553711,
      "learning_rate": 1.7526919558783964e-05,
      "loss": 0.3450229263305664,
      "step": 30500
    },
    {
      "epoch": 36.92549969715324,
      "eval_loss": 0.7585644721984863,
      "eval_mean_accuracy": 0.6040769435708487,
      "eval_mean_iou": 0.45816553266137844,
      "eval_overall_accuracy": 0.8462064166762701,
      "eval_runtime": 277.5929,
      "eval_samples_per_second": 3.541,
      "eval_steps_per_second": 3.541,
      "step": 30500
    },
    {
      "epoch": 36.98606904906117,
      "grad_norm": 2.9500396251678467,
      "learning_rate": 1.7446343825665857e-05,
      "loss": 0.3476728057861328,
      "step": 30550
    },
    {
      "epoch": 37.04603270745003,
      "grad_norm": 1.2187063694000244,
      "learning_rate": 1.7365768092547753e-05,
      "loss": 0.3193428421020508,
      "step": 30600
    },
    {
      "epoch": 37.10660205935797,
      "grad_norm": 6.096078395843506,
      "learning_rate": 1.7285192359429646e-05,
      "loss": 0.31855581283569334,
      "step": 30650
    },
    {
      "epoch": 37.1671714112659,
      "grad_norm": 2.361227512359619,
      "learning_rate": 1.7204616626311538e-05,
      "loss": 0.3107038116455078,
      "step": 30700
    },
    {
      "epoch": 37.227740763173834,
      "grad_norm": 1.508290410041809,
      "learning_rate": 1.712404089319343e-05,
      "loss": 0.29117372512817385,
      "step": 30750
    },
    {
      "epoch": 37.28831011508177,
      "grad_norm": 2.8912646770477295,
      "learning_rate": 1.704346516007533e-05,
      "loss": 0.31443443298339846,
      "step": 30800
    },
    {
      "epoch": 37.3488794669897,
      "grad_norm": 3.1802926063537598,
      "learning_rate": 1.6962889426957223e-05,
      "loss": 0.3093972587585449,
      "step": 30850
    },
    {
      "epoch": 37.40944881889764,
      "grad_norm": 1.7476401329040527,
      "learning_rate": 1.688231369383912e-05,
      "loss": 0.3448560333251953,
      "step": 30900
    },
    {
      "epoch": 37.470018170805574,
      "grad_norm": 2.184483528137207,
      "learning_rate": 1.680173796072101e-05,
      "loss": 0.29785341262817383,
      "step": 30950
    },
    {
      "epoch": 37.53058752271351,
      "grad_norm": 1.6574584245681763,
      "learning_rate": 1.6721162227602904e-05,
      "loss": 0.320775146484375,
      "step": 31000
    },
    {
      "epoch": 37.53058752271351,
      "eval_loss": 0.7910169363021851,
      "eval_mean_accuracy": 0.6151507121581365,
      "eval_mean_iou": 0.4308300027052985,
      "eval_overall_accuracy": 0.8481991555416694,
      "eval_runtime": 282.7771,
      "eval_samples_per_second": 3.476,
      "eval_steps_per_second": 3.476,
      "step": 31000
    },
    {
      "epoch": 37.59115687462144,
      "grad_norm": 2.480398178100586,
      "learning_rate": 1.6640586494484797e-05,
      "loss": 0.30946577072143555,
      "step": 31050
    },
    {
      "epoch": 37.65172622652938,
      "grad_norm": 5.4134368896484375,
      "learning_rate": 1.656001076136669e-05,
      "loss": 0.3317695999145508,
      "step": 31100
    },
    {
      "epoch": 37.71229557843731,
      "grad_norm": 2.3013384342193604,
      "learning_rate": 1.6479435028248582e-05,
      "loss": 0.3213368988037109,
      "step": 31150
    },
    {
      "epoch": 37.77286493034524,
      "grad_norm": 4.025968551635742,
      "learning_rate": 1.639885929513048e-05,
      "loss": 0.3097649002075195,
      "step": 31200
    },
    {
      "epoch": 37.83343428225318,
      "grad_norm": 2.5616707801818848,
      "learning_rate": 1.6318283562012377e-05,
      "loss": 0.32557003021240233,
      "step": 31250
    },
    {
      "epoch": 37.894003634161116,
      "grad_norm": 2.282996654510498,
      "learning_rate": 1.623770782889427e-05,
      "loss": 0.303972110748291,
      "step": 31300
    },
    {
      "epoch": 37.954572986069046,
      "grad_norm": 5.279763698577881,
      "learning_rate": 1.6157132095776162e-05,
      "loss": 0.31186193466186524,
      "step": 31350
    },
    {
      "epoch": 38.014536644457905,
      "grad_norm": 2.225403308868408,
      "learning_rate": 1.6076556362658055e-05,
      "loss": 0.29415384292602537,
      "step": 31400
    },
    {
      "epoch": 38.07510599636584,
      "grad_norm": 4.494822978973389,
      "learning_rate": 1.5995980629539948e-05,
      "loss": 0.3074629783630371,
      "step": 31450
    },
    {
      "epoch": 38.13567534827377,
      "grad_norm": 1.4246044158935547,
      "learning_rate": 1.591540489642184e-05,
      "loss": 0.30858930587768557,
      "step": 31500
    },
    {
      "epoch": 38.13567534827377,
      "eval_loss": 0.7887469530105591,
      "eval_mean_accuracy": 0.6004836414318492,
      "eval_mean_iou": 0.42179931304887247,
      "eval_overall_accuracy": 0.8458154160275464,
      "eval_runtime": 275.2909,
      "eval_samples_per_second": 3.571,
      "eval_steps_per_second": 3.571,
      "step": 31500
    },
    {
      "epoch": 38.19624470018171,
      "grad_norm": 2.002544641494751,
      "learning_rate": 1.5834829163303743e-05,
      "loss": 0.31193737030029295,
      "step": 31550
    },
    {
      "epoch": 38.256814052089645,
      "grad_norm": 8.756086349487305,
      "learning_rate": 1.5754253430185636e-05,
      "loss": 0.3094266128540039,
      "step": 31600
    },
    {
      "epoch": 38.317383403997574,
      "grad_norm": 3.8080265522003174,
      "learning_rate": 1.5673677697067528e-05,
      "loss": 0.2930822944641113,
      "step": 31650
    },
    {
      "epoch": 38.37795275590551,
      "grad_norm": 3.5062742233276367,
      "learning_rate": 1.559310196394942e-05,
      "loss": 0.3055276107788086,
      "step": 31700
    },
    {
      "epoch": 38.43852210781345,
      "grad_norm": 6.11549711227417,
      "learning_rate": 1.5512526230831313e-05,
      "loss": 0.3049530792236328,
      "step": 31750
    },
    {
      "epoch": 38.499091459721384,
      "grad_norm": 1.7740113735198975,
      "learning_rate": 1.5431950497713206e-05,
      "loss": 0.303525390625,
      "step": 31800
    },
    {
      "epoch": 38.559660811629314,
      "grad_norm": 6.573846817016602,
      "learning_rate": 1.5351374764595102e-05,
      "loss": 0.2956509971618652,
      "step": 31850
    },
    {
      "epoch": 38.62023016353725,
      "grad_norm": 4.751812934875488,
      "learning_rate": 1.5270799031476995e-05,
      "loss": 0.33010971069335937,
      "step": 31900
    },
    {
      "epoch": 38.68079951544519,
      "grad_norm": 10.492472648620605,
      "learning_rate": 1.5190223298358896e-05,
      "loss": 0.3109445571899414,
      "step": 31950
    },
    {
      "epoch": 38.74136886735312,
      "grad_norm": 5.696309566497803,
      "learning_rate": 1.5109647565240788e-05,
      "loss": 0.2994685745239258,
      "step": 32000
    },
    {
      "epoch": 38.74136886735312,
      "eval_loss": 0.7346374988555908,
      "eval_mean_accuracy": 0.5951195000014746,
      "eval_mean_iou": 0.48413461327493684,
      "eval_overall_accuracy": 0.843686062103613,
      "eval_runtime": 279.02,
      "eval_samples_per_second": 3.523,
      "eval_steps_per_second": 3.523,
      "step": 32000
    },
    {
      "epoch": 38.801938219261054,
      "grad_norm": 3.046236991882324,
      "learning_rate": 1.5029071832122681e-05,
      "loss": 0.2919857788085938,
      "step": 32050
    },
    {
      "epoch": 38.86250757116899,
      "grad_norm": 7.825695514678955,
      "learning_rate": 1.4948496099004575e-05,
      "loss": 0.3193976020812988,
      "step": 32100
    },
    {
      "epoch": 38.92307692307692,
      "grad_norm": 4.080345630645752,
      "learning_rate": 1.4869531880548832e-05,
      "loss": 0.3288080596923828,
      "step": 32150
    },
    {
      "epoch": 38.98364627498486,
      "grad_norm": 3.413867473602295,
      "learning_rate": 1.4788956147430724e-05,
      "loss": 0.32510913848876954,
      "step": 32200
    },
    {
      "epoch": 39.043609933373716,
      "grad_norm": 3.1092402935028076,
      "learning_rate": 1.4708380414312617e-05,
      "loss": 0.34231349945068357,
      "step": 32250
    },
    {
      "epoch": 39.104179285281646,
      "grad_norm": 4.147870063781738,
      "learning_rate": 1.4627804681194511e-05,
      "loss": 0.30520622253417967,
      "step": 32300
    },
    {
      "epoch": 39.16474863718958,
      "grad_norm": 2.2829861640930176,
      "learning_rate": 1.4547228948076404e-05,
      "loss": 0.32039695739746094,
      "step": 32350
    },
    {
      "epoch": 39.22531798909752,
      "grad_norm": 2.312885046005249,
      "learning_rate": 1.4466653214958296e-05,
      "loss": 0.3197624397277832,
      "step": 32400
    },
    {
      "epoch": 39.28588734100545,
      "grad_norm": 1.8044801950454712,
      "learning_rate": 1.4386077481840198e-05,
      "loss": 0.29550670623779296,
      "step": 32450
    },
    {
      "epoch": 39.346456692913385,
      "grad_norm": 1.715517282485962,
      "learning_rate": 1.430550174872209e-05,
      "loss": 0.293529167175293,
      "step": 32500
    },
    {
      "epoch": 39.346456692913385,
      "eval_loss": 0.7475118041038513,
      "eval_mean_accuracy": 0.6019691599720238,
      "eval_mean_iou": 0.4235236919575106,
      "eval_overall_accuracy": 0.84961201385467,
      "eval_runtime": 277.3999,
      "eval_samples_per_second": 3.544,
      "eval_steps_per_second": 3.544,
      "step": 32500
    },
    {
      "epoch": 39.40702604482132,
      "grad_norm": 1.9567533731460571,
      "learning_rate": 1.4224926015603983e-05,
      "loss": 0.30497398376464846,
      "step": 32550
    },
    {
      "epoch": 39.46759539672925,
      "grad_norm": 2.2935779094696045,
      "learning_rate": 1.4144350282485877e-05,
      "loss": 0.28808256149291994,
      "step": 32600
    },
    {
      "epoch": 39.52816474863719,
      "grad_norm": 4.062912464141846,
      "learning_rate": 1.406377454936777e-05,
      "loss": 0.3180473136901856,
      "step": 32650
    },
    {
      "epoch": 39.588734100545125,
      "grad_norm": 4.411317825317383,
      "learning_rate": 1.3983198816249662e-05,
      "loss": 0.3010701179504395,
      "step": 32700
    },
    {
      "epoch": 39.64930345245306,
      "grad_norm": 1.8129656314849854,
      "learning_rate": 1.3902623083131557e-05,
      "loss": 0.30276674270629883,
      "step": 32750
    },
    {
      "epoch": 39.70987280436099,
      "grad_norm": 2.0021936893463135,
      "learning_rate": 1.382204735001345e-05,
      "loss": 0.30869235992431643,
      "step": 32800
    },
    {
      "epoch": 39.77044215626893,
      "grad_norm": 1.9605317115783691,
      "learning_rate": 1.3741471616895349e-05,
      "loss": 0.29734317779541014,
      "step": 32850
    },
    {
      "epoch": 39.831011508176864,
      "grad_norm": 4.473711013793945,
      "learning_rate": 1.3660895883777243e-05,
      "loss": 0.30062252044677734,
      "step": 32900
    },
    {
      "epoch": 39.891580860084794,
      "grad_norm": 11.503155708312988,
      "learning_rate": 1.3580320150659135e-05,
      "loss": 0.3209872817993164,
      "step": 32950
    },
    {
      "epoch": 39.95215021199273,
      "grad_norm": 2.1323883533477783,
      "learning_rate": 1.3499744417541028e-05,
      "loss": 0.30190839767456057,
      "step": 33000
    },
    {
      "epoch": 39.95215021199273,
      "eval_loss": 0.7959737777709961,
      "eval_mean_accuracy": 0.5975900200522221,
      "eval_mean_iou": 0.4215375378106093,
      "eval_overall_accuracy": 0.8471741312517882,
      "eval_runtime": 278.8639,
      "eval_samples_per_second": 3.525,
      "eval_steps_per_second": 3.525,
      "step": 33000
    },
    {
      "epoch": 40.01211387038159,
      "grad_norm": 2.0529115200042725,
      "learning_rate": 1.3419168684422922e-05,
      "loss": 0.30312461853027345,
      "step": 33050
    },
    {
      "epoch": 40.07268322228952,
      "grad_norm": 2.6802167892456055,
      "learning_rate": 1.3338592951304815e-05,
      "loss": 0.3246957015991211,
      "step": 33100
    },
    {
      "epoch": 40.133252574197456,
      "grad_norm": 2.2852072715759277,
      "learning_rate": 1.3258017218186708e-05,
      "loss": 0.3023448753356934,
      "step": 33150
    },
    {
      "epoch": 40.19382192610539,
      "grad_norm": 1.6106106042861938,
      "learning_rate": 1.3177441485068602e-05,
      "loss": 0.3026760673522949,
      "step": 33200
    },
    {
      "epoch": 40.25439127801332,
      "grad_norm": 10.106108665466309,
      "learning_rate": 1.3096865751950501e-05,
      "loss": 0.30367053985595704,
      "step": 33250
    },
    {
      "epoch": 40.31496062992126,
      "grad_norm": 1.4994571208953857,
      "learning_rate": 1.3016290018832394e-05,
      "loss": 0.31437101364135744,
      "step": 33300
    },
    {
      "epoch": 40.375529981829196,
      "grad_norm": 8.12592601776123,
      "learning_rate": 1.2935714285714286e-05,
      "loss": 0.34352840423583986,
      "step": 33350
    },
    {
      "epoch": 40.436099333737126,
      "grad_norm": 3.038285732269287,
      "learning_rate": 1.285513855259618e-05,
      "loss": 0.2997738838195801,
      "step": 33400
    },
    {
      "epoch": 40.49666868564506,
      "grad_norm": 1.471627950668335,
      "learning_rate": 1.2774562819478073e-05,
      "loss": 0.2995327949523926,
      "step": 33450
    },
    {
      "epoch": 40.557238037553,
      "grad_norm": 2.0798981189727783,
      "learning_rate": 1.2693987086359966e-05,
      "loss": 0.2933077049255371,
      "step": 33500
    },
    {
      "epoch": 40.557238037553,
      "eval_loss": 0.8640518188476562,
      "eval_mean_accuracy": 0.5962193241149072,
      "eval_mean_iou": 0.4509316919829197,
      "eval_overall_accuracy": 0.8433475280947991,
      "eval_runtime": 278.3375,
      "eval_samples_per_second": 3.532,
      "eval_steps_per_second": 3.532,
      "step": 33500
    },
    {
      "epoch": 40.617807389460935,
      "grad_norm": 1.333795428276062,
      "learning_rate": 1.261341135324186e-05,
      "loss": 0.28620515823364256,
      "step": 33550
    },
    {
      "epoch": 40.678376741368865,
      "grad_norm": 1.3497437238693237,
      "learning_rate": 1.2532835620123753e-05,
      "loss": 0.305726261138916,
      "step": 33600
    },
    {
      "epoch": 40.7389460932768,
      "grad_norm": 1.461808681488037,
      "learning_rate": 1.2452259887005652e-05,
      "loss": 0.30444774627685545,
      "step": 33650
    },
    {
      "epoch": 40.79951544518474,
      "grad_norm": 2.0113425254821777,
      "learning_rate": 1.2371684153887547e-05,
      "loss": 0.31584156036376954,
      "step": 33700
    },
    {
      "epoch": 40.86008479709267,
      "grad_norm": 1.488474726676941,
      "learning_rate": 1.229110842076944e-05,
      "loss": 0.2936588478088379,
      "step": 33750
    },
    {
      "epoch": 40.920654149000605,
      "grad_norm": 6.941641330718994,
      "learning_rate": 1.2210532687651332e-05,
      "loss": 0.30999456405639647,
      "step": 33800
    },
    {
      "epoch": 40.98122350090854,
      "grad_norm": 3.129249334335327,
      "learning_rate": 1.2129956954533226e-05,
      "loss": 0.30566299438476563,
      "step": 33850
    },
    {
      "epoch": 41.041187159297394,
      "grad_norm": 1.4845830202102661,
      "learning_rate": 1.2049381221415119e-05,
      "loss": 0.3064897155761719,
      "step": 33900
    },
    {
      "epoch": 41.10175651120533,
      "grad_norm": 2.7902464866638184,
      "learning_rate": 1.1968805488297011e-05,
      "loss": 0.31646635055541994,
      "step": 33950
    },
    {
      "epoch": 41.16232586311327,
      "grad_norm": 2.665487051010132,
      "learning_rate": 1.1888229755178912e-05,
      "loss": 0.30554561614990233,
      "step": 34000
    },
    {
      "epoch": 41.16232586311327,
      "eval_loss": 0.8603617548942566,
      "eval_mean_accuracy": 0.602055195595221,
      "eval_mean_iou": 0.42245606327530966,
      "eval_overall_accuracy": 0.8437334993969752,
      "eval_runtime": 284.2018,
      "eval_samples_per_second": 3.459,
      "eval_steps_per_second": 3.459,
      "step": 34000
    },
    {
      "epoch": 41.2228952150212,
      "grad_norm": 9.084383964538574,
      "learning_rate": 1.1807654022060805e-05,
      "loss": 0.3227758026123047,
      "step": 34050
    },
    {
      "epoch": 41.28346456692913,
      "grad_norm": 2.301841974258423,
      "learning_rate": 1.1727078288942698e-05,
      "loss": 0.2911537170410156,
      "step": 34100
    },
    {
      "epoch": 41.34403391883707,
      "grad_norm": 1.4016790390014648,
      "learning_rate": 1.164650255582459e-05,
      "loss": 0.3106797027587891,
      "step": 34150
    },
    {
      "epoch": 41.404603270745,
      "grad_norm": 2.2057607173919678,
      "learning_rate": 1.1565926822706485e-05,
      "loss": 0.2778498649597168,
      "step": 34200
    },
    {
      "epoch": 41.465172622652936,
      "grad_norm": 3.485146999359131,
      "learning_rate": 1.1485351089588377e-05,
      "loss": 0.3118012809753418,
      "step": 34250
    },
    {
      "epoch": 41.52574197456087,
      "grad_norm": 3.8222689628601074,
      "learning_rate": 1.140477535647027e-05,
      "loss": 0.3020344352722168,
      "step": 34300
    },
    {
      "epoch": 41.58631132646881,
      "grad_norm": 4.763839244842529,
      "learning_rate": 1.1324199623352164e-05,
      "loss": 0.2855449867248535,
      "step": 34350
    },
    {
      "epoch": 41.64688067837674,
      "grad_norm": 1.8285164833068848,
      "learning_rate": 1.1243623890234063e-05,
      "loss": 0.32146831512451174,
      "step": 34400
    },
    {
      "epoch": 41.707450030284676,
      "grad_norm": 4.124021530151367,
      "learning_rate": 1.1163048157115956e-05,
      "loss": 0.294739990234375,
      "step": 34450
    },
    {
      "epoch": 41.76801938219261,
      "grad_norm": 6.982222557067871,
      "learning_rate": 1.108247242399785e-05,
      "loss": 0.28368865966796875,
      "step": 34500
    },
    {
      "epoch": 41.76801938219261,
      "eval_loss": 0.8034929037094116,
      "eval_mean_accuracy": 0.6108892087147132,
      "eval_mean_iou": 0.39938725955931437,
      "eval_overall_accuracy": 0.8432126981438358,
      "eval_runtime": 286.2871,
      "eval_samples_per_second": 3.434,
      "eval_steps_per_second": 3.434,
      "step": 34500
    },
    {
      "epoch": 41.82858873410054,
      "grad_norm": 1.8406651020050049,
      "learning_rate": 1.1003508205542107e-05,
      "loss": 0.32055900573730467,
      "step": 34550
    },
    {
      "epoch": 41.88915808600848,
      "grad_norm": 1.834471583366394,
      "learning_rate": 1.0922932472424e-05,
      "loss": 0.3144832992553711,
      "step": 34600
    },
    {
      "epoch": 41.949727437916415,
      "grad_norm": 2.073193311691284,
      "learning_rate": 1.0842356739305892e-05,
      "loss": 0.3032969093322754,
      "step": 34650
    },
    {
      "epoch": 42.00969109630527,
      "grad_norm": 4.794887065887451,
      "learning_rate": 1.0761781006187786e-05,
      "loss": 0.29607549667358396,
      "step": 34700
    },
    {
      "epoch": 42.070260448213205,
      "grad_norm": 2.9848954677581787,
      "learning_rate": 1.0681205273069679e-05,
      "loss": 0.28320674896240233,
      "step": 34750
    },
    {
      "epoch": 42.13082980012114,
      "grad_norm": 2.9967150688171387,
      "learning_rate": 1.0600629539951572e-05,
      "loss": 0.2850174903869629,
      "step": 34800
    },
    {
      "epoch": 42.19139915202907,
      "grad_norm": 2.0720903873443604,
      "learning_rate": 1.0520053806833466e-05,
      "loss": 0.30621164321899413,
      "step": 34850
    },
    {
      "epoch": 42.25196850393701,
      "grad_norm": 1.6421300172805786,
      "learning_rate": 1.0439478073715365e-05,
      "loss": 0.2892049026489258,
      "step": 34900
    },
    {
      "epoch": 42.312537855844944,
      "grad_norm": 6.617742538452148,
      "learning_rate": 1.0358902340597258e-05,
      "loss": 0.27602550506591794,
      "step": 34950
    },
    {
      "epoch": 42.373107207752874,
      "grad_norm": 4.54785680770874,
      "learning_rate": 1.0278326607479152e-05,
      "loss": 0.3214938354492187,
      "step": 35000
    },
    {
      "epoch": 42.373107207752874,
      "eval_loss": 0.7932268977165222,
      "eval_mean_accuracy": 0.6064531647869176,
      "eval_mean_iou": 0.4234167704884802,
      "eval_overall_accuracy": 0.846119086109367,
      "eval_runtime": 277.6337,
      "eval_samples_per_second": 3.541,
      "eval_steps_per_second": 3.541,
      "step": 35000
    },
    {
      "epoch": 42.43367655966081,
      "grad_norm": 1.5651397705078125,
      "learning_rate": 1.0197750874361045e-05,
      "loss": 0.29947843551635744,
      "step": 35050
    },
    {
      "epoch": 42.49424591156875,
      "grad_norm": 1.345249891281128,
      "learning_rate": 1.0117175141242937e-05,
      "loss": 0.2880203628540039,
      "step": 35100
    },
    {
      "epoch": 42.554815263476684,
      "grad_norm": 2.727341413497925,
      "learning_rate": 1.0036599408124832e-05,
      "loss": 0.30296630859375,
      "step": 35150
    },
    {
      "epoch": 42.61538461538461,
      "grad_norm": 1.6078672409057617,
      "learning_rate": 9.956023675006724e-06,
      "loss": 0.29125791549682617,
      "step": 35200
    },
    {
      "epoch": 42.67595396729255,
      "grad_norm": 6.007794380187988,
      "learning_rate": 9.875447941888617e-06,
      "loss": 0.297181396484375,
      "step": 35250
    },
    {
      "epoch": 42.73652331920049,
      "grad_norm": 3.708423376083374,
      "learning_rate": 9.794872208770518e-06,
      "loss": 0.31471744537353513,
      "step": 35300
    },
    {
      "epoch": 42.797092671108416,
      "grad_norm": 1.4323416948318481,
      "learning_rate": 9.71429647565241e-06,
      "loss": 0.297429256439209,
      "step": 35350
    },
    {
      "epoch": 42.85766202301635,
      "grad_norm": 4.530997276306152,
      "learning_rate": 9.633720742534303e-06,
      "loss": 0.28610986709594727,
      "step": 35400
    },
    {
      "epoch": 42.91823137492429,
      "grad_norm": 5.161438941955566,
      "learning_rate": 9.553145009416197e-06,
      "loss": 0.31195817947387694,
      "step": 35450
    },
    {
      "epoch": 42.978800726832226,
      "grad_norm": 1.3407201766967773,
      "learning_rate": 9.47256927629809e-06,
      "loss": 0.2965873908996582,
      "step": 35500
    },
    {
      "epoch": 42.978800726832226,
      "eval_loss": 0.7430391311645508,
      "eval_mean_accuracy": 0.5972870821472461,
      "eval_mean_iou": 0.397918124820072,
      "eval_overall_accuracy": 0.8471490466097485,
      "eval_runtime": 283.2565,
      "eval_samples_per_second": 3.47,
      "eval_steps_per_second": 3.47,
      "step": 35500
    },
    {
      "epoch": 43.03876438522108,
      "grad_norm": 3.834955930709839,
      "learning_rate": 9.391993543179983e-06,
      "loss": 0.3301237487792969,
      "step": 35550
    },
    {
      "epoch": 43.099333737129015,
      "grad_norm": 1.8333275318145752,
      "learning_rate": 9.311417810061877e-06,
      "loss": 0.28951875686645506,
      "step": 35600
    },
    {
      "epoch": 43.159903089036945,
      "grad_norm": 2.119014263153076,
      "learning_rate": 9.23084207694377e-06,
      "loss": 0.2929644393920898,
      "step": 35650
    },
    {
      "epoch": 43.22047244094488,
      "grad_norm": 4.024323463439941,
      "learning_rate": 9.150266343825669e-06,
      "loss": 0.28976041793823243,
      "step": 35700
    },
    {
      "epoch": 43.28104179285282,
      "grad_norm": 4.066603183746338,
      "learning_rate": 9.069690610707562e-06,
      "loss": 0.3218634414672852,
      "step": 35750
    },
    {
      "epoch": 43.34161114476075,
      "grad_norm": 3.0993618965148926,
      "learning_rate": 8.989114877589456e-06,
      "loss": 0.28794475555419924,
      "step": 35800
    },
    {
      "epoch": 43.402180496668684,
      "grad_norm": 4.103906631469727,
      "learning_rate": 8.908539144471348e-06,
      "loss": 0.29193376541137694,
      "step": 35850
    },
    {
      "epoch": 43.46274984857662,
      "grad_norm": 18.855161666870117,
      "learning_rate": 8.827963411353241e-06,
      "loss": 0.3127193260192871,
      "step": 35900
    },
    {
      "epoch": 43.52331920048456,
      "grad_norm": 1.7834621667861938,
      "learning_rate": 8.747387678235135e-06,
      "loss": 0.29797460556030275,
      "step": 35950
    },
    {
      "epoch": 43.58388855239249,
      "grad_norm": 24.716157913208008,
      "learning_rate": 8.666811945117028e-06,
      "loss": 0.31478187561035154,
      "step": 36000
    },
    {
      "epoch": 43.58388855239249,
      "eval_loss": 0.8815428614616394,
      "eval_mean_accuracy": 0.6015339031308516,
      "eval_mean_iou": 0.42253813493546827,
      "eval_overall_accuracy": 0.8426499391014433,
      "eval_runtime": 278.7249,
      "eval_samples_per_second": 3.527,
      "eval_steps_per_second": 3.527,
      "step": 36000
    },
    {
      "epoch": 43.644457904300424,
      "grad_norm": 3.8666486740112305,
      "learning_rate": 8.58623621199892e-06,
      "loss": 0.2907140922546387,
      "step": 36050
    },
    {
      "epoch": 43.70502725620836,
      "grad_norm": 36.12322998046875,
      "learning_rate": 8.505660478880822e-06,
      "loss": 0.3073836708068848,
      "step": 36100
    },
    {
      "epoch": 43.76559660811629,
      "grad_norm": 1.2825535535812378,
      "learning_rate": 8.425084745762714e-06,
      "loss": 0.31637742996215823,
      "step": 36150
    },
    {
      "epoch": 43.82616596002423,
      "grad_norm": 1.5730884075164795,
      "learning_rate": 8.344509012644607e-06,
      "loss": 0.3000030517578125,
      "step": 36200
    },
    {
      "epoch": 43.88673531193216,
      "grad_norm": 2.6569271087646484,
      "learning_rate": 8.263933279526501e-06,
      "loss": 0.3063284111022949,
      "step": 36250
    },
    {
      "epoch": 43.9473046638401,
      "grad_norm": 1.6443798542022705,
      "learning_rate": 8.183357546408394e-06,
      "loss": 0.28238021850585937,
      "step": 36300
    },
    {
      "epoch": 44.00726832222895,
      "grad_norm": 1.7214020490646362,
      "learning_rate": 8.102781813290286e-06,
      "loss": 0.28323099136352536,
      "step": 36350
    },
    {
      "epoch": 44.06783767413689,
      "grad_norm": 7.604288101196289,
      "learning_rate": 8.02220608017218e-06,
      "loss": 0.30026075363159177,
      "step": 36400
    },
    {
      "epoch": 44.12840702604482,
      "grad_norm": 2.405421257019043,
      "learning_rate": 7.941630347054073e-06,
      "loss": 0.3013182830810547,
      "step": 36450
    },
    {
      "epoch": 44.188976377952756,
      "grad_norm": 1.0289212465286255,
      "learning_rate": 7.861054613935973e-06,
      "loss": 0.3126581764221191,
      "step": 36500
    },
    {
      "epoch": 44.188976377952756,
      "eval_loss": 0.8783482909202576,
      "eval_mean_accuracy": 0.5987335464801655,
      "eval_mean_iou": 0.42321762541273694,
      "eval_overall_accuracy": 0.8429167117859073,
      "eval_runtime": 275.0481,
      "eval_samples_per_second": 3.574,
      "eval_steps_per_second": 3.574,
      "step": 36500
    },
    {
      "epoch": 44.24954572986069,
      "grad_norm": 6.612064838409424,
      "learning_rate": 7.780478880817867e-06,
      "loss": 0.29967594146728516,
      "step": 36550
    },
    {
      "epoch": 44.31011508176862,
      "grad_norm": 1.6074395179748535,
      "learning_rate": 7.69990314769976e-06,
      "loss": 0.2984409713745117,
      "step": 36600
    },
    {
      "epoch": 44.37068443367656,
      "grad_norm": 1.0893789529800415,
      "learning_rate": 7.619327414581652e-06,
      "loss": 0.3139439964294434,
      "step": 36650
    },
    {
      "epoch": 44.431253785584495,
      "grad_norm": 2.897430658340454,
      "learning_rate": 7.538751681463544e-06,
      "loss": 0.28562877655029295,
      "step": 36700
    },
    {
      "epoch": 44.49182313749243,
      "grad_norm": 2.1500511169433594,
      "learning_rate": 7.458175948345438e-06,
      "loss": 0.2941743850708008,
      "step": 36750
    },
    {
      "epoch": 44.55239248940036,
      "grad_norm": 1.8649201393127441,
      "learning_rate": 7.377600215227331e-06,
      "loss": 0.29802820205688474,
      "step": 36800
    },
    {
      "epoch": 44.6129618413083,
      "grad_norm": 2.324097156524658,
      "learning_rate": 7.297024482109231e-06,
      "loss": 0.27902320861816404,
      "step": 36850
    },
    {
      "epoch": 44.673531193216235,
      "grad_norm": 7.424629211425781,
      "learning_rate": 7.216448748991124e-06,
      "loss": 0.30639545440673827,
      "step": 36900
    },
    {
      "epoch": 44.734100545124164,
      "grad_norm": 1.641405463218689,
      "learning_rate": 7.135873015873017e-06,
      "loss": 0.2777372360229492,
      "step": 36950
    },
    {
      "epoch": 44.7946698970321,
      "grad_norm": 1.934893012046814,
      "learning_rate": 7.055297282754911e-06,
      "loss": 0.2974617195129394,
      "step": 37000
    },
    {
      "epoch": 44.7946698970321,
      "eval_loss": 0.7862820625305176,
      "eval_mean_accuracy": 0.5809908314785666,
      "eval_mean_iou": 0.3923961810544258,
      "eval_overall_accuracy": 0.848634100881986,
      "eval_runtime": 276.4029,
      "eval_samples_per_second": 3.556,
      "eval_steps_per_second": 3.556,
      "step": 37000
    },
    {
      "epoch": 44.85523924894004,
      "grad_norm": 1.2517621517181396,
      "learning_rate": 6.974721549636803e-06,
      "loss": 0.29718509674072263,
      "step": 37050
    },
    {
      "epoch": 44.915808600847974,
      "grad_norm": 2.3480029106140137,
      "learning_rate": 6.894145816518697e-06,
      "loss": 0.3141787910461426,
      "step": 37100
    },
    {
      "epoch": 44.976377952755904,
      "grad_norm": 2.0283892154693604,
      "learning_rate": 6.81357008340059e-06,
      "loss": 0.2743204689025879,
      "step": 37150
    },
    {
      "epoch": 45.03634161114476,
      "grad_norm": 1.426616907119751,
      "learning_rate": 6.732994350282483e-06,
      "loss": 0.3000053977966309,
      "step": 37200
    },
    {
      "epoch": 45.09691096305269,
      "grad_norm": 1.426677942276001,
      "learning_rate": 6.652418617164383e-06,
      "loss": 0.2796023368835449,
      "step": 37250
    },
    {
      "epoch": 45.15748031496063,
      "grad_norm": 1.6816178560256958,
      "learning_rate": 6.571842884046276e-06,
      "loss": 0.29328285217285155,
      "step": 37300
    },
    {
      "epoch": 45.218049666868566,
      "grad_norm": 1.9229141473770142,
      "learning_rate": 6.491267150928169e-06,
      "loss": 0.2801569557189941,
      "step": 37350
    },
    {
      "epoch": 45.278619018776496,
      "grad_norm": 4.6404194831848145,
      "learning_rate": 6.4106914178100625e-06,
      "loss": 0.3049056243896484,
      "step": 37400
    },
    {
      "epoch": 45.33918837068443,
      "grad_norm": 0.9662643671035767,
      "learning_rate": 6.330115684691956e-06,
      "loss": 0.3126907157897949,
      "step": 37450
    },
    {
      "epoch": 45.39975772259237,
      "grad_norm": 1.706476092338562,
      "learning_rate": 6.2495399515738485e-06,
      "loss": 0.2917660331726074,
      "step": 37500
    },
    {
      "epoch": 45.39975772259237,
      "eval_loss": 0.8375141024589539,
      "eval_mean_accuracy": 0.5992789103723285,
      "eval_mean_iou": 0.3973563889969856,
      "eval_overall_accuracy": 0.8459074965328555,
      "eval_runtime": 280.4958,
      "eval_samples_per_second": 3.505,
      "eval_steps_per_second": 3.505,
      "step": 37500
    },
    {
      "epoch": 45.460327074500306,
      "grad_norm": 7.005091190338135,
      "learning_rate": 6.168964218455742e-06,
      "loss": 0.29488330841064453,
      "step": 37550
    },
    {
      "epoch": 45.520896426408235,
      "grad_norm": 2.607677459716797,
      "learning_rate": 6.088388485337635e-06,
      "loss": 0.28857643127441407,
      "step": 37600
    },
    {
      "epoch": 45.58146577831617,
      "grad_norm": 1.901489496231079,
      "learning_rate": 6.007812752219535e-06,
      "loss": 0.2978265380859375,
      "step": 37650
    },
    {
      "epoch": 45.64203513022411,
      "grad_norm": 6.210808753967285,
      "learning_rate": 5.927237019101428e-06,
      "loss": 0.27275131225585936,
      "step": 37700
    },
    {
      "epoch": 45.70260448213204,
      "grad_norm": 51.37397003173828,
      "learning_rate": 5.846661285983321e-06,
      "loss": 0.29093929290771486,
      "step": 37750
    },
    {
      "epoch": 45.763173834039975,
      "grad_norm": 1.2711915969848633,
      "learning_rate": 5.766085552865214e-06,
      "loss": 0.2958537483215332,
      "step": 37800
    },
    {
      "epoch": 45.82374318594791,
      "grad_norm": 1.7767047882080078,
      "learning_rate": 5.685509819747108e-06,
      "loss": 0.31694248199462893,
      "step": 37850
    },
    {
      "epoch": 45.88431253785585,
      "grad_norm": 1.1233404874801636,
      "learning_rate": 5.604934086629e-06,
      "loss": 0.29506994247436524,
      "step": 37900
    },
    {
      "epoch": 45.94488188976378,
      "grad_norm": 2.425354242324829,
      "learning_rate": 5.524358353510894e-06,
      "loss": 0.28438488006591794,
      "step": 37950
    },
    {
      "epoch": 46.00484554815264,
      "grad_norm": 12.083049774169922,
      "learning_rate": 5.443782620392787e-06,
      "loss": 0.3166622543334961,
      "step": 38000
    },
    {
      "epoch": 46.00484554815264,
      "eval_loss": 0.8453558087348938,
      "eval_mean_accuracy": 0.6075644940238305,
      "eval_mean_iou": 0.39860080563257994,
      "eval_overall_accuracy": 0.8477330717162465,
      "eval_runtime": 294.0638,
      "eval_samples_per_second": 3.343,
      "eval_steps_per_second": 3.343,
      "step": 38000
    },
    {
      "epoch": 46.06541490006057,
      "grad_norm": 3.4846887588500977,
      "learning_rate": 5.363206887274687e-06,
      "loss": 0.30337177276611327,
      "step": 38050
    },
    {
      "epoch": 46.125984251968504,
      "grad_norm": 2.3858962059020996,
      "learning_rate": 5.28263115415658e-06,
      "loss": 0.28091930389404296,
      "step": 38100
    },
    {
      "epoch": 46.18655360387644,
      "grad_norm": 11.835179328918457,
      "learning_rate": 5.202055421038473e-06,
      "loss": 0.2818661880493164,
      "step": 38150
    },
    {
      "epoch": 46.24712295578437,
      "grad_norm": 2.4357142448425293,
      "learning_rate": 5.121479687920366e-06,
      "loss": 0.28713138580322267,
      "step": 38200
    },
    {
      "epoch": 46.30769230769231,
      "grad_norm": 1.1455798149108887,
      "learning_rate": 5.04090395480226e-06,
      "loss": 0.30912887573242187,
      "step": 38250
    },
    {
      "epoch": 46.36826165960024,
      "grad_norm": 1.8200187683105469,
      "learning_rate": 4.960328221684152e-06,
      "loss": 0.31334226608276367,
      "step": 38300
    },
    {
      "epoch": 46.42883101150818,
      "grad_norm": 3.2757492065429688,
      "learning_rate": 4.879752488566046e-06,
      "loss": 0.30602924346923827,
      "step": 38350
    },
    {
      "epoch": 46.48940036341611,
      "grad_norm": 3.478102922439575,
      "learning_rate": 4.799176755447939e-06,
      "loss": 0.29114416122436526,
      "step": 38400
    },
    {
      "epoch": 46.549969715324046,
      "grad_norm": 1.4237241744995117,
      "learning_rate": 4.7186010223298386e-06,
      "loss": 0.28558128356933593,
      "step": 38450
    },
    {
      "epoch": 46.61053906723198,
      "grad_norm": 2.30112361907959,
      "learning_rate": 4.638025289211732e-06,
      "loss": 0.30260337829589845,
      "step": 38500
    },
    {
      "epoch": 46.61053906723198,
      "eval_loss": 0.8003751635551453,
      "eval_mean_accuracy": 0.6061022619324035,
      "eval_mean_iou": 0.42132527040723533,
      "eval_overall_accuracy": 0.8474852677400575,
      "eval_runtime": 277.2207,
      "eval_samples_per_second": 3.546,
      "eval_steps_per_second": 3.546,
      "step": 38500
    },
    {
      "epoch": 46.67110841913991,
      "grad_norm": 1.5681438446044922,
      "learning_rate": 4.557449556093625e-06,
      "loss": 0.2997440338134766,
      "step": 38550
    },
    {
      "epoch": 46.73167777104785,
      "grad_norm": 3.020061492919922,
      "learning_rate": 4.478485337637882e-06,
      "loss": 0.3010483932495117,
      "step": 38600
    },
    {
      "epoch": 46.792247122955786,
      "grad_norm": 3.0761756896972656,
      "learning_rate": 4.3979096045197745e-06,
      "loss": 0.30926607131958006,
      "step": 38650
    },
    {
      "epoch": 46.85281647486372,
      "grad_norm": 2.4621801376342773,
      "learning_rate": 4.318945386064032e-06,
      "loss": 0.3051552581787109,
      "step": 38700
    },
    {
      "epoch": 46.91338582677165,
      "grad_norm": 3.4860599040985107,
      "learning_rate": 4.2383696529459244e-06,
      "loss": 0.3020890426635742,
      "step": 38750
    },
    {
      "epoch": 46.97395517867959,
      "grad_norm": 2.084812879562378,
      "learning_rate": 4.157793919827818e-06,
      "loss": 0.2889942932128906,
      "step": 38800
    },
    {
      "epoch": 47.03391883706844,
      "grad_norm": 1.7710397243499756,
      "learning_rate": 4.0772181867097105e-06,
      "loss": 0.281812801361084,
      "step": 38850
    },
    {
      "epoch": 47.09448818897638,
      "grad_norm": 1.7569230794906616,
      "learning_rate": 3.996642453591604e-06,
      "loss": 0.2980839729309082,
      "step": 38900
    },
    {
      "epoch": 47.155057540884314,
      "grad_norm": 1.4335309267044067,
      "learning_rate": 3.916066720473497e-06,
      "loss": 0.29432451248168945,
      "step": 38950
    },
    {
      "epoch": 47.215626892792244,
      "grad_norm": 1.8978092670440674,
      "learning_rate": 3.835490987355398e-06,
      "loss": 0.30594936370849607,
      "step": 39000
    },
    {
      "epoch": 47.215626892792244,
      "eval_loss": 0.8737384676933289,
      "eval_mean_accuracy": 0.6010951979543543,
      "eval_mean_iou": 0.42055413627775085,
      "eval_overall_accuracy": 0.845444268879546,
      "eval_runtime": 277.847,
      "eval_samples_per_second": 3.538,
      "eval_steps_per_second": 3.538,
      "step": 39000
    },
    {
      "epoch": 47.27619624470018,
      "grad_norm": 1.823684573173523,
      "learning_rate": 3.7549152542372907e-06,
      "loss": 0.2755848693847656,
      "step": 39050
    },
    {
      "epoch": 47.33676559660812,
      "grad_norm": 7.2978363037109375,
      "learning_rate": 3.6743395211191833e-06,
      "loss": 0.2833772850036621,
      "step": 39100
    },
    {
      "epoch": 47.397334948516054,
      "grad_norm": 4.654191493988037,
      "learning_rate": 3.5937637880010767e-06,
      "loss": 0.28082101821899413,
      "step": 39150
    },
    {
      "epoch": 47.457904300423984,
      "grad_norm": 2.4690470695495605,
      "learning_rate": 3.5131880548829698e-06,
      "loss": 0.3211909484863281,
      "step": 39200
    },
    {
      "epoch": 47.51847365233192,
      "grad_norm": 1.5573468208312988,
      "learning_rate": 3.432612321764863e-06,
      "loss": 0.2929158592224121,
      "step": 39250
    },
    {
      "epoch": 47.57904300423986,
      "grad_norm": 2.7625386714935303,
      "learning_rate": 3.352036588646756e-06,
      "loss": 0.2889478874206543,
      "step": 39300
    },
    {
      "epoch": 47.639612356147786,
      "grad_norm": 1.9633400440216064,
      "learning_rate": 3.2714608555286493e-06,
      "loss": 0.2977812004089355,
      "step": 39350
    },
    {
      "epoch": 47.70018170805572,
      "grad_norm": 1.8500852584838867,
      "learning_rate": 3.190885122410549e-06,
      "loss": 0.30802473068237307,
      "step": 39400
    },
    {
      "epoch": 47.76075105996366,
      "grad_norm": 2.9567220211029053,
      "learning_rate": 3.110309389292442e-06,
      "loss": 0.34268157958984374,
      "step": 39450
    },
    {
      "epoch": 47.821320411871596,
      "grad_norm": 7.717229843139648,
      "learning_rate": 3.029733656174335e-06,
      "loss": 0.3001274681091309,
      "step": 39500
    },
    {
      "epoch": 47.821320411871596,
      "eval_loss": 0.7439069151878357,
      "eval_mean_accuracy": 0.5922930677978935,
      "eval_mean_iou": 0.39702003880438763,
      "eval_overall_accuracy": 0.8508445452576615,
      "eval_runtime": 280.3276,
      "eval_samples_per_second": 3.507,
      "eval_steps_per_second": 3.507,
      "step": 39500
    },
    {
      "epoch": 47.881889763779526,
      "grad_norm": 3.0338943004608154,
      "learning_rate": 2.9491579230562286e-06,
      "loss": 0.2810843849182129,
      "step": 39550
    },
    {
      "epoch": 47.94245911568746,
      "grad_norm": 1.3434761762619019,
      "learning_rate": 2.8685821899381216e-06,
      "loss": 0.27430091857910155,
      "step": 39600
    },
    {
      "epoch": 48.002422774076315,
      "grad_norm": 2.1769888401031494,
      "learning_rate": 2.7880064568200147e-06,
      "loss": 0.3119598579406738,
      "step": 39650
    },
    {
      "epoch": 48.06299212598425,
      "grad_norm": 1.5028141736984253,
      "learning_rate": 2.707430723701908e-06,
      "loss": 0.287723274230957,
      "step": 39700
    },
    {
      "epoch": 48.12356147789219,
      "grad_norm": 1.7210636138916016,
      "learning_rate": 2.626854990583801e-06,
      "loss": 0.29104122161865237,
      "step": 39750
    },
    {
      "epoch": 48.18413082980012,
      "grad_norm": 2.079829216003418,
      "learning_rate": 2.546279257465701e-06,
      "loss": 0.2942757415771484,
      "step": 39800
    },
    {
      "epoch": 48.244700181708055,
      "grad_norm": 2.2698471546173096,
      "learning_rate": 2.465703524347594e-06,
      "loss": 0.277281494140625,
      "step": 39850
    },
    {
      "epoch": 48.30526953361599,
      "grad_norm": 3.482313632965088,
      "learning_rate": 2.3851277912294874e-06,
      "loss": 0.2791715621948242,
      "step": 39900
    },
    {
      "epoch": 48.36583888552393,
      "grad_norm": 5.914761066436768,
      "learning_rate": 2.3045520581113805e-06,
      "loss": 0.31496416091918944,
      "step": 39950
    },
    {
      "epoch": 48.42640823743186,
      "grad_norm": 6.375567436218262,
      "learning_rate": 2.2239763249932735e-06,
      "loss": 0.2867966842651367,
      "step": 40000
    },
    {
      "epoch": 48.42640823743186,
      "eval_loss": 0.7817684412002563,
      "eval_mean_accuracy": 0.6038171972548458,
      "eval_mean_iou": 0.4192394774909136,
      "eval_overall_accuracy": 0.8485027169647682,
      "eval_runtime": 292.2895,
      "eval_samples_per_second": 3.363,
      "eval_steps_per_second": 3.363,
      "step": 40000
    },
    {
      "epoch": 48.486977589339794,
      "grad_norm": 1.3449323177337646,
      "learning_rate": 2.1434005918751665e-06,
      "loss": 0.30994367599487305,
      "step": 40050
    },
    {
      "epoch": 48.54754694124773,
      "grad_norm": 1.8117876052856445,
      "learning_rate": 2.06282485875706e-06,
      "loss": 0.30361223220825195,
      "step": 40100
    },
    {
      "epoch": 48.60811629315566,
      "grad_norm": 1.6686102151870728,
      "learning_rate": 1.982249125638953e-06,
      "loss": 0.29163293838500975,
      "step": 40150
    },
    {
      "epoch": 48.6686856450636,
      "grad_norm": 2.297365427017212,
      "learning_rate": 1.9016733925208526e-06,
      "loss": 0.27008575439453125,
      "step": 40200
    },
    {
      "epoch": 48.729254996971534,
      "grad_norm": 7.195301055908203,
      "learning_rate": 1.8210976594027463e-06,
      "loss": 0.3001567459106445,
      "step": 40250
    },
    {
      "epoch": 48.78982434887946,
      "grad_norm": 1.7622814178466797,
      "learning_rate": 1.7405219262846393e-06,
      "loss": 0.30001522064208985,
      "step": 40300
    },
    {
      "epoch": 48.8503937007874,
      "grad_norm": 5.1849212646484375,
      "learning_rate": 1.6599461931665323e-06,
      "loss": 0.30384117126464844,
      "step": 40350
    },
    {
      "epoch": 48.91096305269534,
      "grad_norm": 1.319477915763855,
      "learning_rate": 1.5793704600484258e-06,
      "loss": 0.28802597045898437,
      "step": 40400
    },
    {
      "epoch": 48.97153240460327,
      "grad_norm": 2.36639404296875,
      "learning_rate": 1.4987947269303188e-06,
      "loss": 0.3059420204162598,
      "step": 40450
    },
    {
      "epoch": 49.031496062992126,
      "grad_norm": 1.9490158557891846,
      "learning_rate": 1.4182189938122118e-06,
      "loss": 0.2769997024536133,
      "step": 40500
    },
    {
      "epoch": 49.031496062992126,
      "eval_loss": 0.8236319422721863,
      "eval_mean_accuracy": 0.6018884210487095,
      "eval_mean_iou": 0.3943616419082227,
      "eval_overall_accuracy": 0.8473656655328077,
      "eval_runtime": 286.3578,
      "eval_samples_per_second": 3.433,
      "eval_steps_per_second": 3.433,
      "step": 40500
    },
    {
      "epoch": 49.09206541490006,
      "grad_norm": 9.08169937133789,
      "learning_rate": 1.3376432606941049e-06,
      "loss": 0.2964111328125,
      "step": 40550
    },
    {
      "epoch": 49.15263476680799,
      "grad_norm": 1.8298964500427246,
      "learning_rate": 1.2570675275760047e-06,
      "loss": 0.30094127655029296,
      "step": 40600
    },
    {
      "epoch": 49.21320411871593,
      "grad_norm": 2.6770153045654297,
      "learning_rate": 1.1764917944578981e-06,
      "loss": 0.2767756462097168,
      "step": 40650
    },
    {
      "epoch": 49.273773470623865,
      "grad_norm": 1.3603380918502808,
      "learning_rate": 1.0959160613397912e-06,
      "loss": 0.296415843963623,
      "step": 40700
    },
    {
      "epoch": 49.3343428225318,
      "grad_norm": 3.3233513832092285,
      "learning_rate": 1.0153403282216844e-06,
      "loss": 0.31005292892456054,
      "step": 40750
    },
    {
      "epoch": 49.39491217443973,
      "grad_norm": 16.872005462646484,
      "learning_rate": 9.347645951035776e-07,
      "loss": 0.29921030044555663,
      "step": 40800
    },
    {
      "epoch": 49.45548152634767,
      "grad_norm": 1.9278150796890259,
      "learning_rate": 8.541888619854707e-07,
      "loss": 0.2744891929626465,
      "step": 40850
    },
    {
      "epoch": 49.516050878255605,
      "grad_norm": 2.373124122619629,
      "learning_rate": 7.736131288673638e-07,
      "loss": 0.29398675918579104,
      "step": 40900
    },
    {
      "epoch": 49.576620230163535,
      "grad_norm": 4.481141090393066,
      "learning_rate": 6.946489104116205e-07,
      "loss": 0.3316389846801758,
      "step": 40950
    },
    {
      "epoch": 49.63718958207147,
      "grad_norm": 3.537287473678589,
      "learning_rate": 6.140731772935136e-07,
      "loss": 0.31054225921630857,
      "step": 41000
    },
    {
      "epoch": 49.63718958207147,
      "eval_loss": 0.823792576789856,
      "eval_mean_accuracy": 0.5953452717850266,
      "eval_mean_iou": 0.41924037289270716,
      "eval_overall_accuracy": 0.8460363036861012,
      "eval_runtime": 282.7136,
      "eval_samples_per_second": 3.477,
      "eval_steps_per_second": 3.477,
      "step": 41000
    }
  ],
  "logging_steps": 50,
  "max_steps": 41300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.8766434129807933e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
